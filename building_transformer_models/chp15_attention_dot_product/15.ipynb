{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3ed5a0-3f7c-41bf-ae01-c82f0553875b",
   "metadata": {},
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 15: Implementing Scaled Dot-Product Attention in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd2604-eb52-47dc-9128-950cbbf9b582",
   "metadata": {},
   "source": [
    "* [Introduction](#introduction)\n",
    "* [14.0 Imports and Setup](#14.0)\n",
    "* [14.1 What is Positional Encoding](#14.1)\n",
    "* [Extra](#extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b3b3f-d441-47ee-8407-028c0445cb71",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='introduction'></a><a id='introduction'></a>\n",
    "# Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "### Dataset\n",
    "\n",
    "* Fibonacci sequence\n",
    "\n",
    "\n",
    "### Explore\n",
    "* The operations forming the scaled dot-product attention mechanism\n",
    "* How to implement the scaled dot-product attention mechanism from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc36887-7910-4f6d-acad-b6d0c406d892",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='15.0'></a><a id='15.0'></a>\n",
    "# 15.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b5949c-5f46-428b-b69f-f95add9579c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_file = \"requirements_15.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb3fc865-8cb7-4dc9-9a0a-6be508c7c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements_15.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "isort\n",
    "scikit-learn-intelex\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8aabb5d-9aca-4ef8-8816-d5b53125aea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --upgrade --quiet -r {req_file}\n",
    "else:\n",
    "    print(\"Running locally.\")\n",
    "\n",
    "# Need to import before sklearn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "235d22d2-de94-4e15-b58e-412fd08cfdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imports.py\n",
    "import locale\n",
    "import math\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca95133c-512d-4128-b9ec-b26c7263a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import locale\n",
      "import math\n",
      "import pprint\n",
      "import warnings\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.activations import softmax\n",
      "from tensorflow.keras.layers import Layer\n",
      "from tqdm.auto import tqdm\n",
      "from watermark import watermark\n"
     ]
    }
   ],
   "source": [
    "!isort imports.py --sl\n",
    "!cat imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f44469f-adae-4c91-8bc6-6d924a90131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import math\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83b38539-ed0a-4066-8663-02b26b99052a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.3)\n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "numpy     : 1.23.5\n",
      "tensorflow: 2.9.3\n",
      "pandas    : 1.5.3\n",
      "seaborn   : 0.12.1\n",
      "matplotlib: 3.6.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "warnings.filterwarnings('default')\n",
    "BASE_DIR = '.'\n",
    "sns.set_style(\"darkgrid\")\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "print(watermark(iversions=True,globals_=globals(),python=True,machine=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b8d87-da41-4ce1-8a3f-acfc84b1adb9",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='15.1'></a><a id='15.1'></a>\n",
    "# 15.1 Recap of the Transformer Architecture\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1519de-1bfa-41a9-9738-47b206e916ce",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='15.2'></a><a id='15.2'></a>\n",
    "# 15.2 Implementing the Scaled Dot-Product Attention from Scratch\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfa9e92e-9ee0-417c-9604-865766c765fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "        \n",
    "        # Score the queries against the keys after transposing the latter, and scaling.\n",
    "        scores = tf.matmul(queries, keys, transpose_b=True) / tf.math.sqrt(tf.cast(d_k, tf.float32))\n",
    "        \n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask\n",
    "            \n",
    "        # Compute the weights by a softmax operation\n",
    "        weights = softmax(scores)\n",
    "        \n",
    "        # Compute the attention by a weighted sum of the values\n",
    "        return tf.matmul(weights, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4294974-f1a0-4123-a8bf-426d196fa4fe",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='15.3'></a><a id='15.3'></a>\n",
    "# 15.3 Testing out the Code\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c47a465-579c-4611-a653-e08da1ca0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_length = 5 # Max length of the input sequence\n",
    "d_k = 64 # Dimensionality of linearly projected queries and keys\n",
    "d_v = 64 # Dimensionality of linearly projected values\n",
    "batch_size = 64 # Batch size from the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1890f651-79c2-4849-a300-6904afae78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed)\n",
    "\n",
    "queries = np.random.random((batch_size, input_seq_length, d_k))\n",
    "keys = np.random.random((batch_size, input_seq_length, d_k))\n",
    "values = np.random.random((batch_size, input_seq_length, d_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4189e1ea-c24e-4bed-968e-80abe2333717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DotProductAttention object at 0x1399a5970>\n",
      "----------------------------------------\n",
      "tf.Tensor(\n",
      "[[[0.58271706 0.3669912  0.7677716  ... 0.46982276 0.5814083  0.4772146 ]\n",
      "  [0.5688315  0.37259603 0.767018   ... 0.465158   0.5966402  0.4810904 ]\n",
      "  [0.57154316 0.37507954 0.761297   ... 0.46625522 0.60105205 0.5013971 ]\n",
      "  [0.5796002  0.35143456 0.7531471  ... 0.46386203 0.5852657  0.46648335]\n",
      "  [0.57480466 0.37260708 0.767243   ... 0.46816579 0.59327304 0.49850357]]\n",
      "\n",
      " [[0.46294922 0.6476046  0.45672026 ... 0.5590128  0.6861026  0.49989527]\n",
      "  [0.48486906 0.6461595  0.44293126 ... 0.5345297  0.6770745  0.49627537]\n",
      "  [0.45582354 0.64962494 0.46603113 ... 0.5639738  0.6960226  0.49553573]\n",
      "  [0.48267892 0.65860003 0.4400514  ... 0.53288347 0.68262976 0.48564136]\n",
      "  [0.4864344  0.6538298  0.44277206 ... 0.5305253  0.6840395  0.4874709 ]]\n",
      "\n",
      " [[0.50777805 0.6476767  0.3940273  ... 0.61106133 0.5313678  0.5628838 ]\n",
      "  [0.5125144  0.65115774 0.3987783  ... 0.6037308  0.5237102  0.5625333 ]\n",
      "  [0.50641376 0.6393231  0.40006137 ... 0.6315589  0.5391761  0.5831233 ]\n",
      "  [0.5066764  0.65097517 0.3991524  ... 0.6206424  0.5197504  0.5742552 ]\n",
      "  [0.514799   0.6340266  0.3939991  ... 0.60917413 0.547514   0.5545743 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.551603   0.5678664  0.4695096  ... 0.22173479 0.31275314 0.4401528 ]\n",
      "  [0.52932173 0.54600847 0.44765413 ... 0.2165416  0.31446537 0.4266675 ]\n",
      "  [0.5087487  0.53149486 0.44538957 ... 0.21169126 0.33248368 0.41809285]\n",
      "  [0.51541156 0.55019665 0.45199695 ... 0.21798195 0.30510688 0.41710615]\n",
      "  [0.536874   0.5472194  0.44824558 ... 0.21546616 0.3179553  0.4267919 ]]\n",
      "\n",
      " [[0.32973108 0.46066383 0.6301271  ... 0.572029   0.1944361  0.49192923]\n",
      "  [0.34099865 0.47038454 0.61871105 ... 0.56400037 0.1927064  0.5063296 ]\n",
      "  [0.3339607  0.4633415  0.61815643 ... 0.5533481  0.19265059 0.5145827 ]\n",
      "  [0.3278299  0.4574967  0.6184747  ... 0.5564228  0.19160196 0.50628716]\n",
      "  [0.3259911  0.4572533  0.6143913  ... 0.55580485 0.19025345 0.49733067]]\n",
      "\n",
      " [[0.541142   0.62675816 0.59683686 ... 0.29518348 0.1602976  0.5144311 ]\n",
      "  [0.5749179  0.6291433  0.60237175 ... 0.30381647 0.15209475 0.4973732 ]\n",
      "  [0.5621699  0.6104141  0.59969795 ... 0.30920124 0.15630879 0.49472478]\n",
      "  [0.5590926  0.6431617  0.60526276 ... 0.2949884  0.15955803 0.51546526]\n",
      "  [0.5447423  0.6276508  0.60030836 ... 0.29614335 0.16254538 0.51518434]]], shape=(64, 5, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attention = DotProductAttention()\n",
    "print(attention)\n",
    "HR()\n",
    "\n",
    "print(attention(queries, keys, values, d_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a17ea9d7-a945-4696-85e6-2038ce89b6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 5, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(queries, keys, values, d_k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa898d-ce90-4293-97f4-59e2b9091134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
