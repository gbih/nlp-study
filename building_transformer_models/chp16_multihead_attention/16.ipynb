{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3ed5a0-3f7c-41bf-ae01-c82f0553875b",
   "metadata": {},
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 16: Implementing Multi-Head Attention in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd2604-eb52-47dc-9128-950cbbf9b582",
   "metadata": {},
   "source": [
    "* [Introduction](#introduction)\n",
    "* [16.0 Imports and Setup](#16.0)\n",
    "* [16.1 Recap of Multi-Head Attention](#16.1)\n",
    "* [16.2 Implementing Multi-Head Attention from Scratch](#16.2)\n",
    "* [16.3 Testing Out the Code](#16.3)\n",
    "* [Extra](#extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b3b3f-d441-47ee-8407-028c0445cb71",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='introduction'></a><a id='introduction'></a>\n",
    "# Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "### Dataset\n",
    "\n",
    "* TODO\n",
    "\n",
    "### Explore\n",
    "* The layers that form part of the multi-head attention mechanism\n",
    "* How to implement the multi-head attention mechanism from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc36887-7910-4f6d-acad-b6d0c406d892",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='16.0'></a><a id='16.0'></a>\n",
    "# 16.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b5949c-5f46-428b-b69f-f95add9579c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_file = \"requirements_16.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3fc865-8cb7-4dc9-9a0a-6be508c7c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements_16.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "isort\n",
    "scikit-learn-intelex\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be81958-6606-47da-9751-2d247f90a70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --upgrade --quiet -r {req_file}\n",
    "else:\n",
    "    print(\"Running locally.\")\n",
    "\n",
    "# Need to import before sklearn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235d22d2-de94-4e15-b58e-412fd08cfdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imports.py\n",
    "import locale\n",
    "import math\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca95133c-512d-4128-b9ec-b26c7263a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import locale\n",
      "import math\n",
      "import pprint\n",
      "import warnings\n",
      "\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras import Model\n",
      "from tensorflow.keras.activations import softmax\n",
      "from tensorflow.keras.layers import Dense\n",
      "from tensorflow.keras.layers import Layer\n",
      "from tqdm.auto import tqdm\n",
      "from watermark import watermark\n"
     ]
    }
   ],
   "source": [
    "!isort imports.py --sl\n",
    "!cat imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f44469f-adae-4c91-8bc6-6d924a90131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import math\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b38539-ed0a-4066-8663-02b26b99052a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.3)\n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "tensorflow: 2.9.3\n",
      "numpy     : 1.23.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "warnings.filterwarnings('default')\n",
    "BASE_DIR = '.'\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "print(watermark(iversions=True,globals_=globals(),python=True,machine=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b8d87-da41-4ce1-8a3f-acfc84b1adb9",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='16.1'></a><a id='16.1'></a>\n",
    "# 16.1 Recap of the Transformer Architecture\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1519de-1bfa-41a9-9738-47b206e916ce",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='16.2'></a><a id='16.2'></a>\n",
    "# 16.2 Implementing the Multi-Head Attention from Scratch\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aab1fea-e950-458f-bbe4-1572c2e03ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
    "        scores = tf.matmul(queries, keys, transpose_b=True) / tf.math.sqrt(tf.cast(d_k, tf.float32))\n",
    "\n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask\n",
    "\n",
    "        # Computing the weights by a softmax operation\n",
    "        weights = softmax(scores)\n",
    "\n",
    "        # Computing the attention by a weighted sum of the value vectors\n",
    "        return tf.matmul(weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b9957b-247d-4d02-92dc-b5cb448cee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Multi-Head Attention\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = DotProductAttention()  # Scaled dot product attention\n",
    "        self.heads = h  # Number of attention heads to use\n",
    "        self.d_k = d_k  # Dimensionality of the linearly projected queries and keys\n",
    "        self.d_v = d_v  # Dimensionality of the linearly projected values\n",
    "        self.d_model = d_model  # Dimensionality of the model\n",
    "        self.W_q = Dense(d_k)   # Learned projection matrix for the queries\n",
    "        self.W_k = Dense(d_k)   # Learned projection matrix for the keys\n",
    "        self.W_v = Dense(d_v)   # Learned projection matrix for the values\n",
    "        self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n",
    "\n",
    "        \n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            # Tensor shape after reshaping and transposing:\n",
    "            # (batch_size, heads, seq_length, -1)\n",
    "            x = tf.reshape(x, shape=(tf.shape(x)[0], tf.shape(x)[1], heads, -1))\n",
    "            x = tf.transpose(x, perm=(0, 2, 1, 3))\n",
    "        else:\n",
    "            # Reverting the reshaping and transposing operations:\n",
    "            # (batch_size, seq_length, d_k)\n",
    "            x = tf.transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = tf.reshape(x, shape=(tf.shape(x)[0], tf.shape(x)[1], self.d_k))\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "        # Rearrange the queries to be able to compute all heads in parallel\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange the keys to be able to compute all heads in parallel\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange the values to be able to compute all heads in parallel\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Compute the multi-head attention output using the reshaped queries,\n",
    "        # keys, and values\n",
    "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange back the output into concatenated form\n",
    "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
    "        # Resulting tensor shape: (batch_size, input_seq_length, d_v)\n",
    "\n",
    "        # Apply one final linear projection to the output to generate the multi-head\n",
    "        # attention. Resulting tensor shape: (batch_size, input_seq_length, d_model)\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9cd2f3-3796-4c25-9476-542b7ff01edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 5, 512)\n",
      "----------------------------------------\n",
      "[[[-0.483   0.0095  0.2367 ...  0.0082 -0.14    0.3893]\n",
      "  [-0.483   0.0083  0.2397 ...  0.0093 -0.1388  0.3903]\n",
      "  [-0.4804  0.0089  0.2385 ...  0.0082 -0.1377  0.392 ]\n",
      "  [-0.482   0.0086  0.239  ...  0.0061 -0.1368  0.3931]\n",
      "  [-0.4803  0.0096  0.2381 ...  0.0064 -0.139   0.3917]]\n",
      "\n",
      " [[-0.3068 -0.1063  0.0525 ...  0.1303 -0.1617  0.3285]\n",
      "  [-0.3079 -0.109   0.0535 ...  0.1306 -0.1605  0.3273]\n",
      "  [-0.3074 -0.1055  0.0474 ...  0.1335 -0.1588  0.3233]\n",
      "  [-0.3063 -0.1089  0.0549 ...  0.1296 -0.1609  0.3292]\n",
      "  [-0.3093 -0.1074  0.054  ...  0.1316 -0.1613  0.3283]]\n",
      "\n",
      " [[-0.4409 -0.0034  0.0741 ...  0.0784 -0.1859  0.3943]\n",
      "  [-0.4421 -0.0052  0.0719 ...  0.0801 -0.1858  0.3927]\n",
      "  [-0.4401 -0.0073  0.0695 ...  0.0807 -0.1872  0.3899]\n",
      "  [-0.4416 -0.007   0.0694 ...  0.0819 -0.1852  0.3903]\n",
      "  [-0.4441 -0.0122  0.0711 ...  0.0843 -0.1868  0.3896]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.427  -0.025   0.0841 ...  0.1249 -0.1349  0.3819]\n",
      "  [-0.4269 -0.0239  0.0825 ...  0.1256 -0.1376  0.3775]\n",
      "  [-0.4255 -0.0246  0.0814 ...  0.1287 -0.1355  0.3792]\n",
      "  [-0.4252 -0.0221  0.0821 ...  0.1269 -0.1368  0.3797]\n",
      "  [-0.4258 -0.0248  0.0853 ...  0.1245 -0.1332  0.3807]]\n",
      "\n",
      " [[-0.3509 -0.091   0.0606 ...  0.1017 -0.0974  0.3658]\n",
      "  [-0.3494 -0.0914  0.0609 ...  0.1056 -0.0965  0.3636]\n",
      "  [-0.3489 -0.0895  0.0598 ...  0.1056 -0.0973  0.3642]\n",
      "  [-0.3507 -0.0903  0.0601 ...  0.1037 -0.099   0.3639]\n",
      "  [-0.3515 -0.0913  0.0609 ...  0.105  -0.0995  0.364 ]]\n",
      "\n",
      " [[-0.4009 -0.1475 -0.0209 ...  0.1204 -0.0738  0.3247]\n",
      "  [-0.4016 -0.1485 -0.0198 ...  0.122  -0.0714  0.3246]\n",
      "  [-0.404  -0.1495 -0.018  ...  0.1259 -0.0706  0.3234]\n",
      "  [-0.4019 -0.1484 -0.0235 ...  0.1267 -0.0696  0.3236]\n",
      "  [-0.3997 -0.1518 -0.0203 ...  0.1251 -0.0711  0.3238]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 11:12:58.542612: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
    "batch_size = 64  # Batch size from the training process\n",
    "\n",
    "queries = np.random.random((batch_size, input_seq_length, d_k))\n",
    "keys = np.random.random((batch_size, input_seq_length, d_k))\n",
    "values = np.random.random((batch_size, input_seq_length, d_v))\n",
    "\n",
    "multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "\n",
    "test = multihead_attention(queries, keys, values)\n",
    "print(test.shape)\n",
    "HR()\n",
    "print(test.numpy().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a315a9-d5f4-4c14-b790-d5f174be90dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
