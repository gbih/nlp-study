{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3ed5a0-3f7c-41bf-ae01-c82f0553875b",
   "metadata": {
    "id": "4f3ed5a0-3f7c-41bf-ae01-c82f0553875b"
   },
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 20: Training the Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd2604-eb52-47dc-9128-950cbbf9b582",
   "metadata": {
    "id": "89bd2604-eb52-47dc-9128-950cbbf9b582"
   },
   "source": [
    "* [Introduction](#introduction)\n",
    "* [20.0 Imports and Setup](#20.0)\n",
    "* [20.1 Preparing the Training Dataset](#20.1)\n",
    "* [20.2 Applying a Padding Mask](#20.2)\n",
    "* [20.3 Training the Transformer Model](#20.3)\n",
    "* [Extra](#extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b3b3f-d441-47ee-8407-028c0445cb71",
   "metadata": {
    "id": "e10b3b3f-d441-47ee-8407-028c0445cb71"
   },
   "source": [
    "---\n",
    "<a name='introduction'></a><a id='introduction'></a>\n",
    "# Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "### Dataset\n",
    "\n",
    "* TODO\n",
    "\n",
    "### Explore\n",
    "* How to prepare the training dataset\n",
    "* How to apply a padding mask to the loss and accuracy computations\n",
    "* How to train the transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc36887-7910-4f6d-acad-b6d0c406d892",
   "metadata": {
    "id": "5dc36887-7910-4f6d-acad-b6d0c406d892"
   },
   "source": [
    "---\n",
    "<a name='20.0'></a><a id='20.0'></a>\n",
    "# 20.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b5949c-5f46-428b-b69f-f95add9579c9",
   "metadata": {
    "id": "99b5949c-5f46-428b-b69f-f95add9579c9"
   },
   "outputs": [],
   "source": [
    "req_file = \"requirements_20.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3fc865-8cb7-4dc9-9a0a-6be508c7c94b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb3fc865-8cb7-4dc9-9a0a-6be508c7c94b",
    "outputId": "d6396dfb-3910-4597-b984-359c171df88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements_20.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "isort\n",
    "scikit-learn-intelex\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vtSirLyD0DG1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtSirLyD0DG1",
    "outputId": "f76e0624-8866-4d8f-c096-ecdb5337299f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --upgrade --quiet -r {req_file}\n",
    "else:\n",
    "    print(\"Running locally.\")\n",
    "\n",
    "# Need to import before sklearn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235d22d2-de94-4e15-b58e-412fd08cfdee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "235d22d2-de94-4e15-b58e-412fd08cfdee",
    "outputId": "aa7111fc-5776-484e-8658-78cc78060680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing imports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imports.py\n",
    "import locale\n",
    "import math\n",
    "import pprint\n",
    "import warnings\n",
    "from pickle import load\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy.random import shuffle\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow import TensorSpec\n",
    "from tensorflow import argmax\n",
    "from tensorflow import cast\n",
    "from tensorflow import convert_to_tensor\n",
    "from tensorflow import data\n",
    "from tensorflow import equal\n",
    "from tensorflow import float32\n",
    "from tensorflow import function\n",
    "from tensorflow import int64\n",
    "from tensorflow import linalg\n",
    "from tensorflow import math\n",
    "from tensorflow import matmul\n",
    "from tensorflow import maximum\n",
    "from tensorflow import newaxis\n",
    "from tensorflow import ones\n",
    "from tensorflow import reduce_sum\n",
    "from tensorflow import reshape\n",
    "from tensorflow import shape\n",
    "from tensorflow import train\n",
    "from tensorflow import transpose\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.backend import softmax\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca95133c-512d-4128-b9ec-b26c7263a342",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca95133c-512d-4128-b9ec-b26c7263a342",
    "outputId": "e8126e0f-ea23-4728-ccd7-27f7e9aa3d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import locale\n",
      "import math\n",
      "import pprint\n",
      "import warnings\n",
      "from pickle import load\n",
      "from time import time\n",
      "\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from numpy.random import shuffle\n",
      "from tensorflow import GradientTape\n",
      "from tensorflow import TensorSpec\n",
      "from tensorflow import argmax\n",
      "from tensorflow import cast\n",
      "from tensorflow import convert_to_tensor\n",
      "from tensorflow import data\n",
      "from tensorflow import equal\n",
      "from tensorflow import float32\n",
      "from tensorflow import function\n",
      "from tensorflow import int64\n",
      "from tensorflow import linalg\n",
      "from tensorflow import math\n",
      "from tensorflow import matmul\n",
      "from tensorflow import maximum\n",
      "from tensorflow import newaxis\n",
      "from tensorflow import ones\n",
      "from tensorflow import reduce_sum\n",
      "from tensorflow import reshape\n",
      "from tensorflow import shape\n",
      "from tensorflow import train\n",
      "from tensorflow import transpose\n",
      "from tensorflow.keras import Model\n",
      "from tensorflow.keras.backend import softmax\n",
      "from tensorflow.keras.layers import Dense\n",
      "from tensorflow.keras.layers import Dropout\n",
      "from tensorflow.keras.layers import Embedding\n",
      "from tensorflow.keras.layers import Layer\n",
      "from tensorflow.keras.layers import LayerNormalization\n",
      "from tensorflow.keras.layers import ReLU\n",
      "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
      "from tensorflow.keras.metrics import Mean\n",
      "from tensorflow.keras.optimizers import Adam\n",
      "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
      "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
      "from tensorflow.keras.preprocessing.text import Tokenizer\n",
      "from tqdm.auto import tqdm\n",
      "from watermark import watermark\n"
     ]
    }
   ],
   "source": [
    "!isort imports.py --sl\n",
    "!cat imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f44469f-adae-4c91-8bc6-6d924a90131e",
   "metadata": {
    "id": "6f44469f-adae-4c91-8bc6-6d924a90131e"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "import math\n",
    "import pprint\n",
    "import warnings\n",
    "from pickle import load\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy.random import shuffle\n",
    "from tensorflow import GradientTape\n",
    "from tensorflow import TensorSpec\n",
    "from tensorflow import argmax\n",
    "from tensorflow import cast\n",
    "from tensorflow import convert_to_tensor\n",
    "from tensorflow import data\n",
    "from tensorflow import equal\n",
    "from tensorflow import float32\n",
    "from tensorflow import function\n",
    "from tensorflow import int64\n",
    "from tensorflow import linalg\n",
    "from tensorflow import math\n",
    "from tensorflow import matmul\n",
    "from tensorflow import maximum\n",
    "from tensorflow import newaxis\n",
    "from tensorflow import ones\n",
    "from tensorflow import reduce_sum\n",
    "from tensorflow import reshape\n",
    "from tensorflow import shape\n",
    "from tensorflow import train\n",
    "from tensorflow import transpose\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.backend import softmax\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b38539-ed0a-4066-8663-02b26b99052a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83b38539-ed0a-4066-8663-02b26b99052a",
    "outputId": "7a373885-58f0-452f-ea07-b1105f6388b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.3)\n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "tensorflow: 2.9.3\n",
      "sys       : 3.8.12 (default, Dec 13 2021, 20:17:08) \n",
      "[Clang 13.0.0 (clang-1300.0.29.3)]\n",
      "numpy     : 1.23.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "warnings.filterwarnings('default')\n",
    "BASE_DIR = '.'\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "print(watermark(iversions=True,globals_=globals(),python=True,machine=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a5e937-3e4c-4260-8f19-45f7d0716361",
   "metadata": {
    "id": "e7a5e937-3e4c-4260-8f19-45f7d0716361"
   },
   "source": [
    "# Previous Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebfaa201-7fdb-4c86-8cc0-4227ee54dbf8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebfaa201-7fdb-4c86-8cc0-4227ee54dbf8",
    "outputId": "efe3894e-9ebf-481e-d401-f1cc10f7edb6"
   },
   "outputs": [],
   "source": [
    "class PositionEmbeddingFixedWeights(Layer):\n",
    "    def __init__(self, seq_length, vocab_size, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        word_embedding_matrix = self.get_position_encoding(vocab_size, output_dim)\n",
    "        pos_embedding_matrix = self.get_position_encoding(seq_length, output_dim)\n",
    "        self.word_embedding_layer = Embedding(\n",
    "            input_dim=vocab_size, output_dim=output_dim,\n",
    "            weights=[word_embedding_matrix],\n",
    "            trainable=False\n",
    "        )\n",
    "        self.position_embedding_layer = Embedding(\n",
    "            input_dim=seq_length, output_dim=output_dim,\n",
    "            weights=[pos_embedding_matrix],\n",
    "            trainable=False\n",
    "        )\n",
    "\n",
    "    def get_position_encoding(self, seq_len, d, n=10000):\n",
    "        P = np.zeros((seq_len, d))\n",
    "        for k in range(seq_len):\n",
    "            for i in np.arange(int(d/2)):\n",
    "                denominator = np.power(n, 2*i/d)\n",
    "                P[k, 2*i] = np.sin(k/denominator)\n",
    "                P[k, 2*i+1] = np.cos(k/denominator)\n",
    "        return P\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
    "        embedded_words = self.word_embedding_layer(inputs)\n",
    "        embedded_indices = self.position_embedding_layer(position_indices)\n",
    "        return embedded_words + embedded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "027b9297-77f4-4f18-9363-ce2c128d9efa",
   "metadata": {
    "id": "027b9297-77f4-4f18-9363-ce2c128d9efa"
   },
   "outputs": [],
   "source": [
    "# Implementing the Scaled-Dot Product Attention\n",
    "class DotProductAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
    "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
    "\n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask\n",
    "\n",
    "        # Computing the weights by a softmax operation\n",
    "        weights = softmax(scores)\n",
    "\n",
    "        # Computing the attention by a weighted sum of the value vectors\n",
    "        return matmul(weights, values)\n",
    "\n",
    "# Implementing the Multi-Head Attention\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = DotProductAttention()  # Scaled dot product attention\n",
    "        self.heads = h  # Number of attention heads to use\n",
    "        self.d_k = d_k  # Dimensionality of the linearly projected queries and keys\n",
    "        self.d_v = d_v  # Dimensionality of the linearly projected values\n",
    "        self.d_model = d_model  # Dimensionality of the model\n",
    "        self.W_q = Dense(d_k)   # Learned projection matrix for the queries\n",
    "        self.W_k = Dense(d_k)   # Learned projection matrix for the keys\n",
    "        self.W_v = Dense(d_v)   # Learned projection matrix for the values\n",
    "        self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n",
    "\n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            # Tensor shape after reshaping and transposing:\n",
    "            # (batch_size, heads, seq_length, -1)\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "        else:\n",
    "            # Reverting the reshaping and transposing operations:\n",
    "            # (batch_size, seq_length, d_k)\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], self.d_k))\n",
    "        return x\n",
    "\n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "        # Rearrange the queries to be able to compute all heads in parallel\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange the keys to be able to compute all heads in parallel\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange the values to be able to compute all heads in parallel\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Compute the multi-head attention output using the reshaped queries,\n",
    "        # keys, and values\n",
    "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
    "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
    "\n",
    "        # Rearrange back the output into concatenated form\n",
    "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
    "        # Resulting tensor shape: (batch_size, input_seq_length, d_v)\n",
    "\n",
    "        # Apply one final linear projection to the output to generate the multi-head\n",
    "        # attention. Resulting tensor shape: (batch_size, input_seq_length, d_model)\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bea761b-1686-48c3-9b3b-f8d26d7f3e0f",
   "metadata": {
    "id": "5bea761b-1686-48c3-9b3b-f8d26d7f3e0f"
   },
   "outputs": [],
   "source": [
    "# Implementing the Add & Norm Layer\n",
    "class AddNormalization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer_norm = LayerNormalization()  # Layer normalization layer\n",
    "\n",
    "    def call(self, x, sublayer_x):\n",
    "        # The sublayer input and output need to be of the same shape to be summed\n",
    "        add = x + sublayer_x\n",
    "\n",
    "        # Apply layer normalization to the sum\n",
    "        return self.layer_norm(add)\n",
    "\n",
    "# Implementing the Feed-Forward Layer\n",
    "class FeedForward(Layer):\n",
    "    def __init__(self, d_ff, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fully_connected1 = Dense(d_ff)  # First fully connected layer\n",
    "        self.fully_connected2 = Dense(d_model)  # Second fully connected layer\n",
    "        self.activation = ReLU()  # ReLU activation layer\n",
    "\n",
    "    def call(self, x):\n",
    "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
    "        x_fc1 = self.fully_connected1(x)\n",
    "\n",
    "        return self.fully_connected2(self.activation(x_fc1))\n",
    "\n",
    "# Implementing the Encoder Layer\n",
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.add_norm1 = AddNormalization()\n",
    "        self.feed_forward = FeedForward(d_ff, d_model)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.add_norm2 = AddNormalization()\n",
    "\n",
    "    def call(self, x, padding_mask, training):\n",
    "        # Multi-head attention layer\n",
    "        multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in a dropout layer\n",
    "        multihead_output = self.dropout1(multihead_output, training=training)\n",
    "\n",
    "        # Followed by an Add & Norm layer\n",
    "        addnorm_output = self.add_norm1(x, multihead_output)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Followed by a fully connected layer\n",
    "        feedforward_output = self.feed_forward(addnorm_output)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in another dropout layer\n",
    "        feedforward_output = self.dropout2(feedforward_output, training=training)\n",
    "\n",
    "        # Followed by another Add & Norm layer\n",
    "        return self.add_norm2(addnorm_output, feedforward_output)\n",
    "\n",
    "# Implementing the Encoder\n",
    "class Encoder(Layer):\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,\n",
    "                       **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,\n",
    "                                                          d_model)\n",
    "        self.dropout = Dropout(rate)\n",
    "        self.encoder_layer = [EncoderLayer(h, d_k, d_v, d_model, d_ff, rate)\n",
    "                              for _ in range(n)]\n",
    "\n",
    "    def call(self, input_sentence, padding_mask, training):\n",
    "        # Generate the positional encoding\n",
    "        pos_encoding_output = self.pos_encoding(input_sentence)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in a dropout layer\n",
    "        x = self.dropout(pos_encoding_output, training=training)\n",
    "\n",
    "        # Pass on the positional encoded values to each encoder layer\n",
    "        for i, layer in enumerate(self.encoder_layer):\n",
    "            x = layer(x, padding_mask, training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5d7bcb-570c-4d51-9c17-9f5a79cc7b77",
   "metadata": {
    "id": "dd5d7bcb-570c-4d51-9c17-9f5a79cc7b77"
   },
   "outputs": [],
   "source": [
    "# Implementing the Decoder Layer\n",
    "class DecoderLayer(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.add_norm1 = AddNormalization()\n",
    "        self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.add_norm2 = AddNormalization()\n",
    "        self.feed_forward = FeedForward(d_ff, d_model)\n",
    "        self.dropout3 = Dropout(rate)\n",
    "        self.add_norm3 = AddNormalization()\n",
    "\n",
    "    def call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n",
    "        # Multi-head attention layer\n",
    "        multihead_output1 = self.multihead_attention1(x, x, x, lookahead_mask)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in a dropout layer\n",
    "        multihead_output1 = self.dropout1(multihead_output1, training=training)\n",
    "\n",
    "        # Followed by an Add & Norm layer\n",
    "        addnorm_output1 = self.add_norm1(x, multihead_output1)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Followed by another multi-head attention layer\n",
    "        multihead_output2 = self.multihead_attention2(addnorm_output1, encoder_output,\n",
    "                                                      encoder_output, padding_mask)\n",
    "\n",
    "        # Add in another dropout layer\n",
    "        multihead_output2 = self.dropout2(multihead_output2, training=training)\n",
    "\n",
    "        # Followed by another Add & Norm layer\n",
    "        addnorm_output2 = self.add_norm1(addnorm_output1, multihead_output2)\n",
    "\n",
    "        # Followed by a fully connected layer\n",
    "        feedforward_output = self.feed_forward(addnorm_output2)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "\n",
    "        # Add in another dropout layer\n",
    "        feedforward_output = self.dropout3(feedforward_output, training=training)\n",
    "\n",
    "        # Followed by another Add & Norm layer\n",
    "        return self.add_norm3(addnorm_output2, feedforward_output)\n",
    "\n",
    "# Implementing the Decoder\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,\n",
    "                       **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,\n",
    "                                                          d_model)\n",
    "        self.dropout = Dropout(rate)\n",
    "        self.decoder_layer = [DecoderLayer(h, d_k, d_v, d_model, d_ff, rate)\n",
    "                              for _ in range(n)]\n",
    "\n",
    "    def call(self, output_target, encoder_output, lookahead_mask, padding_mask, training):\n",
    "        # Generate the positional encoding\n",
    "        pos_encoding_output = self.pos_encoding(output_target)\n",
    "        # Expected output shape = (number of sentences, sequence_length, d_model)\n",
    "\n",
    "        # Add in a dropout layer\n",
    "        x = self.dropout(pos_encoding_output, training=training)\n",
    "\n",
    "        # Pass on the positional encoded values to each encoder layer\n",
    "        for i, layer in enumerate(self.decoder_layer):\n",
    "            x = layer(x, encoder_output, lookahead_mask, padding_mask, training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0134600-8dbc-4513-a0a6-0ec2cb833be3",
   "metadata": {
    "id": "a0134600-8dbc-4513-a0a6-0ec2cb833be3"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(Model):\n",
    "    def __init__(self, enc_vocab_size, dec_vocab_size, enc_seq_length, dec_seq_length,\n",
    "                       h, d_k, d_v, d_model, d_ff_inner, n, rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Set up the encoder\n",
    "        self.encoder = Encoder(enc_vocab_size, enc_seq_length, h, d_k, d_v,\n",
    "                               d_model, d_ff_inner, n, rate)\n",
    "\n",
    "        # Set up the decoder\n",
    "        self.decoder = Decoder(dec_vocab_size, dec_seq_length, h, d_k, d_v,\n",
    "                               d_model, d_ff_inner, n, rate)\n",
    "\n",
    "        # Define the final dense layer\n",
    "        self.model_last_layer = Dense(dec_vocab_size)\n",
    "\n",
    "    def padding_mask(self, input):\n",
    "        # Create mask which marks the zero padding values in the input by a 1.0\n",
    "        mask = math.equal(input, 0)\n",
    "        mask = cast(mask, float32)\n",
    "\n",
    "        # The shape of the mask should be broadcastable to the shape\n",
    "        # of the attention weights that it will be masking later on\n",
    "        return mask[:, newaxis, newaxis, :]\n",
    "\n",
    "    def lookahead_mask(self, shape):\n",
    "        # Mask out future entries by marking them with a 1.0\n",
    "        mask = 1 - linalg.band_part(ones((shape, shape)), -1, 0)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def call(self, encoder_input, decoder_input, training):\n",
    "\n",
    "        # Create padding mask to mask the encoder inputs and the encoder\n",
    "        # outputs in the decoder\n",
    "        enc_padding_mask = self.padding_mask(encoder_input)\n",
    "\n",
    "        # Create and combine padding and look-ahead masks to be fed into the decoder\n",
    "        dec_in_padding_mask = self.padding_mask(decoder_input)\n",
    "        dec_in_lookahead_mask = self.lookahead_mask(decoder_input.shape[1])\n",
    "        dec_in_lookahead_mask = maximum(dec_in_padding_mask, dec_in_lookahead_mask)\n",
    "\n",
    "        # Feed the input into the encoder\n",
    "        encoder_output = self.encoder(encoder_input, enc_padding_mask, training)\n",
    "\n",
    "        # Feed the encoder output into the decoder\n",
    "        decoder_output = self.decoder(decoder_input, encoder_output,\n",
    "                                      dec_in_lookahead_mask, enc_padding_mask, training)\n",
    "\n",
    "        # Pass the decoder output through a final dense layer\n",
    "        model_output = self.model_last_layer(decoder_output)\n",
    "\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a82fc-ff4f-4193-8d38-0a1302faf9ff",
   "metadata": {
    "id": "560a82fc-ff4f-4193-8d38-0a1302faf9ff"
   },
   "source": [
    "---\n",
    "<a name='20.1'></a><a id='20.1'></a>\n",
    "# 20.1 Preparing the Training Datast\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ed5120-4222-49af-a634-fa36c283c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70ed5120-4222-49af-a634-fa36c283c122",
    "outputId": "07813a07-f9a7-446c-f7fc-42c41c6132be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-22 20:21:55--  https://github.com/Rishav09/Neural-Machine-Translation-System/raw/master/english-german-both.pkl\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Rishav09/Neural-Machine-Translation-System/master/english-german-both.pkl [following]\n",
      "--2023-06-22 20:21:55--  https://raw.githubusercontent.com/Rishav09/Neural-Machine-Translation-System/master/english-german-both.pkl\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29600158 (28M) [application/octet-stream]\n",
      "Saving to: ‘english-german-both.pkl’\n",
      "\n",
      "english-german-both 100%[===================>]  28.23M  8.17MB/s    in 3.7s    \n",
      "\n",
      "2023-06-22 20:22:01 (7.67 MB/s) - ‘english-german-both.pkl’ saved [29600158/29600158]\n",
      "\n",
      "----------------------------------------\n",
      "-rw-r--r--  1 gb  staff  29600158 Jun 22 20:22 english-german-both.pkl\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://github.com/Rishav09/Neural-Machine-Translation-System/raw/master/english-german-both.pkl\n",
    "\n",
    "HR()\n",
    "!ls -l english-german-both.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad3ce40-efb2-4a3a-9483-1d00a6fc59a1",
   "metadata": {
    "id": "6ad3ce40-efb2-4a3a-9483-1d00a6fc59a1"
   },
   "outputs": [],
   "source": [
    "class PrepareDataset:\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_sentences = 10000  # Number of sentences to include in the dataset\n",
    "        self.train_split = 0.9  # Ratio of the training data split\n",
    "\n",
    "    # Fit a tokenizer\n",
    "    def create_tokenizer(self, dataset):\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(dataset)\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "    def find_seq_length(self, dataset):\n",
    "        return max(len(seq.split()) for seq in dataset)\n",
    "\n",
    "    def find_vocab_size(self, tokenizer, dataset):\n",
    "        tokenizer.fit_on_texts(dataset)\n",
    "\n",
    "        return len(tokenizer.word_index) + 1\n",
    "\n",
    "    def __call__(self, filename, **kwargs):\n",
    "        # Load a clean dataset\n",
    "        clean_dataset = load(open(filename, 'rb'))\n",
    "\n",
    "        # Reduce dataset size\n",
    "        dataset = clean_dataset[:self.n_sentences, :]\n",
    "\n",
    "        # Include start and end of string tokens\n",
    "        for i in range(dataset[:, 0].size):\n",
    "            dataset[i, 0] = \"<START> \" + dataset[i, 0] + \" <EOS>\"\n",
    "            dataset[i, 1] = \"<START> \" + dataset[i, 1] + \" <EOS>\"\n",
    "\n",
    "        # Random shuffle the dataset\n",
    "        shuffle(dataset)\n",
    "\n",
    "        # Split the dataset\n",
    "        train = dataset[:int(self.n_sentences * self.train_split)]\n",
    "\n",
    "        # Prepare tokenizer for the encoder input\n",
    "        enc_tokenizer = self.create_tokenizer(train[:, 0])\n",
    "        enc_seq_length = self.find_seq_length(train[:, 0])\n",
    "        enc_vocab_size = self.find_vocab_size(enc_tokenizer, train[:, 0])\n",
    "\n",
    "        # Encode and pad the input sequences\n",
    "        trainX = enc_tokenizer.texts_to_sequences(train[:, 0])\n",
    "        trainX = pad_sequences(trainX, maxlen=enc_seq_length, padding='post')\n",
    "        trainX = convert_to_tensor(trainX, dtype=int64)\n",
    "\n",
    "        # Prepare tokenizer for the decoder input\n",
    "        dec_tokenizer = self.create_tokenizer(train[:, 1])\n",
    "        dec_seq_length = self.find_seq_length(train[:, 1])\n",
    "        dec_vocab_size = self.find_vocab_size(dec_tokenizer, train[:, 1])\n",
    "\n",
    "        # Encode and pad the input sequences\n",
    "        trainY = dec_tokenizer.texts_to_sequences(train[:, 1])\n",
    "        trainY = pad_sequences(trainY, maxlen=dec_seq_length, padding='post')\n",
    "        trainY = convert_to_tensor(trainY, dtype=int64)\n",
    "\n",
    "        return (trainX, trainY, train, enc_seq_length, dec_seq_length,\n",
    "                enc_vocab_size, dec_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68762aa8-ac96-489f-904f-adaac7ca19df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68762aa8-ac96-489f-904f-adaac7ca19df",
    "outputId": "d15bc9ef-e902-456b-9af2-1e663a6a2308"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/glk9sq0x22qbdp2r6prn8h600000gn/T/ipykernel_7622/3322222027.py:24: ResourceWarning: unclosed file <_io.BufferedReader name='./english-german-both.pkl'>\n",
      "  clean_dataset = load(open(filename, 'rb'))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "2023-06-22 20:22:02.148581: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> well starve <EOS> \n",
      " tf.Tensor([   1   51 1055    2    0    0    0], shape=(7,), dtype=int64)\n",
      "Encoder sequence length: 7\n",
      "<START> wir werden verhungern <EOS> \n",
      " tf.Tensor([  1  13  72 479   2   0   0   0   0   0   0   0], shape=(12,), dtype=int64)\n",
      "Decoder sequence length: 12\n"
     ]
    }
   ],
   "source": [
    "dataset = PrepareDataset()\n",
    "trainX, trainY, train_orig, enc_seq_length, dec_seq_length, \\\n",
    "    enc_vocab_size, dec_vocab_size = dataset('./english-german-both.pkl')\n",
    "\n",
    "print(train_orig[0, 0], '\\n', trainX[0, :])\n",
    "print('Encoder sequence length:', enc_seq_length)\n",
    "print(train_orig[0, 1], '\\n', trainY[0, :])\n",
    "print('Decoder sequence length:', dec_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ba846-a888-4a57-ac52-16d37a391ff6",
   "metadata": {
    "id": "014ba846-a888-4a57-ac52-16d37a391ff6"
   },
   "source": [
    "---\n",
    "<a name='20.2'></a><a id='20.2'></a>\n",
    "# 20.2 Applying a Padding Mask\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6185de3-603c-49aa-97e7-6073791e02d0",
   "metadata": {
    "id": "e6185de3-603c-49aa-97e7-6073791e02d0"
   },
   "source": [
    "---\n",
    "<a name='20.3'></a><a id='20.3'></a>\n",
    "# 20.3 Training the Transformer Model\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa542d-45c0-486a-a37b-0db4ff86a237",
   "metadata": {
    "id": "4dfa542d-45c0-486a-a37b-0db4ff86a237"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "314d6fe5-609d-4072-a063-04406975d8eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "314d6fe5-609d-4072-a063-04406975d8eb",
    "outputId": "71474c54-1789-4828-b03f-26df039a0663"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/glk9sq0x22qbdp2r6prn8h600000gn/T/ipykernel_7622/3322222027.py:24: ResourceWarning: unclosed file <_io.BufferedReader name='english-german-both.pkl'>\n",
      "  clean_dataset = load(open(filename, 'rb'))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n",
      "Epoch 1 Step 0 Loss 8.3430 Accuracy 0.0000\n",
      "Epoch 1 Step 50 Loss 7.6061 Accuracy 0.1372\n",
      "Epoch 1 Step 100 Loss 7.0229 Accuracy 0.1783\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vb/glk9sq0x22qbdp2r6prn8h600000gn/T/ipykernel_7622/3007766211.py\u001b[0m in \u001b[0;36m<cell line: 116>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batchY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-3.8.12/env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-3.8.12/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-3.8.12/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-3.8.12/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-3.8.12/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Desktop/python-3.8.12/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-3.8.12/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the model parameters\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_model = 512  # Dimensionality of model layers' outputs\n",
    "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
    "n = 6  # Number of layers in the encoder stack\n",
    "\n",
    "# Define the training parameters\n",
    "\n",
    "if IS_COLAB:\n",
    "    epochs = 30\n",
    "else:\n",
    "    epochs = 2\n",
    "\n",
    "batch_size = 64\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.98\n",
    "epsilon = 1e-9\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Implementing a learning rate scheduler\n",
    "class LRScheduler(LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d_model = cast(d_model, float32)\n",
    "        self.warmup_steps = cast(warmup_steps, float32)\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        # Linearly increasing the learning rate for the first warmup_steps, and\n",
    "        # decreasing it thereafter\n",
    "        step_num = cast(step_num, float32)\n",
    "        arg1 = step_num ** -0.5\n",
    "        arg2 = step_num * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return (self.d_model ** -0.5) * math.minimum(arg1, arg2)\n",
    "\n",
    "# Instantiate an Adam optimizer\n",
    "optimizer = Adam(LRScheduler(d_model), beta_1, beta_2, epsilon)\n",
    "\n",
    "# Prepare the training and test splits of the dataset\n",
    "dataset = PrepareDataset()\n",
    "trainX, trainY, train_orig, enc_seq_length, dec_seq_length, \\\n",
    "    enc_vocab_size, dec_vocab_size = dataset('english-german-both.pkl')\n",
    "\n",
    "# Prepare the dataset batches\n",
    "train_dataset = data.Dataset.from_tensor_slices((trainX, trainY))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "# Create model\n",
    "training_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length,\n",
    "                                  dec_seq_length, h, d_k, d_v, d_model, d_ff, n,\n",
    "                                  dropout_rate)\n",
    "\n",
    "# Defining the loss function\n",
    "def loss_fcn(target, prediction):\n",
    "    # Create mask so that the zero padding values are not included in the\n",
    "    # computation of loss\n",
    "    mask = math.logical_not(equal(target, 0))\n",
    "    mask = cast(mask, float32)\n",
    "\n",
    "    # Compute a sparse categorical cross-entropy loss on the unmasked values\n",
    "    loss = sparse_categorical_crossentropy(target, prediction, from_logits=True) * mask\n",
    "\n",
    "    # Compute the mean loss over the unmasked values\n",
    "    return reduce_sum(loss) / reduce_sum(mask)\n",
    "\n",
    "# Defining the accuracy function\n",
    "def accuracy_fcn(target, prediction):\n",
    "    # Create mask so that the zero padding values are not included in the\n",
    "    # computation of accuracy\n",
    "    mask = math.logical_not(equal(target, 0))\n",
    "\n",
    "    # Find equal prediction and target values, and apply the padding mask\n",
    "    accuracy = equal(target, argmax(prediction, axis=2))\n",
    "    accuracy = math.logical_and(mask, accuracy)\n",
    "\n",
    "    # Cast the True/False values to 32-bit-precision floating-point numbers\n",
    "    mask = cast(mask, float32)\n",
    "    accuracy = cast(accuracy, float32)\n",
    "\n",
    "    # Compute the mean accuracy over the unmasked values\n",
    "    return reduce_sum(accuracy) / reduce_sum(mask)\n",
    "\n",
    "# Include metrics monitoring\n",
    "train_loss = Mean(name='train_loss')\n",
    "train_accuracy = Mean(name='train_accuracy')\n",
    "\n",
    "# Create a checkpoint object and manager to manage multiple checkpoints\n",
    "ckpt = train.Checkpoint(model=training_model, optimizer=optimizer)\n",
    "ckpt_manager = train.CheckpointManager(ckpt, \"./checkpoints\", max_to_keep=3)\n",
    "\n",
    "# Speeding up the training process\n",
    "@function\n",
    "def train_step(encoder_input, decoder_input, decoder_output):\n",
    "    with GradientTape() as tape:\n",
    "        # Run the forward pass of the model to generate a prediction\n",
    "        prediction = training_model(encoder_input, decoder_input, training=True)\n",
    "\n",
    "        # Compute the training loss\n",
    "        loss = loss_fcn(decoder_output, prediction)\n",
    "\n",
    "        # Compute the training accuracy\n",
    "        accuracy = accuracy_fcn(decoder_output, prediction)\n",
    "\n",
    "    # Retrieve gradients of the trainable variables with respect to the training loss\n",
    "    gradients = tape.gradient(loss, training_model.trainable_weights)\n",
    "\n",
    "    # Update the values of the trainable variables by gradient descent\n",
    "    optimizer.apply_gradients(zip(gradients, training_model.trainable_weights))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy)\n",
    "\n",
    "start_time = time()\n",
    "for epoch in range(epochs):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    print(\"\\nStart of epoch %d\" % (epoch + 1))\n",
    "\n",
    "    # Iterate over the dataset batches\n",
    "    for step, (train_batchX, train_batchY) in enumerate(train_dataset):\n",
    "        # Define the encoder and decoder inputs, and the decoder output\n",
    "        encoder_input = train_batchX[:, 1:]\n",
    "        decoder_input = train_batchY[:, :-1]\n",
    "        decoder_output = train_batchY[:, 1:]\n",
    "\n",
    "        train_step(encoder_input, decoder_input, decoder_output)\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1} Step {step} Loss {train_loss.result():.4f} \"\n",
    "                  + f\"Accuracy {train_accuracy.result():.4f}\")\n",
    "\n",
    "    # Print epoch number and loss value at the end of every epoch\n",
    "    print(f\"Epoch {epoch+1}: Training Loss {train_loss.result():.4f}, \"\n",
    "          + f\"Training Accuracy {train_accuracy.result():.4f}\")\n",
    "\n",
    "    # Save a checkpoint after every five epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        save_path = ckpt_manager.save()\n",
    "        print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
    "\n",
    "print(\"Total time taken: %.2fs\" % (time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
