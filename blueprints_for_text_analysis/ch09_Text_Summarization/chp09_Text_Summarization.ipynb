{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx4ik9G0T5v9"
   },
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 9: Text Summarization\n",
    "\n",
    "**Blueprints for Text Analysis Using Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkU3BQ1LYGWn"
   },
   "source": [
    "* [Introduction](#introduction)\n",
    "* [9.0 Imports and Setup](#9.0)\n",
    "* [9.1 Text Summarization](#9.1)\n",
    "    - [9.1.1 Extractive Methods](#9.1.1)\n",
    "    - [9.1.2 Data Preprocessing](#9.1.2)\n",
    "* [9.2 Blueprint: Summarizing Text Using Topic Representation](#9.2)\n",
    "    - [9.2.1 Identifying Important Words with TF-IDF Values](#9.2.1)\n",
    "    - [9.2.2 LSA Algorithm](#9.2.2)\n",
    "* [9.3 Blueprint: Summarizing Text Using an Indicator Representation](#9.3)\n",
    "* [9.4 Measuring the Performance of Text Summarization Methods](#9.4)\n",
    "* [9.5 Blueprint: Summarizing Text Using Machine Learning](#9.5)\n",
    "    - [9.5.1 Step 1: Creating Target Labels](#9.5.1)\n",
    "    - [9.5.2 Step 2: Adding Features to Assist Model Prediction](#9.5.2)\n",
    "    - [9.5.3 Step 3: Build a Machine Learning Model](#9.5.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2xUHHOuYGWr"
   },
   "source": [
    "---\n",
    "<a name='introduction'></a><a id='introduction'></a>\n",
    "# Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "### Dataset\n",
    "\n",
    "* acl2017.tex: [script](#acl2017.tex), [source](https://raw.githubusercontent.com/blueprints-for-text-analytics-python/blueprints-text/master/ch09/acl2017.tex)\n",
    "* predicting-the-next-u-s-recession-idUSKCN1V31JE: [script](#predicting-the-next-u-s-recession-idUSKCN1V31JE), [source](https://www.reuters.com/article/us-usa-economy-watchlist-graphic/predicting-the-next-u-s-recession-idUSKCN1V31JE)\n",
    "* travel_threads.csv.gz : [script](#travel_threads.csv.gz), [source](https://github.com/blueprints-for-text-analytics-python/blueprints-text/raw/master/data/travel-forum-threads/travel_threads.csv.gz)\n",
    "\n",
    "\n",
    "### Explore\n",
    "\n",
    "* Analyzing different types of text data.\n",
    "* Examine specific text data characteristics useful in determining the choice of summarization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXuYMAhxYGWt"
   },
   "source": [
    "---\n",
    "<a name='9.0'></a><a id='9.0'></a>\n",
    "# 9.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R2oYvKS5BGOM"
   },
   "outputs": [],
   "source": [
    "# Start with clean project\n",
    "!rm -f *.gz\n",
    "!rm -f *.py\n",
    "!rm -f *.txt\n",
    "!rm -fr articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GulFEtI9BGON"
   },
   "outputs": [],
   "source": [
    "!mkdir articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O2yQoLdVUCBy"
   },
   "outputs": [],
   "source": [
    "req_file = \"requirements_09.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZToiNYlDUCEb",
    "outputId": "8907252d-2278-4293-d010-c46e9958e115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements_09.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "isort\n",
    "rouge-score\n",
    "scikit-learn-intelex\n",
    "spacy\n",
    "sumy\n",
    "textacy\n",
    "textdistance\n",
    "tqdm\n",
    "watermark\n",
    "Wikipedia-API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12MjfAenUCG0",
    "outputId": "235cb193-faf6-4f56-976c-c4731cac8aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.4/208.4 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --upgrade --quiet -r {req_file}\n",
    "else:\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_B5kYM1YGWz",
    "outputId": "9ad1fd36-f344-4ce7-a235-25875613183d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing imports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imports.py\n",
    "# Place at top to patch scikit-learn algorithms\n",
    "from sklearnex import patch_sklearn # isort:skip\n",
    "patch_sklearn() # isort:skip\n",
    "\n",
    "import html\n",
    "import locale\n",
    "import os.path\n",
    "import pprint\n",
    "import random\n",
    "import re\n",
    "import reprlib\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import rouge_score\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import sumy\n",
    "import textacy\n",
    "import textdistance\n",
    "import wikipediaapi\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "from nltk import tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from spacy.tokenizer import Tokenizer as spacy_Tokenizer\n",
    "from spacy.util import (compile_infix_regex, compile_prefix_regex,\n",
    "                        compile_suffix_regex)\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.nlp.tokenizers import Tokenizer as sumy_Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.utils import get_stop_words\n",
    "from textacy.preprocessing import replace\n",
    "from tqdm import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQk0_JfXYGW1",
    "outputId": "151119cb-5a94-48dc-babf-264554991edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Place at top to patch scikit-learn algorithms\n",
      "from sklearnex import patch_sklearn # isort:skip\n",
      "patch_sklearn() # isort:skip\n",
      "\n",
      "import html\n",
      "import locale\n",
      "import os.path\n",
      "import pprint\n",
      "import random\n",
      "import re\n",
      "import reprlib\n",
      "import warnings\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import nltk\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import requests\n",
      "import rouge_score\n",
      "import seaborn as sns\n",
      "import spacy\n",
      "import sumy\n",
      "import textacy\n",
      "import textdistance\n",
      "import wikipediaapi\n",
      "from bs4 import BeautifulSoup\n",
      "from dateutil import parser\n",
      "from nltk import tokenize\n",
      "from rouge_score import rouge_scorer\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import GroupShuffleSplit\n",
      "from spacy.tokenizer import Tokenizer as spacy_Tokenizer\n",
      "from spacy.util import (compile_infix_regex, compile_prefix_regex,\n",
      "                        compile_suffix_regex)\n",
      "from sumy.nlp.stemmers import Stemmer\n",
      "from sumy.nlp.tokenizers import Tokenizer as sumy_Tokenizer\n",
      "from sumy.parsers.plaintext import PlaintextParser\n",
      "from sumy.summarizers.lsa import LsaSummarizer\n",
      "from sumy.summarizers.text_rank import TextRankSummarizer\n",
      "from sumy.utils import get_stop_words\n",
      "from textacy.preprocessing import replace\n",
      "from tqdm import tqdm\n",
      "from watermark import watermark\n"
     ]
    }
   ],
   "source": [
    "!isort imports.py\n",
    "!cat imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-IP1C14T5wG",
    "outputId": "38c5e741-50cc-4c1d-ab68-c33cf88ba6c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# Place at top to patch scikit-learn algorithms\n",
    "from sklearnex import patch_sklearn # isort:skip\n",
    "patch_sklearn() # isort:skip\n",
    "\n",
    "import html\n",
    "import locale\n",
    "import os.path\n",
    "import pprint\n",
    "import random\n",
    "import re\n",
    "import reprlib\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import rouge_score\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import sumy\n",
    "import textacy\n",
    "import textdistance\n",
    "import wikipediaapi\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "from nltk import tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from spacy.tokenizer import Tokenizer as spacy_Tokenizer\n",
    "from spacy.util import (compile_infix_regex, compile_prefix_regex,\n",
    "                        compile_suffix_regex)\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.nlp.tokenizers import Tokenizer as sumy_Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.utils import get_stop_words\n",
    "from textacy.preprocessing import replace\n",
    "from tqdm import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFasvLnkUeK6",
    "outputId": "b536334d-c3c9-4dbb-881a-1361da886f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.16\n",
      "IPython version      : 7.9.0\n",
      "\n",
      "Compiler    : GCC 9.4.0\n",
      "OS          : Linux\n",
      "Release     : 5.10.147+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 2\n",
      "Architecture: 64bit\n",
      "\n",
      "re          : 2.2.1\n",
      "spacy       : 3.5.1\n",
      "sys         : 3.9.16 (main, Dec  7 2022, 01:11:51) \n",
      "[GCC 9.4.0]\n",
      "textdistance: 4.5.0\n",
      "pandas      : 1.4.4\n",
      "wikipediaapi: (0, 5, 8)\n",
      "textacy     : 0.12.0\n",
      "numpy       : 1.22.4\n",
      "matplotlib  : 3.7.1\n",
      "sumy        : 0.11.0\n",
      "seaborn     : 0.12.2\n",
      "dateutil    : 2.8.2\n",
      "nltk        : 3.8.1\n",
      "rouge_score : 0.1.2\n",
      "requests    : 2.27.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "warnings.filterwarnings('ignore')\n",
    "BASE_DIR = '.'\n",
    "sns.set_style(\"darkgrid\")\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "LANGUAGE = \"english\"\n",
    "\n",
    "print(watermark(iversions=True, globals_=globals(),python=True, machine=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1sVfsBNYGW4",
    "outputId": "83ac7325-c2e8-468c-b576-a411033911db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloads\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w_je7kUeV-mf"
   },
   "outputs": [],
   "source": [
    "def regex_clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text) \n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rbCPL_NcT5wK"
   },
   "outputs": [],
   "source": [
    "def download_article(url):\n",
    "    # check if article already there\n",
    "    filename = url.split(\"/\")[-1] + \".html\"\n",
    "    if not os.path.isfile(filename):\n",
    "        r = requests.get(url)\n",
    "        with open(filename, \"w+\") as f:\n",
    "            f.write(r.text)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4tQV9F8bSXb"
   },
   "source": [
    "**Setting up parse_article for Beautiful Soup**\n",
    "\n",
    "* Right click on article element for 'Inspect Accessibility Properties'\n",
    "* Copy entry for DOMNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qV9TJXk6T5wK"
   },
   "outputs": [],
   "source": [
    "def parse_article(article_file):\n",
    "    print(f\"ARTICLE_FILE: {article_file}\")\n",
    "    HR()\n",
    "    with open(article_file, \"r\") as f:\n",
    "        html = f.read()\n",
    "    r = {}\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # r['id'] = soup.select_one(\"div.StandardArticle_inner-container\")['id']\n",
    "    r['url'] = soup.find(\"link\", {'rel': 'canonical'})['href']\n",
    "    r['headline'] = soup.h1.text\n",
    "    \n",
    "    #r['section'] = soup.select_one(\"div.ArticleHeader_channel a\").text\n",
    "    \n",
    "    r['text'] = soup.select_one(\"p.Paragraph-paragraph-2Bgue.ArticleBody-para-TD_9x\").text\n",
    "    # r['text'] = soup.select_one(\"div.StandardArticleBody_body\").text\n",
    "\n",
    "    r['authors'] = [a.text \n",
    "                    for a in soup.select(\"div.BylineBar_first-container.ArticleHeader_byline-bar\\\n",
    "                                          div.BylineBar_byline span\")]\n",
    "    r['time'] = soup.find(\"meta\", { 'property': \"og:article:published_time\"})['content']\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNhPIQ6gYGW8"
   },
   "source": [
    "<a name='9.1'></a><a id='9.1'></a>\n",
    "# 9.1 Text Summarization\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxja6OnHYGW9"
   },
   "source": [
    "<a name='9.1.1'></a><a id='9.1.1'></a>\n",
    "## 9.1.1 Extractive Methods\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "No source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqlJkDN0YGW9"
   },
   "source": [
    "<a name='9.1.2'></a><a id='9.1.2'></a>\n",
    "## 9.1.2 Data Preprocessing\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='news-sitemap'></a><a name='news-sitemap'></a>\n",
    "### Dataset: news-sitemap\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoCm5K37T5wL",
    "outputId": "2c209e17-3b20-496f-be34-3750120d7519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 365332 Mar 22 06:44 articles/what-is-5g-and-who-are-the-major-players-idUSKCN1GR1IN\n"
     ]
    }
   ],
   "source": [
    "r = reprlib.Repr()\n",
    "r.maxstring = 800\n",
    "article_dir = 'articles'\n",
    "\n",
    "article_name1 = \"what-is-5g-and-who-are-the-major-players-idUSKCN1GR1IN\"\n",
    "!wget -P {article_dir} -nc -q https://www.reuters.com/article/us-qualcomm-m-a-broadcom-5g/what-is-5g-and-who-are-the-major-players-idUSKCN1GR1IN\n",
    "!ls -l articles/{article_name1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCruaHHLXmoM",
    "outputId": "065c29d3-1b8d-4c06-a1ec-b3980b138a5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLE_FILE: articles/what-is-5g-and-who-are-the-major-players-idUSKCN1GR1IN\n",
      "----------------------------------------\n",
      "Article Published on '2018-03-15T11:37:01Z'\n",
      "\"LONDON/SAN FRANCISCO (Reuters) - U.S. President Donald Trump has blocked microchip maker Broadcom Ltd's AVGO.O $117 billion takeover of rival Qualcomm QCOM.O amid concerns that it would give China the upper hand in the next generation of mobile communications, or 5G.\"\n"
     ]
    }
   ],
   "source": [
    "article1 = parse_article(f\"{article_dir}/{article_name1}\")\n",
    "\n",
    "print ('Article Published on', r.repr(article1['time']))\n",
    "print (r.repr(article1['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEhjTmh3T5wM"
   },
   "source": [
    "---\n",
    "<a name='9.2'></a><a id='9.2'></a>\n",
    "# 9.2 Blueprint: Summarizing Text Using Topic Representation\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrqnGltJT5wN"
   },
   "source": [
    "<a name='9.2.1'></a><a id='9.2.1'></a>\n",
    "## 9.2.1 Identifying Important Words with TF-IDF Values\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "The simplest approach for summarizing text is to identify important sentences based on an aggregate of the TF-IDF values of the words in the sentence. \n",
    "\n",
    "Here, we apply the TF-IDF vectorization and then aggregate the values to a sentence level. We can generate a score for each sentence as a sum of the TF-IDF values for each word in that sentence. This means a sentence with a high score contains many important words, relative to other sentences in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ox5DmG5DT5wN"
   },
   "outputs": [],
   "source": [
    "sentences = tokenize.sent_tokenize(article1['text'])\n",
    "tfidfVectorizer = TfidfVectorizer()\n",
    "words_tfidf = tfidfVectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qschI6ARGfKV"
   },
   "source": [
    "Here, there are approximately 20 sentences in the article. We create a condensed summary that is only 10% of the size of the original article. We sum up the TF-IDF values for each sentence, and use ng.argsort to sort them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3eczfQG7T5wN",
    "outputId": "e09c796a-d3d3-4cf7-ca7d-3cc8ae41e47b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONDON/SAN FRANCISCO (Reuters) - U.S. President Donald Trump has blocked microchip maker Broadcom Ltd's AVGO.O $117 billion takeover of rival Qualcomm QCOM.O amid concerns that it would give China the upper hand in the next generation of mobile communications, or 5G.\n"
     ]
    }
   ],
   "source": [
    "# Parameter to specify number of summary sentences required\n",
    "num_summary_sentence = 3\n",
    "\n",
    "# Sort the sentences in descending order by the sum of TF-IDF values\n",
    "sent_sum = words_tfidf.sum(axis=1)\n",
    "important_sent = np.argsort(sent_sum, axis=0)[::-1]\n",
    "\n",
    "# Print three most important sentences in the order they appear in the article\n",
    "for i in range(0, len(sentences)):\n",
    "    if i in important_sent[:num_summary_sentence]:\n",
    "        print (sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "scjd8ehGT5wO"
   },
   "outputs": [],
   "source": [
    "def tfidf_summary(text, num_summary_sentence):\n",
    "    summary_sentence = []\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    tfidfVectorizer = TfidfVectorizer()\n",
    "    words_tfidf = tfidfVectorizer.fit_transform(sentences)\n",
    "    sentence_sum = words_tfidf.sum(axis=1)\n",
    "    important_sentences = np.argsort(sentence_sum, axis=0)[::-1]\n",
    "    for i in range(0, len(sentences)):\n",
    "        if i in important_sentences[:num_summary_sentence]:\n",
    "            summary_sentence.append(sentences[i])\n",
    "    return summary_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pPKWuycT5wO",
    "tags": []
   },
   "source": [
    "<a name='9.2.2'></a><a id='9.2.2'></a>\n",
    "## 9.2.2 LSA Algorithm\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "LSA is a general-purpose method used for topic modeling, document similarity, and other tasks. LSA assumes that words close in meaning will occur in the same documents. \n",
    "\n",
    "https://github.com/miso-belica/sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JK8AaJxbT5wP",
    "outputId": "60ec6f04-1755-4f73-bb2c-7a13e482dd7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONDON/SAN FRANCISCO (Reuters) - U.S. President Donald Trump has blocked microchip maker Broadcom Ltd's AVGO.O $117 billion takeover of rival Qualcomm QCOM.O amid concerns that it would give China the upper hand in the next generation of mobile communications, or 5G.\n"
     ]
    }
   ],
   "source": [
    "LANGUAGE = \"english\"\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "parser = PlaintextParser.from_string(article1['text'], sumy_Tokenizer(LANGUAGE))\n",
    "summarizer = LsaSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "for sentence in summarizer(parser.document, num_summary_sentence):\n",
    "    print (str(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UTShujjfT5wP"
   },
   "outputs": [],
   "source": [
    "def lsa_summary(text, num_summary_sentence):\n",
    "    summary_sentence = []\n",
    "    LANGUAGE = \"english\"\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "    parser = PlaintextParser.from_string(text, sumy_Tokenizer(LANGUAGE))\n",
    "    summarizer = LsaSummarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "    for sentence in summarizer(parser.document, num_summary_sentence):\n",
    "        summary_sentence.append(str(sentence))\n",
    "    return summary_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predicting-the-next-u-s-recession-idUSKCN1V31JE'></a><a name='predicting-the-next-u-s-recession-idUSKCN1V31JE'></a>\n",
    "### Dataset: predicting-the-next-u-s-recession-idUSKCN1V31JE\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmmbbRaxYGXB",
    "outputId": "ff4cdf2c-0f3a-422b-d207-c88cb464f5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 373066 Mar 22 06:44 articles/predicting-the-next-u-s-recession-idUSKCN1V31JE\n"
     ]
    }
   ],
   "source": [
    "article_name2 = 'predicting-the-next-u-s-recession-idUSKCN1V31JE'\n",
    "!wget -P {article_dir} -nc -q \"https://www.reuters.com/article/us-usa-economy-watchlist-graphic/predicting-the-next-u-s-recession-idUSKCN1V31JE\"\n",
    "!ls -l {article_dir}/{article_name2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNNVXo3iT5wQ",
    "outputId": "735b4b4b-fe14-40f4-e817-6fbbad2a638e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTICLE_FILE: articles/predicting-the-next-u-s-recession-idUSKCN1V31JE\n",
      "----------------------------------------\n",
      "Article Published '2018-03-15T11:37:01Z'\n",
      "----------------------------------------\n",
      "'NEW YORK A protracted trade war between China and the United States, the world’s largest economies, and a deteriorating global growth outlook has left investors apprehensive about the end to the longest expansion in American history.'\n"
     ]
    }
   ],
   "source": [
    "r.maxstring = 800\n",
    "article2 = parse_article(f\"{article_dir}/{article_name2}\")\n",
    "print ('Article Published', r.repr(article1['time']))\n",
    "HR()\n",
    "print (r.repr(article2['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "45e9T-Wm0NO2",
    "outputId": "ad7f255c-0451-4c48-dc5d-577b4f4e0c44"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'NEW YORK A protracted trade war between China and the United States, the world’s largest economies, and a deteriorating global growth outlook has left investors apprehensive about the end to the longest expansion in American history.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article2['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5kUXp__T5wQ",
    "outputId": "59286762-6b76-4df0-9d18-986f7cef172e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW YORK A protracted trade war between China and the United States, the world’s largest economies, and a deteriorating global growth outlook has left investors apprehensive about the end to the longest expansion in American history.\n"
     ]
    }
   ],
   "source": [
    "summary_sentence = tfidf_summary(article2['text'], num_summary_sentence)\n",
    "\n",
    "for sentence in summary_sentence:\n",
    "    print (sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRbH3vO8T5wR",
    "outputId": "7504fedc-3fa0-4e06-e28a-6f3514632906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW YORK A protracted trade war between China and the United States, the world’s largest economies, and a deteriorating global growth outlook has left investors apprehensive about the end to the longest expansion in American history.\n"
     ]
    }
   ],
   "source": [
    "summary_sentence = lsa_summary(article2['text'], num_summary_sentence)\n",
    "\n",
    "for sentence in summary_sentence:\n",
    "    print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vN6VK0gT5wR"
   },
   "source": [
    "---\n",
    "<a name='9.3'></a><a id='9.3'></a>\n",
    "# 9.3 Blueprint: Summarizing Text Using an Indicator Representation\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoTtDaXyT5wR",
    "outputId": "00d9ead9-d1fa-433b-ce84-c5bb3987e0bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW YORK A protracted trade war between China and the United States, the world’s largest economies, and a deteriorating global growth outlook has left investors apprehensive about the end to the longest expansion in American history.\n"
     ]
    }
   ],
   "source": [
    "parser = PlaintextParser.from_string(article2['text'], sumy_Tokenizer(LANGUAGE))\n",
    "summarizer = TextRankSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "for sentence in summarizer(parser.document, num_summary_sentence):\n",
    "    print (str(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "CWQUQhKgT5wR"
   },
   "outputs": [],
   "source": [
    "def textrank_summary(text, num_summary_sentence):\n",
    "    summary_sentence = []\n",
    "    LANGUAGE = \"english\"\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "    parser = PlaintextParser.from_string(text, sumy_Tokenizer(LANGUAGE))\n",
    "    summarizer = TextRankSummarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "    for sentence in summarizer(parser.document, num_summary_sentence):\n",
    "        summary_sentence.append(str(sentence))\n",
    "    return summary_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhPkZlj5T5wR",
    "outputId": "b0f4d6c1-bd85-4886-ca28-6786ae1f2008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONDON/SAN FRANCISCO (Reuters) - U.S. President Donald Trump has blocked microchip maker Broadcom Ltd's AVGO.O $117 billion takeover of rival Qualcomm QCOM.O amid concerns that it would give China the upper hand in the next generation of mobile communications, or 5G.\n"
     ]
    }
   ],
   "source": [
    "parser = PlaintextParser.from_string(article1['text'], sumy_Tokenizer(LANGUAGE))\n",
    "summarizer = TextRankSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "for sentence in summarizer(parser.document, num_summary_sentence):\n",
    "    print (str(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9Xv6jO4YT5wS"
   },
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jfO1ODdQT5wS"
   },
   "outputs": [],
   "source": [
    "r.maxstring = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OB_AYiWOT5wT",
    "outputId": "27d9766e-1ddf-49a5-830d-8721e26be753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'From the 1220s into the 1240s, the Mongols conquered the Turkic states of Volga Bulgaria, Cumania, Alania, and the Kievan Rus\\' federation. Following this, they began their invasion into heartland Europe by launching a two-pronged invasion of then...Citations\\nSources\\nSverdrup, Carl (2010). \"Numbers in Mongol Warfare\". Journal of Medieval Military History. Boydell Press. 8: 109–17 [p. 115]. ISBN 978-1-84383-596-7.\\n\\nFurther reading\\nExternal links\\nThe Islamic World to 1600: The Golden Horde'\n"
     ]
    }
   ],
   "source": [
    "p_wiki = wiki_wiki.page('Mongol_invasion_of_Europe')\n",
    "print (r.repr(p_wiki.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fifZzXl5T5wT",
    "outputId": "7ed05202-c622-4f42-dd4b-5124b5458a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warring European princes realized they had to cooperate in the face of a Mongol invasion, so local wars and conflicts were suspended in parts of central Europe, only to be resumed after the Mongols had withdrawn.\n",
      "Under Wenceslaus' leadership during the Mongol invasion, Bohemia remained one of a few eastern European kingdoms that was never pillaged by the Mongols even though most kingdoms around it such as Poland and Moravia were ravaged.\n",
      "Saint Margaret (January 27, 1242 – January 18, 1271), a daughter of Béla IV and Maria Laskarina, was born in Klis Fortress during the Mongol invasion of Hungary-Croatia in 1242.Historians estimate that up to half of Hungary's two million population at that time were victims of the Mongol invasion of Europe.\n",
      "European tactics against Mongols The traditional European method of warfare of melee combat between knights ended in catastrophe when it was deployed against the Mongol forces as the Mongols were able to keep a distance and advance with superior numbers.\n",
      "Austrian knights under Duke Frederick also fared better in fighting the Mongol invasion in Vienna.King Béla IV of Hungary hired the help of the Knights Hospitaller, as well as training his own better-armed local knights, in preparation for the Second Mongol invasion of Hungary.\n",
      "After the division of the Mongol Empire into four fragments, when the Golden Horde attempted the next invasion of Hungary, Hungary had increased their proportion of knights (led by Ladislaus IV of Hungary) and they quickly defeated the main Golden Horde Army in the hills of western Transylvania.By this time as well, many Eastern and Central European countries had ended their hostilities with one another and united to finally drive out the remnants of the Golden Horde.\n",
      "An analysis of tree rings there found that Hungary had cold wet weather in early 1242, which likely turned Hungary's central plain into a huge swamp; so, lacking pastures for their horses, the Mongols would have had to fall back to Rus' in search of better grasslands.Regardless of their reasons, the Mongols had completely withdrawn from Central Europe by mid-1242, though they still launched military operations in the west at this time, most notably the 1241–1243 Mongol invasion of Anatolia.\n",
      "They have sometimes been collectively referred to as \"the second Mongol invasion of Europe\", \"the second Tatar-Mongol invasion of central and south-eastern Europe\", or \"the second Mongol invasion of central Europe.\"\n",
      "In the siege of Caffa for example, when the Mongols under Janibeg besieged Caffa in Crimea, a relief force of an Genoese army came and defeated the Mongols, killing 15,000 of their troops and destroying their siege engines.\n",
      "Gallery See also Franco-Mongol alliance Lists of battles of the Mongol invasion of Europe List of battles of the Mongol invasion of Kievan Rus' Mongol invasions and conquests Mongol military tactics and organization Romania in the Early Middle Ages Timeline of the Golden Horde Timeline of the Mongol Empire War of the Heavenly Horses\n"
     ]
    }
   ],
   "source": [
    "r.maxstring = 200\n",
    "\n",
    "num_summary_sentence = 10\n",
    "\n",
    "summary_sentence = textrank_summary(p_wiki.text, num_summary_sentence)\n",
    "\n",
    "for sentence in summary_sentence:\n",
    "    print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='acl2017.tex'></a><a name='acl2017.tex'></a>\n",
    "### Dataset: acl2017.tex\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjIkaLBPiZPg",
    "outputId": "b93da2bf-9a13-4f06-d371-bb078064d1c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 56337 Mar 22 06:44 articles/acl2017.tex\n"
     ]
    }
   ],
   "source": [
    "filename = 'acl2017.tex'\n",
    "!wget -P {article_dir} -nc -q https://raw.githubusercontent.com/blueprints-for-text-analytics-python/blueprints-text/master/ch09/acl2017.tex\n",
    "!ls -l {article_dir}/{filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYFrBtDsT5wU",
    "outputId": "fdf86661-d0b4-433a-8bf8-de6fb3f51403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In more detail, our contributions are as follows: \\begin{itemize}[noitemsep] \\item{We introduce a new dataset for summarisation of scientific publications consisting of over 10k documents} \\item{Following the approach of \\cite{hermann2015teaching} in the news domain, we introduce a method, \\textit{HighlightROUGE}, which can be used to automatically extend this dataset %extractive summarisation datasets% and show empirically that this improves summarisation performance} \\item{Taking inspiration from previous work in summarising scientific literature \\citep{kupiec1995trainable, papers_citationSaggion2016}, we introduce a %further metric we use as a feature, \\textit{AbstractROUGE}, which can be used to extract summaries by exploiting the abstract of a paper} \\item{We benchmark several neural as well traditional summarisation methods on the dataset and use simple features to model the global context of a summary statement, which contribute most to the overall score} \\item{We compare our best performing system to several well-established baseline methods, some of which use more elaborate methods to model the global context than we do, and show that our best performing model outperforms them on this extractive summarisation task by a considerable margin} \\item{We analyse to what degree different sections in scientific papers contribute to a summary} \\end{itemize} We expect the research documented in this paper to be relevant beyond the document summarisation community, for other tasks in the space of automatically understand scientific publications, such as keyphrase extraction~\\cite{kim-EtAl:2010:SemEval,sterckx2016supervised,augenstein2017scienceie,augenstein2017multitask}, semantic relation extraction~\\cite{gupta-manning:2011:IJCNLP-2011,marsi-ozturk:2015:EMNLP} or topic classification of scientific articles~\\cite{oseaghdha-teufel:2014:Coling}.\n",
      "Therefore we assign sentences an integer location for 7 different sections: Highlight, Abstract, Introduction, Results / Discussion / Analysis, Method, Conclusion, all else.\\footnote{based on a small manually created gazetteer of alternative names} Location features have been used in other ways in previous work on summarising scientific literature; \\newcite{Visser2009} extract sentence location features based on the headings they occurred beneath while \\newcite{Teufel2002} divide the paper into 20 equal parts and assign each sentence a location based on which segment it occurred in - an attempt to capture distinct zones of the paper.\n",
      "\\paragraph{Single Feature Models} The simplest class of summarisers use a single feature from Section \\ref{sec:handcrafted_feats} (Sentence Length, Numeric Count and Section are excluded due to lack of granularity when sorting by these).% The sentences are sorted in descending order by the feature being used and the top $n$ sentences taken as the summary, then sorted back into the order they appear in in the paper.\n",
      "Word2Vec takes as input the sentence represented as an averaged word vector of 100 numbers.\\footnote{Word embeddings are obtained by training a Word2Vec skip-gram model on the 10000 papers with dimensionality 100, minimum word count 5, a context window of 20 words and downsample setting of 0.001} Word2VecAF takes the sentence average vector, abstract average vector and handcrafted features, giving a 208-dimensional vector for classification.\n",
      "Hence, although some sections are slightly more likely to contain good summary sentences, and assuming that we do not take summary sentences from the abstract which is already a summary, then Figure \\ref{fig:rouge_by_section} suggests that there is no definitive section from which summary sentences should be extracted.\n"
     ]
    }
   ],
   "source": [
    "parser = PlaintextParser.from_file(f\"{article_dir}/{filename}\", sumy.nlp.tokenizers.Tokenizer(LANGUAGE))\n",
    "summarizer = TextRankSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "for sentence in summarizer(parser.document, 5):\n",
    "    print (str(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZP_5Ae4EYGXK"
   },
   "source": [
    "---\n",
    "<a name='9.4'></a><a id='9.4'></a>\n",
    "# 9.4 Measuring the Performance of Text Summarization Methods\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VI7H8-gBT5wV"
   },
   "outputs": [],
   "source": [
    "def print_rouge_score(rouge_score):\n",
    "    for k,v in rouge_score.items():\n",
    "        print (k, 'Precision:', \"{:.2f}\".format(v.precision), 'Recall:', \"{:.2f}\".format(v.recall), 'fmeasure:', \"{:.2f}\".format(v.fmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gxqz4APkT5wV",
    "outputId": "8fbfc8de-b6b6-43c3-a7c9-1a797108f745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 Precision: 0.05 Recall: 0.33 fmeasure: 0.09\n"
     ]
    }
   ],
   "source": [
    "num_summary_sentence = 3\n",
    "gold_standard = article2['headline']\n",
    "summary = \"\"\n",
    "\n",
    "summary = ''.join(textrank_summary(article2['text'], num_summary_sentence))\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "scores = scorer.score(gold_standard, summary)\n",
    "print_rouge_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Obm8tOIT5wV",
    "outputId": "eaae4672-c8dc-46f6-88e0-00ba2480ea40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 Precision: 0.05 Recall: 0.33 fmeasure: 0.09\n"
     ]
    }
   ],
   "source": [
    "summary = ''.join(lsa_summary(article2['text'], num_summary_sentence))\n",
    "scores = scorer.score(gold_standard, summary)\n",
    "print_rouge_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZc0G6l-T5wW",
    "outputId": "5ba05bcb-056c-4f65-e1cd-95e0a7289ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge2 Precision: 0.10 Recall: 0.28 fmeasure: 0.15\n",
      "rougeL Precision: 0.11 Recall: 0.30 fmeasure: 0.16\n"
     ]
    }
   ],
   "source": [
    "num_summary_sentence = 10 ##\n",
    "gold_standard = p_wiki.summary\n",
    "\n",
    "summary = ''.join(textrank_summary(p_wiki.text, num_summary_sentence))\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge2','rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(gold_standard, summary)\n",
    "print_rouge_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1A3P7AaOT5wW",
    "outputId": "049e9a1b-01bc-40b3-cf80-b930ad2b763b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge2 Precision: 0.04 Recall: 0.09 fmeasure: 0.05\n",
      "rougeL Precision: 0.12 Recall: 0.26 fmeasure: 0.16\n"
     ]
    }
   ],
   "source": [
    "summary = ''.join(lsa_summary(p_wiki.text, num_summary_sentence))\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge2','rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(gold_standard, summary)\n",
    "print_rouge_score(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rfqjRScT5wX"
   },
   "source": [
    "---\n",
    "<a name='9.5'></a><a id='9.5'></a>\n",
    "# 9.5 Blueprint: Summarizing Text Using Machine Learning\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrGpUWhxT5wX"
   },
   "source": [
    "<a name='9.5.1'></a><a id='9.5.1'></a>\n",
    "## 9.5.1 Step 1: Creating target labels\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='travel_threads.csv.gz'></a><a name='travel_threads.csv.gz'></a>\n",
    "### Dataset: travel_threads.csv.gz\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WdUwuMwVPNV",
    "outputId": "090b12e2-6b99-4a3c-dd3e-3d64fb4cbdc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 1825254 Mar 22 06:44 travel_threads.csv.gz\n"
     ]
    }
   ],
   "source": [
    "file = \"travel_threads.csv.gz\"\n",
    "!wget -nc -q https://github.com/blueprints-for-text-analytics-python/blueprints-text/raw/master/data/travel-forum-threads/travel_threads.csv.gz\n",
    "!ls -l {file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "co61rar-T5wY",
    "outputId": "f712f724-9edd-4dfc-d5ac-83abd8ee8555"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ddcfb734-de34-4ad7-91c2-9c848615b84b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Filename</th>\n",
       "      <td>60763_5_3122150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThreadID</th>\n",
       "      <td>60763_5_3122150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>which attractions need to be pre booked?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userID</th>\n",
       "      <td>musicqueenLon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>29 September 2009, 1:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postNum</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>Hi    I am coming to NY in Oct! So excited&amp;quo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>A woman was planning to travel NYC in October ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddcfb734-de34-4ad7-91c2-9c848615b84b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ddcfb734-de34-4ad7-91c2-9c848615b84b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ddcfb734-de34-4ad7-91c2-9c848615b84b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                        850\n",
       "Filename                                    60763_5_3122150\n",
       "ThreadID                                    60763_5_3122150\n",
       "Title              which attractions need to be pre booked?\n",
       "userID                                     musicqueenLon...\n",
       "Date                                29 September 2009, 1:41\n",
       "postNum                                                   1\n",
       "text      Hi    I am coming to NY in Oct! So excited&quo...\n",
       "summary   A woman was planning to travel NYC in October ..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file, sep='|', dtype={'ThreadID': 'object'})\n",
    "df[df['ThreadID']=='60763_5_3122150'].head(1).T\n",
    "\n",
    "# You can view the actual post here ###\n",
    "# URL - https://www.tripadvisor.com/ShowTopic-g60763-i5-k3122150-Which_attractions_need_to_be_pre_booked-New_York_City_New_York.html ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxtOHfLwT5wZ",
    "outputId": "ca9e7915-a58c-46c3-b39f-f64e036bf2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Re-using the blueprint from Chapter 4 but adapting to add additional steps specific to this dataset\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    # use default patterns except the ones matched by re.search\n",
    "    prefixes = [pattern for pattern in nlp.Defaults.prefixes \n",
    "                if pattern not in ['-', '_', '#']]\n",
    "    suffixes = [pattern for pattern in nlp.Defaults.suffixes\n",
    "                if pattern not in ['_']]\n",
    "    infixes  = [pattern for pattern in nlp.Defaults.infixes\n",
    "                if not re.search(pattern, 'xx-xx')]\n",
    "\n",
    "    return spacy_Tokenizer(\n",
    "        vocab          = nlp.vocab, \n",
    "        rules          = nlp.Defaults.tokenizer_exceptions,\n",
    "        prefix_search  = compile_prefix_regex(prefixes).search,\n",
    "        suffix_search  = compile_suffix_regex(suffixes).search,\n",
    "        infix_finditer = compile_infix_regex(infixes).finditer,\n",
    "        token_match    = nlp.Defaults.token_match\n",
    "    )\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "n5viEyOom-cf"
   },
   "outputs": [],
   "source": [
    "def extract_lemmas(doc, **kwargs):\n",
    "    return [t.lemma_ for t in textacy.extract.words(doc, **kwargs)]\n",
    "\n",
    "def extract_noun_chunks(doc, include_pos=['NOUN'], sep='_'):\n",
    "    chunks = []\n",
    "    for noun_chunk in doc.noun_chunks:\n",
    "        chunk = [token.lemma_ for token in noun_chunk\n",
    "                 if token.pos_ in include_pos]\n",
    "        if len(chunk) >= 2:\n",
    "            chunks.append(sep.join(chunk))\n",
    "    return chunks\n",
    "\n",
    "def extract_entities(doc, include_types=None, sep='_'):\n",
    "\n",
    "    ents = textacy.extract.entities(doc, \n",
    "             include_types=include_types, \n",
    "             exclude_types=None, \n",
    "             drop_determiners=True, \n",
    "             min_freq=1)\n",
    "    \n",
    "    return [re.sub('\\s+', sep, e.lemma_)+'/'+e.label_ for e in ents]\n",
    "\n",
    "def clean(text):\n",
    "    # Replace URLs\n",
    "    text = replace.urls(text)\n",
    "    \n",
    "    # Replace semi-colons (relevant in Java code ending)\n",
    "    text = text.replace(';','')\n",
    "    \n",
    "    # Replace character tabs (present as literal in description field)\n",
    "    text = text.replace('\\t','')\n",
    "    \n",
    "    # Find and remove any stack traces - doesn't fix all code fragments but removes many exceptions\n",
    "    start_loc = text.find(\"Stack trace:\")\n",
    "    text = text[:start_loc]\n",
    "    \n",
    "    # Remove Hex Code\n",
    "    text = re.sub(r'(\\w+)0x\\w+', '', text)\n",
    "    \n",
    "    # Initialize Spacy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # From Blueprint function\n",
    "    lemmas = extract_lemmas(\n",
    "        doc, \n",
    "        exclude_pos = ['PART', 'PUNCT', 'DET', 'PRON', 'SYM', 'SPACE', 'NUM'],\n",
    "        filter_stops = True,\n",
    "        filter_nums = True,\n",
    "        filter_punct = True\n",
    "    )\n",
    "\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYlwE4jzT5wZ",
    "outputId": "6118efad-1fbf-4cdd-eeb9-56ee55e7b5d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 7357/7357 [00:01<00:00, 3875.83it/s]\n",
      "progress-bar: 100%|██████████| 7357/7357 [02:30<00:00, 48.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Applying regex based cleaning function\n",
    "df['text'] = df['text'].progress_apply(regex_clean)\n",
    "\n",
    "# Extracting lemmas using spacy pipeline\n",
    "df['lemmas'] = df['text'].progress_apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "JFsv4I-XT5wZ"
   },
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(\n",
    "    n_splits=1, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_split, test_split = next(\n",
    "    gss.split(\n",
    "        df, \n",
    "        groups=df['ThreadID']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obWI2GmHT5wa",
    "outputId": "4c1c2577-a620-497b-eea1-e0133cf49f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of threads for Training  559\n",
      "Number of threads for Testing  140\n"
     ]
    }
   ],
   "source": [
    "train_df = df.iloc[train_split]\n",
    "test_df = df.iloc[test_split]\n",
    "\n",
    "print ('Number of threads for Training ', train_df['ThreadID'].nunique())\n",
    "print ('Number of threads for Testing ', test_df['ThreadID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwqSpy6-T5wc",
    "outputId": "eb09825b-5434-4f80-cb67-8eb7357ef2c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 5858/5858 [00:01<00:00, 3192.10it/s]\n",
      "progress-bar: 100%|██████████| 559/559 [00:00<00:00, 4752.15it/s]\n"
     ]
    }
   ],
   "source": [
    "compression_factor = 0.3\n",
    "\n",
    "train_df['similarity'] = train_df.progress_apply(\n",
    "    lambda x: textdistance.jaro_winkler(x.text, x.summary), axis=1)\n",
    "\n",
    "train_df[\"rank\"] = train_df.groupby(\"ThreadID\")[\"similarity\"].rank(\n",
    "    \"max\", ascending=False)\n",
    "\n",
    "topN = lambda x: x <= np.ceil(compression_factor * x.max())\n",
    "train_df['summaryPost'] = train_df.groupby('ThreadID')['rank'].progress_apply(topN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "VWh-WfxDT5wc",
    "outputId": "7d6e3758-4045-4d0b-de0c-69614494ad12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-67704010-fde6-42d4-9695-b4c404eaabff\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summaryPost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>Hi I am coming to NY in Oct! So excited\" Have ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>I wouldnt bother doing the ESB if I was you TO...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>The Statue of Liberty, if you plan on going to...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67704010-fde6-42d4-9695-b4c404eaabff')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-67704010-fde6-42d4-9695-b4c404eaabff button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-67704010-fde6-42d4-9695-b4c404eaabff');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  text  summaryPost\n",
       "850  Hi I am coming to NY in Oct! So excited\" Have ...         True\n",
       "851  I wouldnt bother doing the ESB if I was you TO...        False\n",
       "852  The Statue of Liberty, if you plan on going to...         True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['text','summaryPost']][train_df['ThreadID']=='60763_5_3122150'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXLErCM0T5wc"
   },
   "source": [
    "<a name='9.5.2'></a><a id='9.5.2'></a>\n",
    "## 9.5.2 Step 2: Adding Features to Assist Model Prediction\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DX5elsJtT5wc",
    "outputId": "435c884d-1196-4922-a3b5-6c11d952d04d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 5858/5858 [00:00<00:00, 20053.86it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df['titleSimilarity'] = train_df.progress_apply(\n",
    "    lambda x: textdistance.jaro_winkler(x.text, x.Title), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "RWbGpkMET5we"
   },
   "outputs": [],
   "source": [
    "## Adding post length as a feature\n",
    "train_df['textLength'] = train_df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "3fKo5XylT5we"
   },
   "outputs": [],
   "source": [
    "train_df.loc[train_df['textLength'] <= 20, 'summaryPost'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "xlYPJ3JpT5we"
   },
   "outputs": [],
   "source": [
    "feature_cols = ['titleSimilarity','textLength','postNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "UzQqvWHET5we"
   },
   "outputs": [],
   "source": [
    "train_df['combined'] = [\n",
    "    ' '.join(map(str, l)) for l in train_df['lemmas'] if l is not '']\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=10, ngram_range=(1, 2), stop_words=\"english\")\n",
    "tfidf_result = tfidf.fit_transform(train_df['combined']).toarray()\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_result, columns=tfidf.get_feature_names_out())\n",
    "\n",
    "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
    "tfidf_df.index = train_df.index\n",
    "train_df_tf = pd.concat([train_df[feature_cols], tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsB84rAST5we",
    "outputId": "00ccc809-d825-4286-d024-b741544862e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 1499/1499 [00:00<00:00, 2928.39it/s]\n",
      "progress-bar: 100%|██████████| 140/140 [00:00<00:00, 4802.74it/s]\n",
      "progress-bar: 100%|██████████| 1499/1499 [00:00<00:00, 19654.45it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['similarity'] = test_df.progress_apply(lambda x: textdistance.jaro_winkler(x.text, x.summary), axis=1)\n",
    "test_df[\"rank\"] = test_df.groupby(\"ThreadID\")[\"similarity\"].rank(\"max\", ascending=False)\n",
    "\n",
    "topN = lambda x: x <= np.ceil(compression_factor * x.max())\n",
    "test_df['summaryPost'] = test_df.groupby('ThreadID')['rank'].progress_apply(topN)\n",
    "\n",
    "test_df['titleSimilarity'] = test_df.progress_apply(lambda x: textdistance.jaro_winkler(x.text, x.Title), axis=1)\n",
    "\n",
    "test_df['textLength'] = test_df['text'].str.len()\n",
    "\n",
    "test_df.loc[test_df['textLength'] <= 20, 'summaryPost'] = False\n",
    "\n",
    "test_df['combined'] = [' '.join(map(str, l)) for l in test_df['lemmas'] if l is not '']\n",
    "\n",
    "tfidf_result = tfidf.transform(test_df['combined']).toarray()\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names_out())\n",
    "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
    "tfidf_df.index = test_df.index\n",
    "test_df_tf = pd.concat([test_df[feature_cols], tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ofY2PJYT5we"
   },
   "source": [
    "<a name='9.5.3'></a><a id='9.5.3'></a>\n",
    "## 9.5.3 Step 3: Build a Machine Learning Model\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rqv6WfVbYGXZ"
   },
   "source": [
    "### API Notes\n",
    "\n",
    "[`sklearn.ensemble.RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "A random forest classifier.\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmAVoK9XT5wf",
    "outputId": "f21c99be-9736-4153-9e6a-dac5d954836a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 164 µs, sys: 0 ns, total: 164 µs\n",
      "Wall time: 170 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = RandomForestClassifier(\n",
    "    random_state=20,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "ktw3aqVnDXbA",
    "outputId": "e3e10dbc-ba62-4380-b677-e02a63540e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 40s, sys: 396 ms, total: 4min 40s\n",
      "Wall time: 4min 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=20, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=20, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=20, verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This takes a lot of time to run\n",
    "\n",
    "model1.fit(\n",
    "    train_df_tf, \n",
    "    train_df['summaryPost']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "VS-PyziMT5wf"
   },
   "outputs": [],
   "source": [
    "# Function to calculate rouge_score for each thread\n",
    "def calculate_rouge_score(x, column_name):\n",
    "    # Get the original summary - only first value since they are repeated\n",
    "    ref_summary = x['summary'].values[0]\n",
    "    \n",
    "    # Join all posts that have been predicted as summary\n",
    "    predicted_summary = ''.join(x['text'][x[column_name]])\n",
    "    \n",
    "    # Return the rouge score for each ThreadID\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(ref_summary, predicted_summary)\n",
    "    return scores['rouge1'].fmeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgohb9YDT5wg",
    "outputId": "9004cf05-4135-4e34-9086-79e620b6a383"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress-bar: 100%|██████████| 140/140 [00:01<00:00, 72.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROUGE-1 Score for test threads 0.3468526208505262\n",
      "CPU times: user 2.21 s, sys: 99.8 ms, total: 2.31 s\n",
      "Wall time: 2.37 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_df['predictedSummaryPost'] = model1.predict(test_df_tf)\n",
    "print('Mean ROUGE-1 Score for test threads',\n",
    "      test_df.groupby('ThreadID')[['summary','text','predictedSummaryPost']] \\\n",
    "      .progress_apply(calculate_rouge_score, column_name='predictedSummaryPost').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diSdDO6bT5wg",
    "outputId": "25086bfc-855f-480a-86ff-958c9d195055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 554 µs, sys: 1 ms, total: 1.56 ms\n",
      "Wall time: 1.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['60763_5_3139646']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "random.seed(2)\n",
    "random.sample(test_df['ThreadID'].unique().tolist(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Wdjro5klT5wh",
    "outputId": "f7c3f6a8-c563-4cff-b617-c03945fe0ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of posts 9\n",
      "Number of summary posts 2\n",
      "Title:  What's fun for kids?\n",
      "CPU times: user 3.99 ms, sys: 2.98 ms, total: 6.97 ms\n",
      "Wall time: 6.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-68827c9e-b051-4b00-97db-ed5a835e2475\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postNum</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>4</td>\n",
       "      <td>Well, you're really in luck, because there's a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>5</td>\n",
       "      <td>Depending on your time frame, a quick trip to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68827c9e-b051-4b00-97db-ed5a835e2475')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-68827c9e-b051-4b00-97db-ed5a835e2475 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-68827c9e-b051-4b00-97db-ed5a835e2475');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     postNum                                               text\n",
       "813        4  Well, you're really in luck, because there's a...\n",
       "814        5  Depending on your time frame, a quick trip to ..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "example_df = test_df[test_df['ThreadID'] == '60974_588_2180141']\n",
    "print('Total number of posts', example_df['postNum'].max())\n",
    "print('Number of summary posts',\n",
    "      example_df[example_df['predictedSummaryPost']].count().values[0])\n",
    "print('Title: ', example_df['Title'].values[0])\n",
    "example_df[['postNum', 'text']][example_df['predictedSummaryPost']]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
