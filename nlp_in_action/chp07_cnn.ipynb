{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ao8e59KhzlJy"
   },
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 7: Getting words in order with convolutional neural networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj6k4cfozlJ0"
   },
   "source": [
    "* [Introduction](#introduction)\n",
    "* [7.0 Imports and Setup](#7.0)\n",
    "* [7.1 Learning meaning](#7.1)\n",
    "* [7.2 Toolkit](#7.2)\n",
    "* [7.3 Convolutional neural nets](#7.3)\n",
    "    - [7.3.1 Building blocks](#7.3.1)\n",
    "    - [7.3.2 Step size (stride)](#7.3.2)\n",
    "    - [7.3.3 Filter composition](#7.3.3)\n",
    "    - [7.3.4 Padding](#7.3.4)\n",
    "    - [7.3.5 Learning](#7.3.5)\n",
    "* [7.4 Narrow windows indeed](#7.4)\n",
    "    - [7.4.1 Implementation in Keras: prepping the data](#7.4.1)\n",
    "    - [7.4.2 Convolutional neural network architecture](#7.4.2)\n",
    "    - [7.4.3 Pooling](#7.4.3)\n",
    "    - [7.4.4 Dropout](#7.4.4)\n",
    "    - [7.4.5 The cherry on the sundae](#7.4.5)\n",
    "    - [7.4.6 Let's get to learning (training)](#7.4.6)\n",
    "    - [7.4.7 Using the model in a pipeline](#7.4.7)\n",
    "    - [7.4.8 Where do you go from here?](#7.4.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiM83iGdzlJ2"
   },
   "source": [
    "---\n",
    "<a name='introduction'></a><a id='introduction'></a>\n",
    "# Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "### Datasets\n",
    "\n",
    "* aclImdb_v1.tar.gz: [script](#aclImdb_v1.tar.gz), [source](https://www.dropbox.com/s/yviic64qv84x73j/aclImdb_v1.tar.gz?dl=1)\n",
    "* GoogleNews-vectors-negative300.bin.gz: [script](#GoogleNews-vectors-negative300.bin.gz), [source](https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz)\n",
    "\n",
    "### Explore\n",
    "\n",
    "* Using neural networks for NLP\n",
    "* Finding meaning in word patterns\n",
    "* Building a CNN\n",
    "* Vectorizing natural language text in a way that suits neural networks\n",
    "* Training a CNN\n",
    "* Classifying the sentiment of novel text\n",
    "\n",
    "### Key points\n",
    "\n",
    "* A convolution is a window sliding over something larger (keeping the focus on a subset on the greater whole).\n",
    "* Neural networks can treat text just as they treat images and \"see\" them.\n",
    "* Handicapping the learning process with dropout actually helps.\n",
    "* Sentiment exists not only in the words but in the patterns that are used.\n",
    "* Neural networks have many knobs you can turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC4Wv0T8zlJ3"
   },
   "source": [
    "---\n",
    "<a name='7.0'></a><a id='7.0'></a>\n",
    "# 7.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('setup'):\n",
    "    os.mkdir('setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_file = \"setup/requirements_07.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup/requirements_07.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "isort\n",
    "scikit-learn-intelex\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --upgrade --quiet -r {req_file}\n",
    "else:\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "#if IS_COLAB:\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup/chp07_imports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup/chp07_imports.py\n",
    "import glob\n",
    "import locale\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import shlex\n",
    "import subprocess\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing /Users/gb/Desktop/examples/setup/chp07_imports.py\n",
      "import glob\n",
      "import locale\n",
      "import os\n",
      "import pprint\n",
      "import random\n",
      "import shlex\n",
      "import subprocess\n",
      "import warnings\n",
      "from pathlib import Path\n",
      "from random import shuffle\n",
      "\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import tensorflow as tf\n",
      "from gensim.models import KeyedVectors\n",
      "from nltk.tokenize import TreebankWordTokenizer\n",
      "from tensorflow.keras.layers import GRU\n",
      "from tensorflow.keras.layers import LSTM\n",
      "from tensorflow.keras.layers import Activation\n",
      "from tensorflow.keras.layers import Conv1D\n",
      "from tensorflow.keras.layers import Dense\n",
      "from tensorflow.keras.layers import Dropout\n",
      "from tensorflow.keras.layers import Flatten\n",
      "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.models import model_from_json\n",
      "from tqdm.auto import tqdm\n",
      "from watermark import watermark\n"
     ]
    }
   ],
   "source": [
    "!isort setup/chp07_imports.py --sl\n",
    "!cat setup/chp07_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import locale\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import shlex\n",
    "import subprocess\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.3)\n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "tensorflow: 2.9.3\n",
      "numpy     : 1.23.5\n",
      "sys       : 3.8.12 (default, Dec 13 2021, 20:17:08) \n",
      "[Clang 13.0.0 (clang-1300.0.29.3)]\n",
      "seaborn   : 0.12.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"darkgrid\")\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "random.seed(23)\n",
    "\n",
    "print(watermark(iversions=True,globals_=globals(),python=True,machine=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks1f3xCfzlJ7"
   },
   "source": [
    "---\n",
    "<a name='7.1'></a><a id='7.1'></a>\n",
    "# 7.1 Learning meaning\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How is semantic meaning learned from words?\n",
    "\n",
    "Idea: There are at least two important ways. One is via *word order*. The second is via *word proximity*. There relationships can be explored for patters in two ways, specially and temporally.\n",
    "\n",
    "Importance: In spatial relationships, we examine a statement as if written on page, where we look for relationships in the position of words. In a temporal relationship, we explore a statement as if spoken, where the words and letters become *time series* data. Spatial data is usually viewed through a fixed-width window. Time series data can extend for an unknown amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gb-ack9ZzlJ7"
   },
   "source": [
    "---\n",
    "<a name='7.2'></a><a id='7.2'></a>\n",
    "# 7.2 Toolkit\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How can we create neural nets at a high-level?\n",
    "\n",
    "Idea: There are several popular frameworks in Python, including Keras and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6sT7rGQzlJ8"
   },
   "source": [
    "---\n",
    "<a name='7.3'></a><a id='7.3'></a>\n",
    "# 7.3 Convolutional neural nets\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is the basic concept of *convolutional neural nets*?\n",
    "\n",
    "Idea: Slide (or convolve) a small window over the data sample. Convolutions appear in many places in mathematics, and they're usually related to time series data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4LaRTg8zlJ9"
   },
   "source": [
    "<a name='7.3.1'></a><a id='7.3.1'></a>\n",
    "## 7.3.1 Building blocks\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is the basic mechanism of CNNs?\n",
    "\n",
    "Idea: A CNN does not assign a weight to each element (eg an image pixel), as in a traditional feedforward net. Instead, it defines a set of filters (also called *kernels*) that move across the image. This is the *convolution*.\n",
    "\n",
    "Importance: This sliding/snapshot mechanism enables highly parallelizable neural networks. Each snapshot for a given data sample can be calculated independently of all the others for that given data sample. There is no need to wait for the first snapshot to happen before taking the second. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7aWVg7ozlJ-"
   },
   "source": [
    "<a name='7.3.2'></a><a id='7.3.2'></a>\n",
    "## 7.3.2 Step size (stride)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is the distance traveled during the sliding phase?\n",
    "\n",
    "Idea: This is called the *stride*, and usually set to 1. \n",
    "\n",
    "Importance: A stride value of 1 creates overlap in the various inputs to the filter from one position to the next. A larger stride that has no overlap between filter applications will lose the blurring effect of one pixel or token relating to its neighbors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7ky-r_ZzlJ-"
   },
   "source": [
    "<a name='7.3.3'></a><a id='7.3.3'></a>\n",
    "## 7.3.3 Filter composition\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is filter composition?\n",
    "\n",
    "Idea: A filtering neuron (as a set of weights) and an activation function are used to output a set of *feature maps*, which are new filtered images. For *n* filter, *n* new filtered images are returned. This is called a feature map because it is a mapping of where a certain kind of feature is found in the image. CNNs sesarch for  features such as lines, edges, objects, etc\n",
    "\n",
    "Importance: We capture the features in space of input patterns in via this mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYs9EcEvzlJ_"
   },
   "source": [
    "<a name='7.3.4'></a><a id='7.3.4'></a>\n",
    "## 7.3.4 Padding\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is padding?\n",
    "\n",
    "Idea: Padding referes to the amount of pixels added to an image when it is being processed by the kernel of a CNN. In Keras, `padding='valid'` results in no padding, hence no additional pixels are added. `padding='same'` results in the layer's outputs having the same spatial dimensions as its inputs, assuming a stride value of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTeLRnibzlKA"
   },
   "source": [
    "<a name='7.3.5'></a><a id='7.3.5'></a>\n",
    "## 7.3.5 Learning\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How does learning in CNN differ from a regular feedforward network?\n",
    "\n",
    "Idea: They are basically the same. Both calculate how much each particular weight contributes to the overall error of the system. Both then calculate how best to correct that error to a weight that will cause less error in future training examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Taqm5K_kzlKA"
   },
   "source": [
    "---\n",
    "<a name='7.4'></a><a id='7.4'></a>\n",
    "# 7.4 Narrow windows indeed\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How does CNN differ when used on images vs words?\n",
    "\n",
    "Idea: When used on CNN, it uses a 2D filter to convolve over a 2D picture input. When used on natural language processing, the input is word vectors (*word embeddings*), in a 1D dimension. Hence instead of a 2D filter, we use a 1D filter to focus on relationships of tokens in one spatial dimension. This is horizontal in the case of the English language. The CNN filter shape for words vectors will also be one-dimensional. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBpghrALzlKA"
   },
   "source": [
    "<a name='7.4.1'></a><a id='7.4.1'></a>\n",
    "## 7.4.1 Implementation in Keras: prepping the data\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How to preprocess NLP data for a CNN?\n",
    "\n",
    "Idea: Use Keras to tokenize and vectorizer the dataset, then create a train/test split\n",
    "\n",
    "Importance: This is often the most time-consuming and complex step of a machine-learning pipeline.\n",
    "\n",
    "**1. Download the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aclImdb_v1.tar.gz'></a><a name='aclImdb_v1.tar.gz'></a>\n",
    "### Dataset: aclImdb_v1.tar.gz\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aunnKpb7zlKB",
    "outputId": "6dc24dd7-d930-48d8-d0fb-bf17a52f76bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data_imdb_file:\taclImdb_v1.tar.gz\n",
      "data_imdb_url:\thttps://www.dropbox.com/s/yviic64qv84x73j/aclImdb_v1.tar.gz?dl=1\n",
      "data_imdb_dir:\tdata/data_imdb\n",
      "data_imdb_src:\tdata/data_imdb/aclImdb_v1.tar.gz\n",
      "data_imdb_path:\tdata/data_imdb/aclImdb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_imdb_file = \"aclImdb_v1.tar.gz\"\n",
    "data_imdb_url = f\"https://www.dropbox.com/s/yviic64qv84x73j/{data_imdb_file}?dl=1\"\n",
    "data_imdb_dir = Path(\"data/data_imdb\")\n",
    "data_imdb_src = data_imdb_dir / data_imdb_file\n",
    "data_imdb_path = data_imdb_dir / \"aclImdb\"\n",
    "\n",
    "print(f\"\"\"\n",
    "data_imdb_file:\\t{data_imdb_file}\n",
    "data_imdb_url:\\t{data_imdb_url}\n",
    "data_imdb_dir:\\t{data_imdb_dir}\n",
    "data_imdb_src:\\t{data_imdb_src}\n",
    "data_imdb_path:\\t{data_imdb_path}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLOFJXxVzlKC",
    "outputId": "b654a1e9-a546-402c-ca57-a2563aac35ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_imdb/aclImdb_v1.tar.gz exists.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_imdb_dir):\n",
    "    os.mkdir(data_imdb_dir)\n",
    "    \n",
    "if not data_imdb_src.is_file():\n",
    "    print(f\"Downloading {data_imdb_url} to {data_imdb_src}\")\n",
    "    subprocess.run(shlex.split(f\"wget -q -O {data_imdb_src} {data_imdb_url}\"))\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(f\"{data_imdb_src} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6l2IEN0zlKC",
    "outputId": "2a8e42bb-cf27-4fe5-d1e9-29623ba4c9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data_imdb/aclImdb exists\n"
     ]
    }
   ],
   "source": [
    "if not data_imdb_path.is_dir():\n",
    "    os.makedirs(data_imdb_path, exist_ok=True)\n",
    "    print(\"Extracting file\")\n",
    "    subprocess.run(shlex.split(f\"tar -xf {data_imdb_src} -C {data_imdb_path}\"))\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(f\"{data_imdb_path} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0rToLYC0VX-",
    "outputId": "f653c1c2-3f68-4228-daa6-34d850e8658b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50M\tdata/data_imdb/aclImdb/aclImdb/test/neg\n",
      " 50M\tdata/data_imdb/aclImdb/aclImdb/test/pos\n",
      "121M\tdata/data_imdb/aclImdb/aclImdb/test\n",
      " 50M\tdata/data_imdb/aclImdb/aclImdb/train/neg\n",
      "201M\tdata/data_imdb/aclImdb/aclImdb/train/unsup\n",
      " 50M\tdata/data_imdb/aclImdb/aclImdb/train/pos\n",
      "365M\tdata/data_imdb/aclImdb/aclImdb/train\n",
      "487M\tdata/data_imdb/aclImdb/aclImdb\n",
      "487M\tdata/data_imdb/aclImdb\n"
     ]
    }
   ],
   "source": [
    "!du -h {data_imdb_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GoogleNews-vectors-negative300.bin.gz'></a><a name='GoogleNews-vectors-negative300.bin.gz'></a>\n",
    "### Dataset: GoogleNews-vectors-negative300.bin.gz\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘data/data_word2vec/GoogleNews-vectors-negative300.bin.gz’ already there; not retrieving.\n",
      "total 3216888\n",
      "-rw-r--r--  1 gb  staff  1647046227 Mar 25 12:29 GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "data_gn_dir = 'data/data_word2vec'\n",
    "if not os.path.exists(data_gn_dir):\n",
    "    os.mkdir(data_gn_dir)\n",
    "\n",
    "data_gn_file = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "data_gn_path = f\"{data_gn_dir}/{data_gn_file}\"\n",
    "!wget -P {data_gn_dir} -O {data_gn_path} -nc \"https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz/GoogleNews-vectors-negative300.bin.gz?dl=1\"\n",
    "!ls -l {data_gn_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5G\tdata/data_word2vec/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "!du -h {data_gn_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH_LDjm2-trF"
   },
   "source": [
    "---\n",
    "Working with word vectors can be memory intensive. If your available memory is limited or if you don’t want to wait minutes for the word vector model to load, you can reduce the number of words loaded into memory by passing in the limit keyword argument. In the following example, you’ll load the 200k most common words from the Google News corpus.\n",
    "\n",
    "However, a word vector model with a limited vocabulary will lead to a lower performance of your NLP pipeline if your documents contain words that you haven’t loaded word vectors for. Therefore, you probably only want to limit the size of your word vector model during the development phase. For the rest of the examples in this chapter, you should use the complete Word2vec model if you want to get the same results we show here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GVLCdU4K1HdO"
   },
   "outputs": [],
   "source": [
    "# Constants for IMDB training data and Word2vec data\n",
    "TRAINING_DATA_N = 2_000 # ok: 1000, 2000 / 10_000 results in a crash\n",
    "\n",
    "# Possible values:\n",
    "# None\n",
    "# 200_000 most common words from the Google News corpus\n",
    "WORD_2_VEC_N = 200_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhHfm-jUzlKC"
   },
   "source": [
    "**2. Read and shuffle dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gfBlESKNzlKC"
   },
   "outputs": [],
   "source": [
    "def pre_process_data(filepath):\n",
    "    \"\"\"\n",
    "    This is dependent on your training data source but we will try to generalize it as best as possible.\n",
    "    \"\"\"\n",
    "    positive_path = os.path.join(filepath, 'pos')\n",
    "    negative_path = os.path.join(filepath, 'neg')    \n",
    "    pos_label = 1\n",
    "    neg_label = 0\n",
    "    \n",
    "    dataset = []\n",
    "    \n",
    "    for i, filename in enumerate(glob.glob(os.path.join(positive_path, '*.txt'))):\n",
    "        if i < TRAINING_DATA_N:\n",
    "            with open(filename, 'r') as f:\n",
    "                dataset.append((pos_label, f.read()))\n",
    "        else:\n",
    "            break\n",
    "                \n",
    "    for i, filename in enumerate(glob.glob(os.path.join(negative_path, '*.txt'))):\n",
    "        if i < TRAINING_DATA_N:\n",
    "            with open(filename, 'r') as f:\n",
    "                dataset.append((neg_label, f.read()))\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    shuffle(dataset)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQWY207X1xb3",
    "outputId": "cdbd6f17-8816-44d8-9256-c10f76222d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.26 s, sys: 352 ms, total: 4.61 s\n",
      "Wall time: 4.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load GoogleNews Word2Vec vocabulary\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\n",
    "    data_gn_path, \n",
    "    binary=True, \n",
    "    limit=WORD_2_VEC_N\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lLillxbj1xer"
   },
   "outputs": [],
   "source": [
    "# Listing 8.3 Data tokenizer + vectorizer\n",
    "# Tokenize and vectorize the IMDB dataset using the Google Word2vec model\n",
    "def tokenize_and_vectorize(dataset):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    vectorized_data = []\n",
    "    expected = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenizer.tokenize(sample[1])\n",
    "        sample_vecs = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                sample_vecs.append(word_vectors[token])\n",
    "\n",
    "            except KeyError:\n",
    "                pass  # No matching token in the Google w2v vocab\n",
    "            \n",
    "        vectorized_data.append(sample_vecs)\n",
    "\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeNxEi6G1xhX",
    "outputId": "233c752d-bdc8-4e8c-8a9f-04bdcb54ed89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05126953, -0.02233887, -0.17285156,  0.16113281, -0.08447266],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors[\"dog\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TEv5tySd1xj5"
   },
   "outputs": [],
   "source": [
    "# Target unzipper\n",
    "def collect_expected(dataset):\n",
    "    \"\"\"Peel off the target values from the dataset \"\"\"\n",
    "    expected = []\n",
    "    for sample in dataset:\n",
    "        expected.append(sample[0])\n",
    "    return expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MVz1AzD1xmX",
    "outputId": "18eb9ce8-1bac-4b81-c3cf-b7375b1a2663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50M\tdata/data_imdb/aclImdb/aclImdb/train/neg\n",
      "201M\tdata/data_imdb/aclImdb/aclImdb/train/unsup\n",
      " 50M\tdata/data_imdb/aclImdb/aclImdb/train/pos\n",
      "365M\tdata/data_imdb/aclImdb/aclImdb/train\n"
     ]
    }
   ],
   "source": [
    "!du -h {data_imdb_path}/aclImdb/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btNj8IPqzlKG"
   },
   "source": [
    "**3. Vectorize and tokenize datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PwyfzvD2PXZ",
    "outputId": "0495819d-e3c9-44e0-d8a3-eb19bb15c6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess training dataset\n",
      "Create vectorized data\n",
      "Preprocess target dataset\n",
      "CPU times: user 6.02 s, sys: 741 ms, total: 6.76 s\n",
      "Wall time: 8.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load and prepare the data\n",
    "print(\"Preprocess training dataset\")\n",
    "dataset = pre_process_data(f\"{data_imdb_path}/aclImdb/train\")\n",
    "\n",
    "print(\"Create vectorized data\")\n",
    "vectorized_data = tokenize_and_vectorize(dataset)\n",
    "\n",
    "print(\"Preprocess target dataset\")\n",
    "expected = collect_expected(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytA1YhA_2PaK",
    "outputId": "3c8093cc-002c-4f36-806b-4ef760aa25de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(vectorized_data))\n",
    "print(len(expected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTuzdrHMzlKJ"
   },
   "source": [
    "**4. Create train / test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fGSsqDazlKJ",
    "outputId": "79a5549e-2e1b-4f34-b7fa-346dafb6e567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "CPU times: user 999 µs, sys: 884 µs, total: 1.88 ms\n",
      "Wall time: 3.27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "split_point = int(len(vectorized_data)*.8)\n",
    "\n",
    "x_train = vectorized_data[:split_point]\n",
    "y_train = expected[:split_point]\n",
    "x_test = vectorized_data[split_point:]\n",
    "y_test = expected[split_point:]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rODqM5MTzlKJ",
    "outputId": "0c9de125-8ee8-4aa2-e066-afc86f6d691c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "----------------------------------------\n",
      "3200\n",
      "3200\n",
      "800\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "HR()\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ctIWVmAJzlKJ"
   },
   "outputs": [],
   "source": [
    "# Initialize your network parameters\n",
    "maxlen = 400\n",
    "batch_size = 32         # How many samples to show the net before backpropogating the error and updating the weights\n",
    "embedding_dims = 300    # Length of the token vectors we will create for passing into the Convnet\n",
    "filters = 250           # Number of filters we will train\n",
    "kernel_size = 3         # The width of the filters, actual filters will each be a matrix of weights of size: embedding_dims x kernel_size or 50 x 3 in our case\n",
    "hidden_dims = 250       # Number of neurons in the plain feed forward net at the end of the chain\n",
    "epochs = 5 # 10              # Number of times we will pass the entire training dataset through the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7pn4zPCzlKK"
   },
   "source": [
    "**5. Handle padding for CNN model**\n",
    "\n",
    "Each input to a CNN must be equal in dimension. Here we truncate any sample longer than 400 tokens, and pad shorter samples out to 400 tokens with Null or 0. We can also use \"PAD\" tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Y_bvNXP3zlKK"
   },
   "outputs": [],
   "source": [
    "# Must manually pad/truncate\n",
    "\n",
    "def pad_trunc(data, maxlen):\n",
    "    \"\"\" For a given dataset pad with zero vectors or truncate to maxlen \"\"\"\n",
    "    new_data = []\n",
    "\n",
    "    # Create a vector of 0's the length of our word vectors\n",
    "    zero_vector = []\n",
    "    for _ in range(len(data[0][0])):\n",
    "        zero_vector.append(0.0)\n",
    "\n",
    "    for sample in data:\n",
    " \n",
    "        if len(sample) > maxlen:\n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample) < maxlen:\n",
    "            temp = sample\n",
    "            additional_elems = maxlen - len(sample)\n",
    "            for _ in range(additional_elems):\n",
    "                temp.append(zero_vector)\n",
    "        else:\n",
    "            temp = sample\n",
    "        new_data.append(temp)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bL-a11gdzlKK"
   },
   "source": [
    "**6. Convert to numpy arrays**\n",
    "\n",
    "We want our dataset to have this shape:\n",
    "\n",
    "    x_train: (20000, 400, 300)\n",
    "    y_train: (20000,)\n",
    "    \n",
    "    x_test: (5000, 400, 300)\n",
    "    y_test: (5000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5DZdONSzlKL",
    "outputId": "30931f6b-28fd-4490-9f60-3051196c66a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/test split. This may require more time to complete.\n",
      "Done\n",
      "CPU times: user 102 ms, sys: 13.1 ms, total: 115 ms\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This may require a lot of memory and crash Colab.\n",
    "print(\"Creating train/test split. This may require more time to complete.\")\n",
    "x_train = pad_trunc(x_train, maxlen)\n",
    "x_test = pad_trunc(x_test, maxlen)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBVR0OeK34sC"
   },
   "source": [
    "**Note**\n",
    "\n",
    "Creating a huge Python list and then casting it to a Numpy array requires too much memory, and this crashes on Colab.\n",
    "\n",
    "One response to create a list small enough so it doesn't exceed available memory.\n",
    "\n",
    "Another is to create a numpy array without \"casting\" a list (or other iterable), by using one of the several methods defined by numpy itself that returns array:\n",
    "\n",
    "    np.empty, np.zeros, np.ones, np.full \n",
    "    \n",
    "These create arrays of given size with fixed values. However, the array size/shape must be known beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53EOqhLHzlKL",
    "outputId": "c6ce4a53-65b8-4cb9-ee71-49b19ef3b3a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping train/test split.\n",
      "Done\n",
      "CPU times: user 22.6 s, sys: 2.64 s, total: 25.2 s\n",
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Reshaping train/test split.\")\n",
    "x_train = np.reshape(x_train, (len(x_train), maxlen, embedding_dims))\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.reshape(x_test, (len(x_test), maxlen, embedding_dims))\n",
    "y_test = np.array(y_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mt5gddkSzlKM",
    "outputId": "7d91bcc8-5d6c-4853-dd97-698bcdd55380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "----------------------------------------\n",
      "x_train: (3200, 400, 300)\n",
      "y_train: (3200,)\n",
      "x_test: (800, 400, 300)\n",
      "y_test: (800,)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "HR()\n",
    "print(f\"x_train: {x_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"x_test: {x_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV15PmM-zlKM"
   },
   "source": [
    "<a name='7.4.2'></a><a id='7.4.2'></a>\n",
    "## 7.4.2 Convolutional neural network architecture\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What are the steps to create a CNN architecture?\n",
    "\n",
    "Idea: \n",
    "Use the Keras API for a Conv1D layer, which will learn filters:\n",
    "* Use the Keras API to add a convolutional layer via `keras.layers.Conv1D`. \n",
    "* Use an output of smaller dimension than the input via `padding='valid'`. \n",
    "* Each shift (stride) in the convolution will be one token via `strides=1`. \n",
    "* The kernel (window width) is set to 3 tokens via `kernel_size`. \n",
    "* Use the 'relu' activation function via `activation='relu'` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAeY3FCEzlKM",
    "outputId": "7b095c26-c5c6-4fb0-b3e4-67487a1e07e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "CPU times: user 92.6 ms, sys: 56.5 ms, total: 149 ms\n",
      "Wall time: 252 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 22:29:03.163499: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length\n",
    "model.add(\n",
    "    Conv1D(\n",
    "        filters,\n",
    "        kernel_size=kernel_size,\n",
    "        padding='valid',\n",
    "        activation='relu',\n",
    "        strides=1,\n",
    "        input_shape=(maxlen, embedding_dims)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dqtp0OC0zlKN"
   },
   "source": [
    "<a name='7.4.3'></a><a id='7.4.3'></a>\n",
    "## 7.4.3 Pooling\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How can we do dimensionality reduction in CNN?\n",
    "\n",
    "Idea: Use a pooling layer. We evenly divide the output of each filter into a subsection. Then for each of those subsections, select of compute a representative value. Then set the original output aside, and use the collections of representative values as the input to the next layers.\n",
    "\n",
    "Importance: We get dimensionality reduction and location invariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "S83EtnZuzlKN"
   },
   "outputs": [],
   "source": [
    "# Use max pooling\n",
    "model.add(GlobalMaxPooling1D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUbbln1nzlKO"
   },
   "source": [
    "<a name='7.4.4'></a><a id='7.4.4'></a>\n",
    "## 7.4.4 Dropout\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How can we help prevent overfitting?\n",
    "\n",
    "Idea: Use the Dropout layer. On each training pass, a certain percentage of the input is randomly \"turned off\", so the model is less likely to learn the specifics of the training set (overfitting), and instead learns more nuanced representations of the patterns in the data. \n",
    "\n",
    "Importance: Using a Dropout layer helps the model be able to generalize and make accurate predictions when making inferences on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "GKlujic0zlKO"
   },
   "outputs": [],
   "source": [
    "# Add a vanilla hidden layer\n",
    "model.add(Dense(hidden_dims))\n",
    "\n",
    "# Add a Dropout layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VeeZfEHzlKP"
   },
   "source": [
    "<a name='7.4.5'></a><a id='7.4.5'></a>\n",
    "## 7.4.5 The cherry on the sunday\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What to use for the last model layer?\n",
    "\n",
    "Idea: The last layer, or output layer, is the actual classifier. We need a neuron that fires based on the `sigmoid` activation function, which gives a value between 0 and 1. We project onto a single unit output layer and funnel the signal into a sigmoid activation fucntion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMFK6fPuzlKP",
    "outputId": "8600a991-5902-402c-8b6e-5e0f6d886abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 398, 250)          225250    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 250)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               62750     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 250)               0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 250)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 288,251\n",
      "Trainable params: 288,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Project onto a single unit output layer, and squash it with a sigmoid\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Use sigmoid used for binary classification\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79HgVvTRzlKP"
   },
   "source": [
    "<a name='7.4.6'></a><a id='7.4.6'></a>\n",
    "## 7.4.6 Let's get to learning (training)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: We need to actually train the model. We also want to save the model and be able to load it later.\n",
    "\n",
    "Idea: Use the `tf.kerad.Model` API:\n",
    " * Use `tf.keras.Model.fit()` to train the model for a fixed number of epochs (iterations on a dataset).\n",
    " * Use `tf.keras.models.save_model()` and `tf.keras.models.load_model()` to save and load a model in `tf` format.\n",
    " * Use `tf.keras.models.model_to_json()` and `tf.keras.models.model_from_json()` to save and load in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmikkFYhzlKP",
    "outputId": "abe17138-2d14-4afa-a750-e6a27f3a118c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 27s 247ms/step - loss: 0.5920 - accuracy: 0.6709 - val_loss: 0.4061 - val_accuracy: 0.8213\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.2938 - accuracy: 0.8816 - val_loss: 0.3886 - val_accuracy: 0.8250\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 0.1087 - accuracy: 0.9731 - val_loss: 0.4037 - val_accuracy: 0.8313\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.0281 - accuracy: 0.9975 - val_loss: 0.3992 - val_accuracy: 0.8425\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.8487\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Start model training\")\n",
    "\n",
    "hist = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "859DCoF64b2C",
    "outputId": "bc2ec5f9-dbcb-46f7-c9e5-2a9da8c0de33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8J2eOAZd6TWT",
    "outputId": "2f31c5c3-3ec4-4833-8389-d7c19739741f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5919910073280334, 0.29382237792015076, 0.10868116468191147, 0.0281315166503191, 0.007226124871522188]\n",
      "----------------------------------------\n",
      "[0.4061225950717926, 0.38862156867980957, 0.4036911129951477, 0.3992493450641632, 0.4351734519004822]\n",
      "----------------------------------------\n",
      "[0.6709374785423279, 0.8815624713897705, 0.9731249809265137, 0.9975000023841858, 1.0]\n",
      "----------------------------------------\n",
      "[0.8212500214576721, 0.824999988079071, 0.831250011920929, 0.8424999713897705, 0.8487499952316284]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['loss'])\n",
    "HR()\n",
    "print(hist.history['val_loss'])\n",
    "HR()\n",
    "print(hist.history['accuracy'])\n",
    "HR()\n",
    "print(hist.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "NGjAT9zM5Wqc",
    "outputId": "e66a4adf-b7d7-41d1-8601-3643c794a64a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(hist.history)\n",
    "df.plot(legend=True, grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZECY5QlzlKQ",
    "outputId": "bb4fa590-e0a6-4eb7-bb78-2b2caa3e6d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in json-format.\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_chp07/model_cnn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_chp07/model_cnn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in tf-format.\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/guide/keras/save_and_serialize#to_json_and_tfkerasmodelsmodel_from_json\n",
    "# Saving the architecture / configuration only, usually as a JSON file\n",
    "\n",
    "model_dir = \"models/model_chp07\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "model_structure = model.to_json()\n",
    "\n",
    "with open(f\"{model_dir}/cnn_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "\n",
    "model.save_weights(f\"{model_dir}/cnn_weights.h5\")\n",
    "print('Model saved in json-format.')\n",
    "\n",
    "HR()\n",
    "\n",
    "model.save(\n",
    "    f'{model_dir}/model_cnn', \n",
    "    overwrite=True,\n",
    "    save_format='tf'\n",
    ")\n",
    "print('Model saved in tf-format.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWvR6b2LzlKQ"
   },
   "source": [
    "<a name='7.4.7'></a><a id='7.4.7'></a>\n",
    "## 7.4.7 Using the model in a pipeline\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How to use a trained model?\n",
    "\n",
    "Idea: Pass a new, unseen sample. We reinstatiate our model, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pU_EjbiXzlKQ",
    "outputId": "b4ae5453-9627-4c1e-ff8a-9a68a64065e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstatiating json-format model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "print(\"Reinstatiating json-format model.\")\n",
    "# Load json-format model.\n",
    "with open(f\"{model_dir}/cnn_model.json\", \"r\") as json_file:\n",
    "    json_string = json_file.read()\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "model.load_weights(f'{model_dir}/cnn_weights.h5')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVxJKRI0zlKR",
    "outputId": "8d434e6c-35bf-41d0-dead-3ee504569a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinstatiating tf-format model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load tf-format model.\n",
    "print(\"Reinstatiating tf-format model.\")\n",
    "model2 = tf.keras.models.load_model(f'{model_dir}/model_cnn')\n",
    "model2\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "2GnC23EyzlKR"
   },
   "outputs": [],
   "source": [
    "sample_1 = \"\"\"I'm hate that the dismal weather that had me down for so long, \n",
    "when will it break! Ugh, when does happiness return?  \n",
    "The sun is blinding and the puffy clouds are too thin.  \n",
    "I can't wait for the weekend.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFHDobnZzlKR",
    "outputId": "ae8ccffd-e94b-4adc-c919-ee70f2a5fcd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07910156 -0.0050354   0.11181641  0.21289062  0.13085938]\n",
      "----------------------------------------\n",
      "(1, 400, 300)\n"
     ]
    }
   ],
   "source": [
    "# We pass a dummy value in the first element of the tuple just because our helper expects it from the way processed the initial data.  That value won't ever see the network, so it can be whatever.\n",
    "vec_list = tokenize_and_vectorize([(1, sample_1)])\n",
    "print(vec_list[0][0][:5])\n",
    "HR()\n",
    "\n",
    "# Tokenize returns a list of the data (length 1 here)\n",
    "test_vec_list = pad_trunc(vec_list, maxlen)\n",
    "test_vec = np.reshape(test_vec_list, (len(test_vec_list), maxlen, embedding_dims))\n",
    "print(test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Gmz3JsNL83ck"
   },
   "outputs": [],
   "source": [
    "# 0 = negative review, 1 = positive review\n",
    "sentiment_imdb = []\n",
    "sentiment_imdb.append('Negative Sentiment')\n",
    "sentiment_imdb.append('Positive Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "0jr1Q_G5zlKS",
    "outputId": "b3c8902c-da7d-4337-fb2a-6f7a4f6a0ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "[[0.00088994]]\n",
      "----------------------------------------\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative Sentiment'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1, saved as json format\n",
    "y_pred = model.predict(test_vec)\n",
    "print(y_pred)\n",
    "HR()\n",
    "\n",
    "# If model is binary classification, eg sigmoid last-layer activation\n",
    "res01 = (np.argmax(y_pred > 0.5))\n",
    "print(res01)\n",
    "sentiment_imdb[res01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "f2H7dAS0zlKS",
    "outputId": "112947bf-005e-4abb-c01e-124abe78c822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "[[0.00088994]]\n",
      "----------------------------------------\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative Sentiment'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2, saved in tf format\n",
    "y_pred2 = model2.predict(test_vec)\n",
    "print(y_pred)\n",
    "HR()\n",
    "\n",
    "res02 = (np.argmax(y_pred2 > 0.5))\n",
    "print(res02)\n",
    "sentiment_imdb[res02]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4oFXWx5zlKS"
   },
   "source": [
    "<a name='7.4.8'></a><a id='7.4.8'></a>\n",
    "## 7.4.8 Where do you go from here?\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is the potential of CNN for NLP classification tasks?\n",
    "\n",
    "Idea: We may be able to create richer models by stacking convolutional layers and pssing the output of the earlier filters as the \"image\" sample into the next set, and so on. We can also run the model with multiple size filters and concatenate the output of each size filter into a longer thought vector, before passing it into the feedforward network at the end, to provide more accurate results. Also, in general CNNs can perform without relying on rich word embeddings. Lastly, CNNs are very efficient."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
