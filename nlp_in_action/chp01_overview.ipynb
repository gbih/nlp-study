{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3b5d3d-4793-4838-a3d5-cbf41f92e226",
   "metadata": {},
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 1: Wordy machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e538a-4199-4175-9f9a-23bd7056a9d3",
   "metadata": {},
   "source": [
    "* [Introduction](#introduction)\n",
    "* [1.0 Packets of thought (NLP overview)](#1.0)\n",
    "* [1.1 Natural language vs programming language](#1.1)\n",
    "* [1.2 The magic](#1.2)\n",
    "    - [1.2.1 Machines that converse](#1.2.1)\n",
    "    - [1.2.2 The math](#1.2.2)\n",
    "* [1.3 Practical applications](1.3#)\n",
    "* [1.3 Language through a computer's \"eyes\"](#1.3)\n",
    "* [1.4 A brief overview of hyperspace](#1.4)\n",
    "    - [1.4.1 The language of locks](#1.4.1)\n",
    "* [1.5 A brief overflight of hyperspace](#1.5)\n",
    "* [1.6 Word order and grammer](#1.6)\n",
    "* [1.7 A chatbot natural language pipeline](#1.7)\n",
    "* [1.8 Processing in depth](#1.8)\n",
    "* [1.9 Natural language](#1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee28ada-c8a6-471a-abbd-fce8f585a681",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='introduction'></a><a id='introduction'></a>\n",
    "# Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "### Dataset\n",
    "\n",
    "* No real datasets\n",
    "\n",
    "### Explore\n",
    "\n",
    "* What natural language processing (NLP) is\n",
    "* Why NLP is hard and only recently has become widespread\n",
    "* When word order and grammar is important and when it can be ignored\n",
    "* How a chatbot combines many of the tools of NLP\n",
    "* How to use a regular expression to build the start of a tiny chatbot\n",
    "\n",
    "### Key points\n",
    "\n",
    "* NLP can be very useful\n",
    "* The meaning and intent of words can be deciphered by machines\n",
    "* A smart NLP pipeline will be able to deal with ambiguity\n",
    "* We can teach machines common sense knowledge without spending a lifetime training them\n",
    "* Chatbots can be thought of as semantic search engines\n",
    "* Regular expressions are useful for more than just search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8786e80-a8db-42f7-a6ee-c3ad2b4b7f44",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.0'></a><a id='1.0'></a>\n",
    "# 1.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638d97b9-8e19-4bb1-8a5e-c13a6e624a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('setup'):\n",
    "    os.mkdir('setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cf7f7e-94f4-440f-a2ea-cd0852f84d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_file = \"setup/requirements_01.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21a1dfb-b0b1-40f1-a421-5cce40983bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup/requirements_01.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "isort\n",
    "scikit-learn-intelex\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b098adc-187f-4ed3-9d2f-f4064ccd9590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --upgrade --quiet -r {req_file}\n",
    "else:\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfdd06c-f642-4663-a9d8-aa7fc0ffc414",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    from sklearnex import patch_sklearn\n",
    "    patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8605238b-5b0e-433e-8ec2-6a6bf0b57105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup/chp01_imports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup/chp01_imports.py\n",
    "import locale\n",
    "import pprint\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from itertools import permutations\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b0544a-adf0-4cc7-a878-c1818cf3a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import locale\n",
      "import pprint\n",
      "import random\n",
      "import re\n",
      "import warnings\n",
      "from collections import Counter\n",
      "from itertools import permutations\n",
      "\n",
      "import numpy as np\n",
      "import seaborn as sns\n",
      "from tqdm.auto import tqdm\n",
      "from watermark import watermark\n"
     ]
    }
   ],
   "source": [
    "!isort setup/chp01_imports.py\n",
    "!cat setup/chp01_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98313d21-9ffc-4357-bbba-945b84a6f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import pprint\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from itertools import permutations\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5ad894-ed09-4a58-aa4f-f800e8e8060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.3)\n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "seaborn: 0.12.1\n",
      "sys    : 3.8.12 (default, Dec 13 2021, 20:17:08) \n",
      "[Clang 13.0.0 (clang-1300.0.29.3)]\n",
      "numpy  : 1.23.5\n",
      "re     : 2.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"darkgrid\")\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "random.seed(23)\n",
    "\n",
    "print(watermark(iversions=True,globals_=globals(),python=True,machine=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7831b75-562b-4339-8de9-e3f1cfb8797b",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.1'></a><a id='1.1'></a>\n",
    "# 1.1 Natural language vs. programming language\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: Natural languages are not intended to be translated into a set of finite set of mathematical operations, like programming languages are.\n",
    "\n",
    "Idea: Create representations that enable mathematical and statistical operations on natural languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c6d1b-7ae0-414d-b611-5365846bf73f",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.2'></a><a id='1.2'></a>\n",
    "# 1.2 The magic\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: There is a massive amount of natural language text, so we need a way to automatically process it.\n",
    "\n",
    "Idea: Use programming languages and machines to enable processing natural language text in a scalable manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14587bcd-862e-404b-b637-0df211957033",
   "metadata": {},
   "source": [
    "<a name='1.2.1'></a><a id='1.2.1'></a>\n",
    "## 1.2.1 Machines that converse\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: Natural languages cannot be directly translated into a precise set of mathematical operations.\n",
    "    \n",
    "Idea: Text contains enough information and instructions that can be extracted. This information and instructions can be stored, indexed, searched or immediately used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf201d2b-8887-4d37-af0e-f9b712c1ee88",
   "metadata": {},
   "source": [
    "<a name='1.2.2'></a><a id='1.2.2'></a>\n",
    "## 1.2.2 The math\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: Processing natural languages to extract useful information entails tedious statistical bookkeeping.\n",
    "\n",
    "Idea: Use machines to systematically extract structured numerical data from text in the form of vectors. Then, use mathematical operations (especially from linear algebra) to find and build on statistical relationships between words, instead of a system of grammatical rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357b529-4bdc-497e-b539-6eab1c6df44f",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.3'></a><a id='1.3'></a>\n",
    "# 1.3 Practical applications\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What are some useful applications of NLP?\n",
    "\n",
    "Idea: Search, editing, dialog, writing, email, text mining, law, news, attribution, sentiment analysis, behaviour prediction, creative writing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace07e07-7214-4417-96e3-3bbf670ab57e",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.4'></a><a id='1.4'></a>\n",
    "# 1.4 Language through a computer's \"eyes\"\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How can a computer respond to text input?\n",
    "\n",
    "Idea: A primitive approach is to create a finite state machine (FSM), which contains a manually created nested tree of conditionals. This is a pattern-based approach to NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f22f3-5aa8-4f6f-a6a1-138eb3019081",
   "metadata": {},
   "source": [
    "<a name='1.4.1'></a><a id='1.4.1'></a>\n",
    "## 1.4.1 The language of locks\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How to better understand a simple language processing machine?\n",
    "\n",
    "Idea: Use the analogy of a mechanical lock and pattern matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7523230-236a-4145-bf29-2342b4b3db18",
   "metadata": {},
   "source": [
    "<a name='1.4.2'></a><a id='1.4.2'></a>\n",
    "## 1.4.2 Regular expression\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How do regular expressions operate?\n",
    "\n",
    "Idea: Regex use a special class of formal language grammar called a *regular grammar*. A machine that processes this kind of language is a formal mathematical object called a finite state machine (FSM). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51570e2e-6986-4f5f-8161-6bcfd8745744",
   "metadata": {},
   "source": [
    "<a name='1.4.3'></a><a id='1.4.3'></a>\n",
    "## 1.4.3 A simple chatbot\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How to create a pattern matching chatbot?\n",
    "\n",
    "Idea: Create a FSM regular expression that can speak a *regular language*, which here is the capability to respond to simple greetings. This is the pattern-based approach to NLP. The challenge of pattern-matching approaches to NLP is to create elegant patterns that capture what you want, without too many lines of regex code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d47e1600-8c2e-4156-815b-d93a3f7ca112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 10), match='Hello Rosa'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = \"(hi|hello|hey)[ ]*([a-z]*)\"\n",
    "re.match(r, 'Hello Rosa', flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5905b089-646a-47df-a4af-12fa50b8ee63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='hi ho'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r, \"hi ho, hi ho, it's off to work ...\", flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2843171d-718e-47f2-ab26-1f75489f2167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='hey'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r, \"hey, what's up\", flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0d8812-21eb-4cd6-a422-8e34f482739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed regex\n",
    "r = r\"[^a-z]*([y]o|[h']?ello|ok|hey|(good[ ])?(morn[gin']{0,3}|\"\\\n",
    "    r\"afternoon|even[gin']{0,3}))[\\s,;:]{1,3}([a-z]{1,20})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "616aa69f-18a8-46fa-a394-f6c5b9bfd8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_greeting = re.compile(r, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e11648-593b-4ceb-af79-c2bcc8a218b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 10), match='Hello Rosa'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_greeting.match('Hello Rosa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebff5727-99a0-4462-9602-23be2a1b3fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_greeting.match('Hi Rosa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62861b9e-9b57-4c13-b654-5bde1f560080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hello', None, None, 'Rosa')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_greeting.match('Hello Rosa').groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a669d70f-35ba-4335-b439-20835945398f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 17), match='Good morning Rosa'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_greeting.match(\"Good morning Rosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54ced168-aa73-49db-8b08-6a4de768884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_greeting.match(\"Good Manning Rosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e06ed88c-bf60-4d53-b6fe-d48500ff819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Good evening', 'Good ', 'evening', 'Rosa')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_greeting.match('Good evening Rosa Parks').groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36a1fca9-cd74-4264-a926-295de27e0e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 16), match=\"Good Morn'n Rosa\">"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_greeting.match(\"Good Morn'n Rosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5882883-055d-466a-bb72-794b6c684439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 7), match='yo Rosa'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_greeting.match(\"yo Rosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9b21981-5159-4754-bdfa-89f41c3aa148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Rosa, How are you?\n"
     ]
    }
   ],
   "source": [
    "# Add an output generator\n",
    "my_names = set(['rosa', 'rose', 'chatty', 'chatbot', 'bot', 'chatterbot'])\n",
    "\n",
    "curt_names = set(['hal', 'you', 'u'])\n",
    "greeter_name = ''\n",
    "\n",
    "# Manually assign input\n",
    "match = re_greeting.match(\"Hello Rosa\")\n",
    "\n",
    "if match:\n",
    "    at_name = match.groups()[-1]\n",
    "    # print(f\"at_name: {at_name}\")\n",
    "    if at_name in curt_names:\n",
    "        print(\"Good one.\")\n",
    "    elif at_name.lower() in my_names:\n",
    "        greeter_name = at_name\n",
    "        print(f\"Hi {greeter_name}, How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f418d1d2-57cb-4dc9-87e0-6b93bb053318",
   "metadata": {},
   "source": [
    "<a name='1.4.4'></a><a id='1.4.4'></a>\n",
    "## 1.4.4 Another way\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How to replace the fragile pattern-based approach?\n",
    "\n",
    "Idea: Use a statistical or machine-learning approach, in which we use vector representation of words.\n",
    "\n",
    "This enables the simple but powerful mechanism of measuring the difference or similarity in meaning between character sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0233f45d-6c7e-4b1e-99f3-9d3de0f33757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Guten': 1, 'Morgen': 1, 'Rosa': 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\"Guten Morgen Rosa\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0bcf92a-7e79-4242-b60c-20286ff619b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Good': 1, 'morning,': 1, 'Rosa!': 1})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\"Good morning, Rosa!\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aecbb3f-cd56-45f0-9fbf-c1b17eb5f09b",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.5'></a><a id='1.5'></a>\n",
    "# 1.5 A brief overflight of hyperspace\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How to constrain a huge amount of possible patterns into a manageable number?\n",
    "\n",
    "Idea: Create a reduced dimension vector space model of messages.\n",
    "\n",
    "This allows us to use labels vectors with a set of continuous float values. The list of dimensions should be much smaller than the number of possible statements. And statements that mean the same thing should have similar values. We can further simplify vectors by clustering statements together where appropriate. The simplest form of a vector space model is the \"one-hot encoded\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec540f4-05a5-4784-8cbd-ae6c44c776be",
   "metadata": {},
   "source": [
    "<a name='1.6'></a><a id='1.6'></a>\n",
    "# 1.6 Word order and grammar\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: Is word order important?\n",
    "\n",
    "Idea: For encoding the general sense and sentiment of a short sentence, it is not super important. But it is very important in longer sentences, which rely on word order to convey logical relationships between things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34f7f2c6-5469-4551-9eb2-e6d14358d9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good morning Rosa!',\n",
       " 'Good Rosa! morning',\n",
       " 'morning Good Rosa!',\n",
       " 'morning Rosa! Good',\n",
       " 'Rosa! Good morning',\n",
       " 'Rosa! morning Good']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent to factorial(3)\n",
    "[\" \".join(combo) for combo in permutations(\"Good morning Rosa!\".split(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7316eab7-8965-43e3-bcb6-45eab6b861cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\"\"Find textbooks with titles containing 'NLP', or 'natural' and 'language', or 'computations' and 'linguistics'.\"\"\"\n",
    "len(set(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3dfb66c-1557-4bf0-aeac-b13da3334a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479001600"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent to factorial(12)\n",
    "np.arange(1, 12 + 1).prod()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9678b5-66fc-4731-9e9a-e8dc2e6ec429",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.7'></a><a id='1.7'></a>\n",
    "# 1.7 A chatbot natural language pipeline\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is the mechanism necessary for a chatbot for processing and state management?\n",
    "\n",
    "Idea: We need stages for parsing, analyzing, generation, and execution. We also need a database to maintain a memory of past statements and responses. \n",
    "\n",
    "1. Parse: Extract features, structured numerical data, from natural language text.\n",
    "2. Analyze: Generate and combine features by scoring text for sentiment, grammaticality, and semantics.\n",
    "3. Generate: Compose possible responses using templates, search, or language models.\n",
    "4. Execute: Plan statements based on conversation history and objectives, and select the next response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbedf83-d79e-495b-8097-f810f23c1bdd",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.8'></a><a id='1.8'></a>\n",
    "# 1.8 Processing in depth\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How to conceptualize a NLP pipeline?\n",
    "\n",
    "Idea: Think of the stages of a NLP pipeline as layers in a feed-forward neural network. Deep learning is all about creating more complex models and behavior by adding additional processing layers. We add these layers to the standard two-layer machine learning model architecture of feature extraction and modeling.\n",
    "\n",
    "Misc: What is *inference*?\n",
    "\n",
    "Inferences are logical extrapolations from a set of conditions detected in the environment, like the logic contained in the statement of a chatbot user. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be56a8-1540-4e15-ae23-c38c04d56775",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='1.9'></a><a id='1.9'></a>\n",
    "# 1.9 Natural language IQ\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How to best measure the power of an NLP pipeline?\n",
    "\n",
    "Idea: Conceptualize this by measuring the breadth and depth of complexity (as two axis) of the NLP pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a48ece-c3b9-4934-91e3-6bca861b4cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
