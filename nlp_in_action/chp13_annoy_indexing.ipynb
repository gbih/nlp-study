{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 13: Advanced indexing with Annoy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introduction](#introduction)\n",
    "* [13.0 Imports and Setup](#13.0)\n",
    "* [13.2 Optimizing NLP algorithms](#13.2)\n",
    "    - [13.2.1 Indexing](#13.2.1)\n",
    "    - [13.2.2 Advanced Indexing](#13.2.2)\n",
    "    - [13.2.3 Advanced indexing with Annoy](#13.2.3)\n",
    "    - [13.2.4 Why use approximate indexes at all?](#13.2.4)\n",
    "    - [13.2.5 An indexing workaround: discretizing](#13.2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='introduction'></a><a id='introduction'></a>\n",
    "# Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "### Datasets\n",
    "\n",
    "* GoogleNews-vectors-negative300.bin.gz: [script](#GoogleNews-vectors-negative300.bin.gz), [source](https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='13.0'></a><a id='13.0'></a>\n",
    "# 13.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('setup'):\n",
    "    os.mkdir('setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_file = \"setup/requirements_13.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup/requirements_13.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "isort\n",
    "scikit-learn-intelex\n",
    "scrapy\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --upgrade --quiet -r {req_file}\n",
    "else:\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "#if IS_COLAB:\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup/chp13_imports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup/chp13_imports.py\n",
    "import locale\n",
    "import os\n",
    "import os.path\n",
    "import pprint\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from annoy import AnnoyIndex\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing /Users/gb/Desktop/examples/setup/chp13_imports.py\n",
      "import locale\n",
      "import os\n",
      "import os.path\n",
      "import pprint\n",
      "import random\n",
      "import sys\n",
      "import warnings\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "from annoy import AnnoyIndex\n",
      "from gensim.models import KeyedVectors\n",
      "from tqdm.auto import tqdm\n",
      "from watermark import watermark\n"
     ]
    }
   ],
   "source": [
    "!isort setup/chp13_imports.py --sl\n",
    "!cat setup/chp13_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import os\n",
    "import os.path\n",
    "import pprint\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from annoy import AnnoyIndex\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm.auto import tqdm\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.3)\n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "seaborn: 0.12.1\n",
      "numpy  : 1.23.5\n",
      "sys    : 3.8.12 (default, Dec 13 2021, 20:17:08) \n",
      "[Clang 13.0.0 (clang-1300.0.29.3)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"darkgrid\")\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(watermark(iversions=True,globals_=globals(),python=True,machine=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='13.2'></a><a id='13.2'></a>\n",
    "# 13.2 Optimizing NLP algorithms\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='13.2.1'></a><a id='13.2.1'></a>\n",
    "## 13.2.1 Indexing\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='13.2.2'></a><a id='13.2.2'></a>\n",
    "## 13.2.2 Advanced indexing\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='13.2.3'></a><a id='13.2.3'></a>\n",
    "## 13.2.3 Advanced indexing with Annoy\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GoogleNews-vectors-negative300.bin.gz'></a><a name='GoogleNews-vectors-negative300.bin.gz'></a>\n",
    "### Dataset: GoogleNews-vectors-negative300.bin.gz\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘data/data_word2vec/GoogleNews-vectors-negative300.bin.gz’ already there; not retrieving.\n",
      "1.5G\tdata/data_word2vec/GoogleNews-vectors-negative300.bin.gz\n",
      "CPU times: user 15.4 ms, sys: 24.2 ms, total: 39.6 ms\n",
      "Wall time: 516 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Download word2vec vectors\n",
    "data_gn_dir = 'data/data_word2vec'\n",
    "if not os.path.exists(data_gn_dir):\n",
    "    os.makedirs(data_gn_dir)\n",
    "\n",
    "data_gn_file = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "data_gn_path = f\"{data_gn_dir}/{data_gn_file}\"\n",
    "!wget -P {data_gn_dir} -O {data_gn_path} -nc \"https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz/GoogleNews-vectors-negative300.bin.gz?dl=1\"\n",
    "!du -h {data_gn_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model\n",
      "Done loading model.\n",
      "CPU times: user 1min 8s, sys: 5.33 s, total: 1min 14s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Loading word2vec model\")\n",
    "wv = KeyedVectors.load_word2vec_format(data_gn_path, binary=True)\n",
    "print(\"Done loading model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 3,000,000\n",
      "Columns: 300\n"
     ]
    }
   ],
   "source": [
    "# Get shape of word2vec vectors\n",
    "num_words, num_dimensions = wv.vectors.shape\n",
    "print(f\"Rows: {num_words:,}\")\n",
    "print(f\"Columns: {num_dimensions:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnnoyIndex is a class that provides functions for k-nearest neighbors search.\n",
    "\n",
    "`AnnoyIndex(f, metric)` returns a new index that's read-write and stores vector of f dimensions. Metric can be \"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\".\n",
    "\n",
    "Defaults to: 'angular'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate 300D AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64 µs, sys: 27 µs, total: 91 µs\n",
      "Wall time: 102 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create a new index that is read-write and stores vector of num_dimensions.\n",
    "index = AnnoyIndex(\n",
    "    num_dimensions, \n",
    "    'euclidean'\n",
    ")\n",
    "\n",
    "index.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add each word2vec vector to Annoy index\n",
    "\n",
    "    wv.index_to_key: Built-in mutable sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40eaeec7547a45b3b04da39462fa3e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: </s>\n",
      "100,000: distinctiveness\n",
      "200,000: barbiturate\n",
      "300,000: Sony_PS3\n",
      "400,000: Infiniti_FX\n",
      "500,000: Attorney_Bud_Cummins\n",
      "600,000: Giske\n",
      "700,000: f_***_er\n",
      "800,000: Shaw_Stockbroking_Ltd.\n",
      "900,000: HKSTP\n",
      "1,000,000: Starwood_Hotels_HOT\n",
      "1,100,000: McGrath_RentCorp_NASDAQ_MGRC\n",
      "1,200,000: Piveteau\n",
      "1,300,000: Rob_Pavey\n",
      "1,400,000: Giant_Octopus\n",
      "1,500,000: eur_UPM_Kymmene\n",
      "1,600,000: CSSL\n",
      "1,700,000: Lubina\n",
      "1,800,000: Ndian\n",
      "1,900,000: Cape_Solander\n",
      "2,000,000: Iordanis\n",
      "2,100,000: Allegiance_recitation\n",
      "2,200,000: brandy_soaked\n",
      "2,300,000: Coach_Kurt_Budke\n",
      "2,400,000: backcountry_hikers\n",
      "2,500,000: Brawn_BMW_Sauber\n",
      "2,600,000: cedar_juniper\n",
      "2,700,000: Wendy_Liberatore\n",
      "2,800,000: Management_GDCM\n",
      "2,900,000: BOARDED_UP\n",
      "----------------------------------------\n",
      "Done\n",
      "----------------------------------------\n",
      "CPU times: user 2min 16s, sys: 15.8 s, total: 2min 31s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i, word in enumerate(tqdm(wv.index_to_key)):\n",
    "    # Visual check\n",
    "    if not i % 100_000:\n",
    "        print(f\"{i:,}: {word}\") \n",
    "    index.add_item(i, wv[word])\n",
    "\n",
    "HR()\n",
    "print(\"Done\")\n",
    "HR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Euclidean distance index with 15 trees\n",
    "\n",
    "Next, this `AnnoyIndex` object reads through the entire index and clusters the vectors into chunks that can be indexed into a tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 trees for our 3,000,000 vectors.\n",
      "Building Euclidean distance indexing for 15 trees.\n",
      "Saving Annoy index file as annoy_euclidean_index.ann\n",
      "CPU times: user 5min 14s, sys: 49.5 s, total: 6min 3s\n",
      "Wall time: 2min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "annoy_euclidean_index_file = 'annoy_euclidean_index.ann'\n",
    "\n",
    "# hyperparameter\n",
    "num_trees = int(np.log(num_words).round(0))\n",
    "print(f\"{num_trees} trees for our {num_words:,} vectors.\")   \n",
    "\n",
    "print(f\"Building Euclidean distance indexing for {num_trees} trees.\")\n",
    "index.build(num_trees)\n",
    "\n",
    "# Build index on disk to enable indexing big datasets that won't fit into memory.\n",
    "print(f\"Saving Annoy index file as {annoy_euclidean_index_file}\")\n",
    "index.save(annoy_euclidean_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0G\tword2vec_index.ann\n"
     ]
    }
   ],
   "source": [
    "!du -h word2vec_index.ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 668 ms, sys: 2.67 s, total: 3.34 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2id = dict(zip(range(len(wv.key_to_index)), wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3,000,000'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{len(w2id):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(w2id):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look up words from our vocabulary in the AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9494"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Harry_Potter neighbors with AnnoyIndex\n",
    "wv.key_to_index['Harry_Potter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2990506"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look up number of times the Harry_Potter 20gram was mentioned in the GoogleNews corpus.\n",
    "wv.get_vecattr(\"Harry_Potter\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map similar to wv.key_to_index mapping the tokens to their index values (integer)\n",
    "w2id = dict(zip(wv.key_to_index, range(len(wv.key_to_index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9494"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2id['Harry_Potter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9494,\n",
       " 37681,\n",
       " 597774,\n",
       " 307186,\n",
       " 987327,\n",
       " 481759,\n",
       " 500570,\n",
       " 728042,\n",
       " 400305,\n",
       " 872473,\n",
       " 501614]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = index.get_nns_by_item(\n",
    "    w2id['Harry_Potter'], 11\n",
    ")\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 nearest neighbors listed by Annoy. \n",
    "\n",
    "This provides results from the general vicinity of a search term, rather than the closest 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry_Potter',\n",
       " 'JK_Rowling',\n",
       " 'Neville_Longbottom',\n",
       " 'muggle',\n",
       " 'Professor_Slughorn',\n",
       " 'Harry_Potter_Daniel_Radcliffe',\n",
       " 'Death_Eater',\n",
       " 'Hogwarts_headmaster_Albus_Dumbledore',\n",
       " 'Hogwart',\n",
       " 'Remus_Lupin',\n",
       " 'Lucius_Malfoy']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_euclidean = [wv.index_to_key[i] for i in ids]\n",
    "results_euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Harry_Potter neighbors with gensim.KeyedVectors index\n",
    "\n",
    "This looks more like a relevant top-10 synonym list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "CPU times: user 626 ms, sys: 43.5 ms, total: 669 ms\n",
      "Wall time: 375 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['JK_Rowling_Harry_Potter',\n",
       " 'JK_Rowling',\n",
       " 'boy_wizard',\n",
       " 'Deathly_Hallows',\n",
       " 'Half_Blood_Prince',\n",
       " 'Rowling',\n",
       " 'Actor_Rupert_Grint',\n",
       " 'HARRY_Potter',\n",
       " 'wizard_Harry_Potter',\n",
       " 'HARRY_POTTER']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Start\")\n",
    "results_gensim = [word for word, similarity in wv.most_similar('Harry_Potter', topn=10)]\n",
    "results_gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild the Annoy indexing approprimation to use the cosine distance metric.\n",
    "\n",
    "* Rebuild with cosine instead of Euclidean, and add more trees. \n",
    "* This should improve the accuracy of the nearest neighbors and make its results match gensim's more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82349b98b9f04711ad6f6d5acee1cc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: </s>\n",
      "100,000: distinctiveness\n",
      "200,000: barbiturate\n",
      "300,000: Sony_PS3\n",
      "400,000: Infiniti_FX\n",
      "500,000: Attorney_Bud_Cummins\n",
      "600,000: Giske\n",
      "700,000: f_***_er\n",
      "800,000: Shaw_Stockbroking_Ltd.\n",
      "900,000: HKSTP\n",
      "1,000,000: Starwood_Hotels_HOT\n",
      "1,100,000: McGrath_RentCorp_NASDAQ_MGRC\n",
      "1,200,000: Piveteau\n",
      "1,300,000: Rob_Pavey\n",
      "1,400,000: Giant_Octopus\n",
      "1,500,000: eur_UPM_Kymmene\n",
      "1,600,000: CSSL\n",
      "1,700,000: Lubina\n",
      "1,800,000: Ndian\n",
      "1,900,000: Cape_Solander\n",
      "2,000,000: Iordanis\n",
      "2,100,000: Allegiance_recitation\n",
      "2,200,000: brandy_soaked\n",
      "2,300,000: Coach_Kurt_Budke\n",
      "2,400,000: backcountry_hikers\n",
      "2,500,000: Brawn_BMW_Sauber\n",
      "2,600,000: cedar_juniper\n",
      "2,700,000: Wendy_Liberatore\n",
      "2,800,000: Management_GDCM\n",
      "2,900,000: BOARDED_UP\n",
      "----------------------------------------\n",
      "Done\n",
      "----------------------------------------\n",
      "CPU times: user 2min 25s, sys: 16.8 s, total: 2min 42s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Start\")\n",
    "\n",
    "index_cos = AnnoyIndex(\n",
    "    f=num_dimensions, \n",
    "    metric='angular'\n",
    ")\n",
    "\n",
    "for i, word in enumerate(tqdm(wv.index_to_key)):\n",
    "    # Visual check\n",
    "    if not i % 100_000:\n",
    "        print(f\"{i:,}: {word}\") \n",
    "    index_cos.add_item(i, wv[word])\n",
    "\n",
    "HR()\n",
    "print(\"Done\")\n",
    "HR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build twice the number of trees, with cosine distance index\n",
    "\n",
    "The indexing should take twice as long to run, but once it finished we can expect results closer to what gensim produces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "CPU times: user 15min 22s, sys: 1min 4s, total: 16min 27s\n",
      "Wall time: 5min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Start\")\n",
    "annoy_cos_index_file = 'annoy_cos_index.ann'\n",
    "\n",
    "index_cos.build(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "CPU times: user 775 ms, sys: 16.8 s, total: 17.6 s\n",
      "Wall time: 33.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Start\")\n",
    "index_cos.save(annoy_cos_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6G\tannoy_cos_index.ann\n"
     ]
    }
   ],
   "source": [
    "!du -h {annoy_cos_index_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harry_Potter neighbors in a cosine distance world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9494, 193309, 40544, 41526, 340510, 1038917, 14273, 165465, 337152, 1889661]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_cos = index_cos.get_nns_by_item(\n",
    "    w2id['Harry_Potter'], 10\n",
    ")\n",
    "\n",
    "ids_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry_Potter',\n",
       " 'JK_Rowling_Harry_Potter',\n",
       " 'Deathly_Hallows',\n",
       " 'Half_Blood_Prince',\n",
       " 'wizard_Harry_Potter',\n",
       " 'OotP',\n",
       " 'Twilight',\n",
       " 'Twilight_saga',\n",
       " 'Stephenie_Meyer_Twilight',\n",
       " 'Harry_Potter_Hermione_Granger']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cos = [wv.index_to_key[i] for i in ids_cos]\n",
    "results_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Top-10 Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annoy_gensim</th>\n",
       "      <th>annoy_euclidean_15</th>\n",
       "      <th>annoy_cosine_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JK_Rowling_Harry_Potter</td>\n",
       "      <td>Harry_Potter</td>\n",
       "      <td>Harry_Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JK_Rowling</td>\n",
       "      <td>JK_Rowling</td>\n",
       "      <td>JK_Rowling_Harry_Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boy_wizard</td>\n",
       "      <td>Neville_Longbottom</td>\n",
       "      <td>Deathly_Hallows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deathly_Hallows</td>\n",
       "      <td>muggle</td>\n",
       "      <td>Half_Blood_Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Half_Blood_Prince</td>\n",
       "      <td>Professor_Slughorn</td>\n",
       "      <td>wizard_Harry_Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rowling</td>\n",
       "      <td>Harry_Potter_Daniel_Radcliffe</td>\n",
       "      <td>OotP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Actor_Rupert_Grint</td>\n",
       "      <td>Death_Eater</td>\n",
       "      <td>Twilight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HARRY_Potter</td>\n",
       "      <td>Hogwarts_headmaster_Albus_Dumbledore</td>\n",
       "      <td>Twilight_saga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wizard_Harry_Potter</td>\n",
       "      <td>Hogwart</td>\n",
       "      <td>Stephenie_Meyer_Twilight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HARRY_POTTER</td>\n",
       "      <td>Remus_Lupin</td>\n",
       "      <td>Harry_Potter_Hermione_Granger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              annoy_gensim                    annoy_euclidean_15  \\\n",
       "0  JK_Rowling_Harry_Potter                          Harry_Potter   \n",
       "1               JK_Rowling                            JK_Rowling   \n",
       "2               boy_wizard                    Neville_Longbottom   \n",
       "3          Deathly_Hallows                                muggle   \n",
       "4        Half_Blood_Prince                    Professor_Slughorn   \n",
       "5                  Rowling         Harry_Potter_Daniel_Radcliffe   \n",
       "6       Actor_Rupert_Grint                           Death_Eater   \n",
       "7             HARRY_Potter  Hogwarts_headmaster_Albus_Dumbledore   \n",
       "8      wizard_Harry_Potter                               Hogwart   \n",
       "9             HARRY_POTTER                           Remus_Lupin   \n",
       "\n",
       "                 annoy_cosine_30  \n",
       "0                   Harry_Potter  \n",
       "1        JK_Rowling_Harry_Potter  \n",
       "2                Deathly_Hallows  \n",
       "3              Half_Blood_Prince  \n",
       "4            wizard_Harry_Potter  \n",
       "5                           OotP  \n",
       "6                       Twilight  \n",
       "7                  Twilight_saga  \n",
       "8       Stephenie_Meyer_Twilight  \n",
       "9  Harry_Potter_Hermione_Granger  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    list(\n",
    "        zip(\n",
    "            results_gensim, \n",
    "            results_euclidean, \n",
    "            results_cos\n",
    "        )\n",
    "    ), \n",
    "    columns =['annoy_gensim','annoy_euclidean_15', 'annoy_cosine_30'],\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='13.2.4'></a><a id='13.2.4'></a>\n",
    "## 13.2.4 Why use approximate indexes at all?\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='13.2.5'></a><a id='13.2.5'></a>\n",
    "## 13.2.5 An indexing workaround: discretizing\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
