{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d850a95-29a1-4948-9c7d-02b209f3a02b",
   "metadata": {
    "id": "3d850a95-29a1-4948-9c7d-02b209f3a02b"
   },
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 4: Finding meaning in word counts (semantic analysis)\n",
    "\n",
    "## 4.5 Latent Dirichlet allocation (LDiA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb858e-93ff-41c5-8e26-37c70bb0007c",
   "metadata": {
    "id": "d4fb858e-93ff-41c5-8e26-37c70bb0007c"
   },
   "source": [
    "* [Introduction](#introduction)\n",
    "* [4.0 Imports and Setup](#4.0)\n",
    "* [4.5 Latent Dirichlet allocation (LDA)](#4.5)\n",
    "    - [4.5.1 The LDiA idea](#4.5.1)\n",
    "    - [4.5.2 LDiA topic model for SMS message](#4.5.2)\n",
    "    - [4.5.3 LDiA + LDA = spam classifier](#4.5.3)\n",
    "    - [4.5.4 A fairer comparison: 32 LDiA topics](#4.5.4)\n",
    "* [4.6 Distance and similarity](#4.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9bf07-3035-4166-bbb7-d7ba2d2a67cf",
   "metadata": {
    "id": "7ee9bf07-3035-4166-bbb7-d7ba2d2a67cf"
   },
   "source": [
    "---\n",
    "<a name='introduction'></a><a id='introduction'></a>\n",
    "# Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "### Datasets\n",
    "\n",
    "* sms-spam.csv: [script](#sms-spam.csv), [source](https://github.com/totalgood/nlpia/raw/master/src/nlpia/data/sms-spam.csv)\n",
    "\n",
    "### Explore\n",
    "\n",
    "* Analyzing semantics (meaning) to create topic vectors\n",
    "* Semantic search using the similarity between topic vectors\n",
    "* Scalable semantic analysis and semantic search for large copora\n",
    "* Using semantic components (topics) as features in your NLP pipeline\n",
    "* Navigating high-dimensional vector spaces\n",
    "\n",
    "\n",
    "### Key points\n",
    "\n",
    "* You can use SVD for semantic analysis to decompose and transform TF-IDF\n",
    "* Use LDiA when you need to compute explainable topic vectors\n",
    "* No matter how you create your topic vectors, they can be used for semantic search to find documents based on their meaning\n",
    "* Topic vectors can be used to predict whether a social post is spam or is likely to be \"liked\"\n",
    "* We can sidestep the curse of dimensionality to approximate nearest neighbors in a semantic vector space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d418f-975f-497b-9a83-169fb911a0ad",
   "metadata": {
    "id": "e28d418f-975f-497b-9a83-169fb911a0ad"
   },
   "source": [
    "---\n",
    "<a name='4.0'></a><a id='4.0'></a>\n",
    "# 4.0 Imports and Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6227bd6-d034-4ad3-86d6-a07c5e78716b",
   "metadata": {
    "id": "b6227bd6-d034-4ad3-86d6-a07c5e78716b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('setup'):\n",
    "    os.mkdir('setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91127bef-d081-46d6-99cb-7203814d9a3b",
   "metadata": {
    "id": "91127bef-d081-46d6-99cb-7203814d9a3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "req_file = \"setup/requirements_04.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d86fec3-3bb5-4df9-8514-aac0e766bf30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d86fec3-3bb5-4df9-8514-aac0e766bf30",
    "outputId": "67a31a74-e64e-4e53-8f89-61243c65c125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup/requirements_04.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {req_file}\n",
    "isort\n",
    "plyfile\n",
    "scikit-learn-intelex\n",
    "scrapy\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0d752e-c897-4120-ae57-375257381a29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a0d752e-c897-4120-ae57-375257381a29",
    "outputId": "9fc4b4e2-c080-48ac-dab7-314552d14466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Installing packages\")\n",
    "    !pip install --upgrade --quiet -r {req_file}\n",
    "else:\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25f7609-7c51-4a72-86ca-6eccfffbf487",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    # On this script, this seems to crash local computer\n",
    "    from sklearnex import patch_sklearn\n",
    "    patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "827eff72-dcd3-4cc6-9d26-20d959dd8f0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "827eff72-dcd3-4cc6-9d26-20d959dd8f0e",
    "outputId": "a1b0bb53-7e3c-4597-a224-ea3fc6f5819d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup/chp04_4.5_imports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup/chp04_4.5_imports.py\n",
    "import locale\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import casual_tokenize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f41d56-423e-41b9-984f-00c5bb19ae10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00f41d56-423e-41b9-984f-00c5bb19ae10",
    "outputId": "1c4c865f-9a6f-4876-fe57-21206c52ad0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing /Users/gb/Desktop/examples/setup/chp04_4.5_imports.py\n",
      "import locale\n",
      "import os\n",
      "import random\n",
      "import warnings\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "from nltk.tokenize import casual_tokenize\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
      "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from watermark import watermark\n"
     ]
    }
   ],
   "source": [
    "!isort setup/chp04_4.5_imports.py --sl\n",
    "!cat setup/chp04_4.5_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8371a67-5f08-49e8-9c43-4d4e7613654c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8371a67-5f08-49e8-9c43-4d4e7613654c",
    "outputId": "a5b5891a-6e2e-47f6-8b50-a6f6b35f9686"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import casual_tokenize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from watermark import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8704e77a-43ea-48ea-9ba3-ce84b66c36f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8704e77a-43ea-48ea-9ba3-ce84b66c36f4",
    "outputId": "ea102bf0-3c88-4d5c-e475-2b54c0b9e3a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.3)\n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "pandas : 1.5.3\n",
      "sys    : 3.8.12 (default, Dec 13 2021, 20:17:08) \n",
      "[Clang 13.0.0 (clang-1300.0.29.3)]\n",
      "numpy  : 1.23.5\n",
      "seaborn: 0.12.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = getpreferredencoding\n",
    "warnings.filterwarnings('ignore')\n",
    "np.seterr(invalid='warn')\n",
    "sns.set_style(\"darkgrid\")\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(watermark(iversions=True,globals_=globals(),python=True,machine=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a30808-ac33-4797-852b-be553a038a60",
   "metadata": {
    "id": "54a30808-ac33-4797-852b-be553a038a60"
   },
   "source": [
    "---\n",
    "<a name='4.5'></a><a id='4.5'></a>\n",
    "# 4.5 Latent Dirichlet allocation (LDiA)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is the Latent Dirichlet Allocation (LDiA) model?\n",
    " \n",
    "Idea: It is a generative probabilistic model for collections of discrete dataset such as text corpora. It is also a topic model used for discovering abstract topics from a collection of documents.\n",
    "\n",
    "Importance: LDiA can give better results than LSA in certain situations. LDiA topic models can be easier to understand than LSAs because the words assigned to topics and topics assigned to documents tend to make more sense thant LSAs. In general, LSA focus on reducing matrix dimension, while LDiA solves topic modeling problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17e3cc-626f-4f4d-b2c6-da04b9316502",
   "metadata": {
    "id": "2d17e3cc-626f-4f4d-b2c6-da04b9316502"
   },
   "source": [
    "<a name='4.5.1'></a><a id='4.5.1'></a>\n",
    "## 4.5.1 The LDiA idea\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: What is the core concept of LDiA?\n",
    "\n",
    "Idea: It is a generative statistical model that explains a set of observations through unobserved groups, and each group explains why some parts of the data are similar. Observations (eg words) are collected into documents, and each word's presence is attributable to one of the document's topics. Each document will contain a small number of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb555a7a-ce5b-40e9-a947-8322a372d88e",
   "metadata": {},
   "source": [
    "<a id='sms-spam.csv'></a><a name='sms-spam.csv'></a>\n",
    "### Dataset: sms-spam.csv\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfd34b0-3318-48ca-8ada-3cddbfeb1030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘data/data_sms_spam/sms-spam.csv’ already there; not retrieving.\n",
      "\n",
      "-rw-r--r--  1 gb  staff  493232 Mar 25 11:17 data/data_sms_spam/sms-spam.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam                                               text\n",
       "sms0      0  Go until jurong point, crazy.. Available only ...\n",
       "sms1      0                      Ok lar... Joking wif u oni...\n",
       "sms2!     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "sms3      0  U dun say so early hor... U c already then say...\n",
       "sms4      0  Nah I don't think he goes to usf, he lives aro...\n",
       "sms5!     1  FreeMsg Hey there darling it's been 3 week's n..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'data/data_sms_spam'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "data_sms_spam = f\"{data_dir}/sms-spam.csv\"\n",
    "!wget -P {data_dir} -nc https://github.com/totalgood/nlpia/raw/master/src/nlpia/data/sms-spam.csv\n",
    "!ls -l {data_sms_spam}\n",
    "\n",
    "sms = pd.read_csv(data_sms_spam, index_col=0)\n",
    "\n",
    "# https://github.com/totalgood/nlpia/blob/master/src/nlpia/book/examples/ch04.rst\n",
    "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]  # <1>\n",
    "sms = pd.DataFrame(sms.values, columns=sms.columns, index=index)\n",
    "sms.spam = sms.spam.astype(int)\n",
    "sms.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b8d647-9d35-4540-b28e-13187a4aa2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4837, 9232)\n",
      "638\n"
     ]
    }
   ],
   "source": [
    "# Calculate the TF-IDF vectors for each of these messages.\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()\n",
    "tfidf_docs = pd.DataFrame(tfidf_docs, index=index)\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()\n",
    "\n",
    "print(tfidf_docs.shape)\n",
    "print(sms.spam.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6249ddae-f086-4688-9942-a8019eeff7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.53 s, sys: 702 ms, total: 7.23 s\n",
      "Wall time: 3.98 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['topic0',\n",
       " 'topic1',\n",
       " 'topic2',\n",
       " 'topic3',\n",
       " 'topic4',\n",
       " 'topic5',\n",
       " 'topic6',\n",
       " 'topic7',\n",
       " 'topic8',\n",
       " 'topic9',\n",
       " 'topic10',\n",
       " 'topic11',\n",
       " 'topic12',\n",
       " 'topic13',\n",
       " 'topic14',\n",
       " 'topic15']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Using sklearnex on PCA seems to cause an error.\n",
    "\n",
    "# Specify 16-D vectors\n",
    "pca = PCA(n_components=16)\n",
    "\n",
    "pca = pca.fit(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "\n",
    "# Create DataFrame for more convenience\n",
    "columns = ['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2798fad1-8cda-453b-abc0-e4997657715f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2798fad1-8cda-453b-abc0-e4997657715f",
    "outputId": "87aa431b-a55a-4d51-bd69-cc768a35dfb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_corpus_len = 0\n",
    "for document_text in sms.text:\n",
    "    total_corpus_len += len(casual_tokenize(document_text))\n",
    "\n",
    "mean_document_len = total_corpus_len / len(sms)\n",
    "round(mean_document_len, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff25d0e-5f3f-4d2e-bea3-65008a07bc5e",
   "metadata": {
    "id": "5ff25d0e-5f3f-4d2e-bea3-65008a07bc5e"
   },
   "source": [
    "<a name='4.5.2'></a><a id='4.5.2'></a>\n",
    "## 4.5.2 LDiA topic model for SMS messages\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: How does LDiA treat topics?\n",
    "\n",
    "Idea: The topics produced by LDiA tend to be more understandable and \"explainable\". This is because words that frequently occur together are assigned the same topic. Where LSA (PCA) tries to keep things spread apart that were spread apart to start with, LDiA tries to keep things close together that started out close together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77a8e88d-dab2-48ec-b6e1-d15491f08336",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77a8e88d-dab2-48ec-b6e1-d15491f08336",
    "outputId": "30c85d99-9209-4709-b756-645cf428f304"
   },
   "outputs": [],
   "source": [
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=sms.text).toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(), counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dc3f1a8-1dd4-462e-a64a-9b4b543be290",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "4dc3f1a8-1dd4-462e-a64a-9b4b543be290",
    "outputId": "08523817-bfe0-4b26-9701-2692f9bcb8a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.loc['sms0'].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c1af57-cbd4-43a7-9e95-a1edb2035849",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87c1af57-cbd4-43a7-9e95-a1edb2035849",
    "outputId": "1d905ffe-d7be-4df2-ee5b-1727c6a5fb94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",            1\n",
       "..           1\n",
       "...          2\n",
       "amore        1\n",
       "available    1\n",
       "Name: sms0, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_docs.loc['sms0'][bow_docs.loc['sms0'] > 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36ddf7-4182-4e1a-a86c-a4c10e3fca78",
   "metadata": {
    "id": "ce36ddf7-4182-4e1a-a86c-a4c10e3fca78"
   },
   "source": [
    "Use LDiA to create topic vectors for the SMS corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7363dda7-3294-403d-a483-34f59b003c09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7363dda7-3294-403d-a483-34f59b003c09",
    "outputId": "5740b85c-3bc1-4f63-c0b0-c5a02ac79ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 1.01 s, total: 24 s\n",
      "Wall time: 28.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 9232)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ldia = LDiA(n_components=16, learning_method='batch')\n",
    "ldia = ldia.fit(bow_docs)\n",
    "ldia.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71efb10d-364b-4487-898a-3089f358e27f",
   "metadata": {
    "id": "71efb10d-364b-4487-898a-3089f358e27f"
   },
   "source": [
    "Examine the first few words and how they're allocated to the 17 topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbde7d85-4324-4f21-8e89-1d583712df2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "bbde7d85-4324-4f21-8e89-1d583712df2c",
    "outputId": "1151e912-9bb9-4df5-d16e-8d318874392f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>4.63</td>\n",
       "      <td>33.22</td>\n",
       "      <td>202.06</td>\n",
       "      <td>11.01</td>\n",
       "      <td>13.23</td>\n",
       "      <td>144.89</td>\n",
       "      <td>86.72</td>\n",
       "      <td>73.59</td>\n",
       "      <td>487.08</td>\n",
       "      <td>107.13</td>\n",
       "      <td>35.32</td>\n",
       "      <td>29.73</td>\n",
       "      <td>7.32</td>\n",
       "      <td>69.83</td>\n",
       "      <td>61.54</td>\n",
       "      <td>21.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>4.00</td>\n",
       "      <td>195.89</td>\n",
       "      <td>0.06</td>\n",
       "      <td>35.85</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#150</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#5000</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>6.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>1.62</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;</th>\n",
       "      <td>17.05</td>\n",
       "      <td>5.87</td>\n",
       "      <td>18.83</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.82</td>\n",
       "      <td>37.45</td>\n",
       "      <td>58.58</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7.59</td>\n",
       "      <td>102.87</td>\n",
       "      <td>0.06</td>\n",
       "      <td>36.77</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>13.44</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7.73</td>\n",
       "      <td>0.06</td>\n",
       "      <td>10.88</td>\n",
       "      <td>8.78</td>\n",
       "      <td>2.49</td>\n",
       "      <td>107.42</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>10.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>24.59</td>\n",
       "      <td>11.58</td>\n",
       "      <td>22.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9.73</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.45</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "!        4.63   33.22  202.06   11.01   13.23  144.89   86.72   73.59   \n",
       "\"        0.06    0.06    4.00  195.89    0.06   35.85    8.42    0.06   \n",
       "#        0.06    0.06    0.06    0.06    0.06    3.66    0.06    1.41   \n",
       "#150     0.06    0.06    0.06    0.06    0.06    0.06    0.06    0.06   \n",
       "#5000    0.06    0.06    0.06    0.06    0.06    0.06    3.06    0.06   \n",
       "$        6.14    0.06    9.32    0.06    0.06    4.60    0.06    0.06   \n",
       "%        1.62    0.06    0.06    0.06    0.06    4.51    0.06    0.06   \n",
       "&       17.05    5.87   18.83    0.06    2.82   37.45   58.58    0.06   \n",
       "'        0.06    0.06   13.44    5.52    0.06    7.73    0.06   10.88   \n",
       "(       10.36    0.06    1.58    0.06    0.06   24.59   11.58   22.13   \n",
       "\n",
       "       topic8  topic9  topic10  topic11  topic12  topic13  topic14  \\\n",
       "!      487.08  107.13    35.32    29.73     7.32    69.83    61.54   \n",
       "\"        0.06    0.06     0.06     0.06     0.06     0.06     0.06   \n",
       "#        0.06    0.06     0.06     0.06     0.06     0.06     2.12   \n",
       "#150     0.06    0.06     0.06     0.06     0.06     0.06     0.06   \n",
       "#5000    0.06    0.06     0.06     0.06     0.06     0.06     0.06   \n",
       "$        0.06    0.06     0.06     0.06     2.06     0.06     1.19   \n",
       "%        0.06    1.06     0.06     1.06     2.06     0.06     0.06   \n",
       "&        7.59  102.87     0.06    36.77     0.06     0.57     0.27   \n",
       "'        8.78    2.49   107.42     4.24     0.06     0.06     0.06   \n",
       "(        0.06    9.73     0.06     1.06     0.06     6.45     0.06   \n",
       "\n",
       "       topic15  \n",
       "!        21.71  \n",
       "\"        11.16  \n",
       "#         0.06  \n",
       "#150      1.06  \n",
       "#5000     0.06  \n",
       "$         0.06  \n",
       "%         0.06  \n",
       "&         6.07  \n",
       "'         0.06  \n",
       "(         0.06  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', 75)\n",
    "\n",
    "components = pd.DataFrame(ldia.components_.T, index=terms, columns=columns)\n",
    "components.round(2).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "791d1045-7c55-41d4-b4a6-1e381329a6ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "791d1045-7c55-41d4-b4a6-1e381329a6ce",
    "outputId": "46ec8695-9c88-4ddb-c745-3450be1c0ead"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"        195.891765\n",
       "..       172.154417\n",
       ",        114.853307\n",
       "call      78.200003\n",
       ".         70.338211\n",
       "d         69.603604\n",
       "sorry     58.616796\n",
       "u         56.246730\n",
       "later     46.006989\n",
       "of        42.608127\n",
       "Name: topic3, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components.topic3.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10174dec-493b-4aca-964a-203602b16dc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "10174dec-493b-4aca-964a-203602b16dc0",
    "outputId": "20d7e172-6ec0-4698-9fc7-de6ad3a7a114"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "sms0     0.00    0.46    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "sms1     0.01    0.90    0.01    0.01    0.01    0.01    0.01    0.01   \n",
       "sms2!    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "sms3     0.00    0.86    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "sms4     0.94    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "\n",
       "       topic8  topic9  topic10  topic11  topic12  topic13  topic14  \\\n",
       "sms0     0.00    0.00     0.00     0.51     0.00     0.00     0.00   \n",
       "sms1     0.01    0.01     0.01     0.01     0.01     0.01     0.01   \n",
       "sms2!    0.00    0.98     0.00     0.00     0.00     0.00     0.00   \n",
       "sms3     0.00    0.08     0.00     0.00     0.00     0.00     0.00   \n",
       "sms4     0.00    0.00     0.00     0.00     0.00     0.00     0.00   \n",
       "\n",
       "       topic15  \n",
       "sms0      0.00  \n",
       "sms1      0.01  \n",
       "sms2!     0.00  \n",
       "sms3      0.00  \n",
       "sms4      0.00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia16_topic_vectors = ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors, index=index, columns=columns)\n",
    "ldia16_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8239883-5478-4946-a101-fe680dc4eaa5",
   "metadata": {
    "id": "a8239883-5478-4946-a101-fe680dc4eaa5"
   },
   "source": [
    "\n",
    "<a name='4.5.3'></a><a id='4.5.3'></a>\n",
    "## 4.5.3 LDiA + LDA = spam classifier\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: Examine how well LDiA topics are at predicting something useful, such as spaminess. \n",
    "\n",
    "Idea: Use LDiA topic vectors to train a LDA model, and test via inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09ea22f3-c977-45c9-bd7f-8168de6e1aed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "09ea22f3-c977-45c9-bd7f-8168de6e1aed",
    "outputId": "59be1a76-cb4a-417f-eb30-5987ec66678f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.936412490739722e-06\n",
      "0.9919871750616998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms929!</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.159604</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.178012</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.608217</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2321</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.292796</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.652517</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4443!</th>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.308197</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.662637</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3615!</th>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.969758</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2313!</th>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.963942</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.002404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic0    topic1    topic2    topic3    topic4    topic5  \\\n",
       "sms929!   0.004167  0.004167  0.159604  0.004167  0.004167  0.178012   \n",
       "sms2321   0.003906  0.003906  0.003906  0.003906  0.003906  0.003906   \n",
       "sms4443!  0.002083  0.002083  0.002083  0.002083  0.002083  0.002083   \n",
       "sms3615!  0.002016  0.002016  0.002016  0.002016  0.002016  0.002016   \n",
       "sms2313!  0.002404  0.002404  0.002404  0.002404  0.002404  0.963942   \n",
       "\n",
       "            topic6    topic7    topic8    topic9   topic10   topic11  \\\n",
       "sms929!   0.004167  0.004167  0.004167  0.608217  0.004167  0.004167   \n",
       "sms2321   0.003906  0.003906  0.292796  0.003906  0.652517  0.003906   \n",
       "sms4443!  0.002083  0.002083  0.002083  0.308197  0.002083  0.002083   \n",
       "sms3615!  0.002016  0.002016  0.002016  0.002016  0.002016  0.969758   \n",
       "sms2313!  0.002404  0.002404  0.002404  0.002404  0.002404  0.002404   \n",
       "\n",
       "           topic12   topic13   topic14   topic15  \n",
       "sms929!   0.004167  0.004167  0.004167  0.004167  \n",
       "sms2321   0.003906  0.003906  0.003906  0.003906  \n",
       "sms4443!  0.002083  0.662637  0.002083  0.002083  \n",
       "sms3615!  0.002016  0.002016  0.002016  0.002016  \n",
       "sms2313!  0.002404  0.002404  0.002404  0.002404  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the LDiA topic vectors to train an LDA model.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    ldia16_topic_vectors, \n",
    "    sms.spam, \n",
    "    test_size=0.5, \n",
    "    random_state=271828\n",
    ")\n",
    "\n",
    "print(np.nanmin(X_train))\n",
    "print(np.nanmax(X_train))\n",
    "test1 = pd.DataFrame(X_train)\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "vpaXmfE9dP1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpaXmfE9dP1c",
    "outputId": "47c06375-e088-4208-96b3-9d9efc6988bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2418 entries, sms929! to sms2178\n",
      "Data columns (total 16 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   topic0   2418 non-null   float64\n",
      " 1   topic1   2418 non-null   float64\n",
      " 2   topic2   2418 non-null   float64\n",
      " 3   topic3   2418 non-null   float64\n",
      " 4   topic4   2418 non-null   float64\n",
      " 5   topic5   2418 non-null   float64\n",
      " 6   topic6   2418 non-null   float64\n",
      " 7   topic7   2418 non-null   float64\n",
      " 8   topic8   2418 non-null   float64\n",
      " 9   topic9   2418 non-null   float64\n",
      " 10  topic10  2418 non-null   float64\n",
      " 11  topic11  2418 non-null   float64\n",
      " 12  topic12  2418 non-null   float64\n",
      " 13  topic13  2418 non-null   float64\n",
      " 14  topic14  2418 non-null   float64\n",
      " 15  topic15  2418 non-null   float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 321.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "oLzSgR-TJ2aZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLzSgR-TJ2aZ",
    "outputId": "6748bd10-0786-4bdb-8fd5-685cbd61aa1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "sms['ldia16_spam'] = lda.predict(ldia16_topic_vectors)\n",
    "\n",
    "print(f\"Test set accuracy: {round(float(lda.score(X_test, y_test)), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fad843-1a16-4aef-bd80-06d71e215095",
   "metadata": {
    "id": "88fad843-1a16-4aef-bd80-06d71e215095"
   },
   "source": [
    "---\n",
    "\n",
    "Compare how the LDiA model compares to a much higher-dimensional model based on the TF-IDF vectors.\n",
    "\n",
    "The TF-IDF vectors have many more features (more than 3,000 unique terms. So you’re likely to experience overfitting and poor generalization. This is where the generalization of LDiA and PCA should help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9d42c1a-ce4b-4c92-b1b9-7c664941d6f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "b9d42c1a-ce4b-4c92-b1b9-7c664941d6f5",
    "outputId": "6e20769c-0129-4e9d-de97-51ba65fe9192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06573907666856706\n",
      "0.9997932602853008\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9222</th>\n",
       "      <th>9223</th>\n",
       "      <th>9224</th>\n",
       "      <th>9225</th>\n",
       "      <th>9226</th>\n",
       "      <th>9227</th>\n",
       "      <th>9228</th>\n",
       "      <th>9229</th>\n",
       "      <th>9230</th>\n",
       "      <th>9231</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.025643</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>0.205146</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.002745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-7.667659e-07</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.025643</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.002745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-7.667659e-07</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.219732</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>0.113991</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.002745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-7.667659e-07</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.025643</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.002745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-7.667659e-07</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.025643</td>\n",
       "      <td>-0.00584</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.002745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-7.667659e-07</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1         2         3         4         5         6     \\\n",
       "0 -0.025643 -0.00584 -0.000228 -0.000053 -0.000156 -0.000943 -0.000463   \n",
       "1 -0.025643 -0.00584 -0.000228 -0.000053 -0.000156 -0.000943 -0.000463   \n",
       "2  0.219732 -0.00584 -0.000228 -0.000053 -0.000156 -0.000943 -0.000463   \n",
       "3 -0.025643 -0.00584 -0.000228 -0.000053 -0.000156 -0.000943 -0.000463   \n",
       "4 -0.025643 -0.00584 -0.000228 -0.000053 -0.000156 -0.000943 -0.000463   \n",
       "\n",
       "       7         8         9     ...      9222      9223          9224  \\\n",
       "0  0.205146 -0.004035 -0.002745  ... -0.000264 -0.000426 -7.667659e-07   \n",
       "1 -0.006695 -0.004035 -0.002745  ... -0.000264 -0.000426 -7.667659e-07   \n",
       "2  0.113991 -0.004035 -0.002745  ... -0.000264 -0.000426 -7.667659e-07   \n",
       "3  0.119565 -0.004035 -0.002745  ... -0.000264 -0.000426 -7.667659e-07   \n",
       "4 -0.006695 -0.004035 -0.002745  ... -0.000264 -0.000426 -7.667659e-07   \n",
       "\n",
       "       9225      9226      9227     9228      9229      9230      9231  \n",
       "0 -0.001598 -0.000148 -0.000099 -0.00066 -0.000055 -0.000055 -0.000055  \n",
       "1 -0.001598 -0.000148 -0.000099 -0.00066 -0.000055 -0.000055 -0.000055  \n",
       "2 -0.001598 -0.000148 -0.000099 -0.00066 -0.000055 -0.000055 -0.000055  \n",
       "3 -0.001598 -0.000148 -0.000099 -0.00066 -0.000055 -0.000055 -0.000055  \n",
       "4 -0.001598 -0.000148 -0.000099 -0.00066 -0.000055 -0.000055 -0.000055  \n",
       "\n",
       "[5 rows x 9232 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text).toarray()\n",
    "\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean(axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tfidf_docs, \n",
    "    sms.spam.values, \n",
    "    test_size=0.5, \n",
    "    random_state=271828\n",
    ")\n",
    "\n",
    "print(np.nanmin(X_train))\n",
    "print(np.nanmax(X_train))\n",
    "test2 = pd.DataFrame(X_train)\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "vqUywtxJdJul",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqUywtxJdJul",
    "outputId": "ffa3f62e-13e8-4680-975c-d22558a5dce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2418 entries, 0 to 2417\n",
      "Columns: 9232 entries, 0 to 9231\n",
      "dtypes: float64(9232)\n",
      "memory usage: 170.3 MB\n"
     ]
    }
   ],
   "source": [
    "test2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9nhAUe-vIebP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nhAUe-vIebP",
    "outputId": "c778d225-f935-413c-94c2-cf3e768e6bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 1.0\n",
      "Test set accuracy: 0.748\n"
     ]
    }
   ],
   "source": [
    "# Fitting an LDA model to all these thousands of features will take \n",
    "# quite a long time. It’s slicing up your vector space with a \n",
    "# 9,332-dimension hyperplane.\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training set accuracy: {round(float(lda.score(X_train, y_train)), 3)}\")\n",
    "print(f\"Test set accuracy: {round(float(lda.score(X_test, y_test)), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad54b6-c003-4169-8ae4-b297d4c853eb",
   "metadata": {
    "id": "0fad54b6-c003-4169-8ae4-b297d4c853eb"
   },
   "source": [
    "<a name='4.5.4'></a><a id='4.5.4'></a>\n",
    "## 4.5.4 A fairer comparison: 32 LDiA topics\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: LDiA may not be as efficient as LSA (PSA), so it may need more topics to allocate words to.\n",
    "\n",
    "Idea: Try 32 topics (components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bd45dca-20b0-4762-a322-4aada753decb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bd45dca-20b0-4762-a322-4aada753decb",
    "outputId": "0a1c3ed8-1a17-464f-dbc2-707c79de1c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.3 s, sys: 1.12 s, total: 25.5 s\n",
      "Wall time: 32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 9232)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Try 32 topics (components)\n",
    "ldia32 = LDiA(n_components=32, learning_method='batch')\n",
    "ldia32 = ldia32.fit(bow_docs)\n",
    "ldia32.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f562041-a4fa-4c3d-8c51-f6aa7745bfd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "9f562041-a4fa-4c3d-8c51-f6aa7745bfd7",
    "outputId": "ed997147-c026-4c44-d970-3fd121d79afa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic22</th>\n",
       "      <th>topic23</th>\n",
       "      <th>topic24</th>\n",
       "      <th>topic25</th>\n",
       "      <th>topic26</th>\n",
       "      <th>topic27</th>\n",
       "      <th>topic28</th>\n",
       "      <th>topic29</th>\n",
       "      <th>topic30</th>\n",
       "      <th>topic31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "sms0      0.0     0.0     0.0     0.0    0.47     0.0    0.00     0.0   \n",
       "sms1      0.0     0.0     0.0     0.0    0.13     0.0    0.12     0.0   \n",
       "sms2!     0.0     0.0     0.0     0.0    0.06     0.0    0.00     0.0   \n",
       "sms3      0.0     0.0     0.0     0.0    0.27     0.0    0.00     0.0   \n",
       "sms4      0.0     0.0     0.0     0.0    0.31     0.0    0.00     0.0   \n",
       "\n",
       "       topic8  topic9  ...  topic22  topic23  topic24  topic25  topic26  \\\n",
       "sms0      0.0     0.0  ...      0.0      0.0      0.0     0.49      0.0   \n",
       "sms1      0.0     0.0  ...      0.0      0.0      0.0     0.49      0.0   \n",
       "sms2!     0.0     0.0  ...      0.0      0.0      0.0     0.00      0.0   \n",
       "sms3      0.0     0.0  ...      0.0      0.0      0.0     0.66      0.0   \n",
       "sms4      0.0     0.0  ...      0.0      0.0      0.0     0.00      0.0   \n",
       "\n",
       "       topic27  topic28  topic29  topic30  topic31  \n",
       "sms0       0.0      0.0      0.0      0.0     0.00  \n",
       "sms1       0.0      0.0      0.0      0.0     0.00  \n",
       "sms2!      0.0      0.0      0.0      0.0     0.91  \n",
       "sms3       0.0      0.0      0.0      0.0     0.00  \n",
       "sms4       0.0      0.0      0.0      0.0     0.00  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute new 32-D topic vectors for all the documents (SMS messages)\n",
    "ldia32_topic_vectors = ldia32.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia32.n_components)]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors, index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52ebe616-d81d-4a93-bf0f-75a5d91b56a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "52ebe616-d81d-4a93-bf0f-75a5d91b56a8",
    "outputId": "1125d4a1-8697-4ed5-eb1e-09b615cb7b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.968203497626435e-06\n",
      "0.991720085470069\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic22</th>\n",
       "      <th>topic23</th>\n",
       "      <th>topic24</th>\n",
       "      <th>topic25</th>\n",
       "      <th>topic26</th>\n",
       "      <th>topic27</th>\n",
       "      <th>topic28</th>\n",
       "      <th>topic29</th>\n",
       "      <th>topic30</th>\n",
       "      <th>topic31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms929!</th>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.166457</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2321</th>\n",
       "      <td>0.340144</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.424644</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4443!</th>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3615!</th>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.078617</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2313!</th>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.161379</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.745291</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic0    topic1    topic2    topic3    topic4    topic5  \\\n",
       "sms929!   0.002083  0.002083  0.002083  0.002083  0.002083  0.002083   \n",
       "sms2321   0.340144  0.001953  0.001953  0.178571  0.001953  0.424644   \n",
       "sms4443!  0.001042  0.001042  0.001042  0.001042  0.001042  0.001042   \n",
       "sms3615!  0.001008  0.001008  0.001008  0.001008  0.001008  0.001008   \n",
       "sms2313!  0.001202  0.001202  0.001202  0.001202  0.001202  0.001202   \n",
       "\n",
       "            topic6    topic7    topic8    topic9  ...   topic22  \\\n",
       "sms929!   0.002083  0.002083  0.002083  0.002083  ...  0.002083   \n",
       "sms2321   0.001953  0.001953  0.001953  0.001953  ...  0.001953   \n",
       "sms4443!  0.001042  0.001042  0.001042  0.001042  ...  0.001042   \n",
       "sms3615!  0.001008  0.001008  0.001008  0.001008  ...  0.001008   \n",
       "sms2313!  0.161379  0.001202  0.001202  0.001202  ...  0.001202   \n",
       "\n",
       "           topic23   topic24   topic25   topic26   topic27   topic28  \\\n",
       "sms929!   0.002083  0.166457  0.002083  0.002083  0.002083  0.002083   \n",
       "sms2321   0.001953  0.001953  0.001953  0.001953  0.001953  0.001953   \n",
       "sms4443!  0.001042  0.001042  0.001042  0.001042  0.001042  0.001042   \n",
       "sms3615!  0.001008  0.001008  0.001008  0.001008  0.001008  0.001008   \n",
       "sms2313!  0.001202  0.001202  0.001202  0.001202  0.001202  0.001202   \n",
       "\n",
       "           topic29   topic30   topic31  \n",
       "sms929!   0.002083  0.002083  0.002083  \n",
       "sms2321   0.001953  0.001953  0.001953  \n",
       "sms4443!  0.001042  0.001042  0.001042  \n",
       "sms3615!  0.078617  0.001008  0.001008  \n",
       "sms2313!  0.745291  0.001202  0.001202  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA model (classifier) training, using 32-D LDiA topic vectors\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    ldia32_topic_vectors, \n",
    "    sms.spam, \n",
    "    test_size=0.5, \n",
    "    random_state=271828\n",
    ")\n",
    "\n",
    "print(np.nanmin(X_train))\n",
    "print(np.nanmax(X_train))\n",
    "test3 = pd.DataFrame(X_train)\n",
    "test3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "qV7P5fSId-FX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qV7P5fSId-FX",
    "outputId": "cd99101b-32e6-4146-9857-530e3212c275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2418 entries, sms929! to sms2178\n",
      "Data columns (total 32 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   topic0   2418 non-null   float64\n",
      " 1   topic1   2418 non-null   float64\n",
      " 2   topic2   2418 non-null   float64\n",
      " 3   topic3   2418 non-null   float64\n",
      " 4   topic4   2418 non-null   float64\n",
      " 5   topic5   2418 non-null   float64\n",
      " 6   topic6   2418 non-null   float64\n",
      " 7   topic7   2418 non-null   float64\n",
      " 8   topic8   2418 non-null   float64\n",
      " 9   topic9   2418 non-null   float64\n",
      " 10  topic10  2418 non-null   float64\n",
      " 11  topic11  2418 non-null   float64\n",
      " 12  topic12  2418 non-null   float64\n",
      " 13  topic13  2418 non-null   float64\n",
      " 14  topic14  2418 non-null   float64\n",
      " 15  topic15  2418 non-null   float64\n",
      " 16  topic16  2418 non-null   float64\n",
      " 17  topic17  2418 non-null   float64\n",
      " 18  topic18  2418 non-null   float64\n",
      " 19  topic19  2418 non-null   float64\n",
      " 20  topic20  2418 non-null   float64\n",
      " 21  topic21  2418 non-null   float64\n",
      " 22  topic22  2418 non-null   float64\n",
      " 23  topic23  2418 non-null   float64\n",
      " 24  topic24  2418 non-null   float64\n",
      " 25  topic25  2418 non-null   float64\n",
      " 26  topic26  2418 non-null   float64\n",
      " 27  topic27  2418 non-null   float64\n",
      " 28  topic28  2418 non-null   float64\n",
      " 29  topic29  2418 non-null   float64\n",
      " 30  topic30  2418 non-null   float64\n",
      " 31  topic31  2418 non-null   float64\n",
      "dtypes: float64(32)\n",
      "memory usage: 623.4+ KB\n"
     ]
    }
   ],
   "source": [
    "test3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "Ncp3nmJgIod_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ncp3nmJgIod_",
    "outputId": "cd695671-1f84-4bfb-9c00-c1eefa5ac5b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2418, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "sms['ldia32_spam'] = lda.predict(ldia32_topic_vectors)\n",
    "\n",
    "# Check number of dimensions in topic vectors\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "439157a4-ee78-476d-af1f-691e29e738ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "439157a4-ee78-476d-af1f-691e29e738ac",
    "outputId": "34c8711a-97ed-4d47-881c-18392d06808a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.922\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {round(float(lda.score(X_train, y_train)), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d518d7b2-730f-44f8-9d4a-8b7f3ca563fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d518d7b2-730f-44f8-9d4a-8b7f3ca563fd",
    "outputId": "ac32aee1-dd59-4614-e926-f935088b5109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {round(float(lda.score(X_test, y_test)), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9711d-d7f8-4d7b-afb6-bf8c0996b259",
   "metadata": {
    "id": "8dc9711d-d7f8-4d7b-afb6-bf8c0996b259"
   },
   "source": [
    "---\n",
    "<a name='4.6'></a><a id='4.6'></a>\n",
    "# 4.6 Distance and similarity\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Problem: Test how well LSA topic models agree with the higher-dimensional TF-IDF model.\n",
    "\n",
    "Idea: Use similarity scores and distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e2788-b9e6-447e-8b84-ecc62e80ebdc",
   "metadata": {
    "id": "e29e2788-b9e6-447e-8b84-ecc62e80ebdc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
